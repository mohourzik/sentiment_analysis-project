{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import annotations\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1e etape: pre-precessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31232, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['text']\n",
    "\n",
    "def cleaning_text(text):\n",
    "  text_pattern = re.compile(\n",
    "    r'(<.+?>)'         # Balises HTML\n",
    "    r'|([@|#]\\w+)'     # Mentions et hashtags\n",
    "    r'|([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'  # Emails\n",
    "    r'|(https?\\W+[^\\s]+)'  # URLs commençant par http ou https\n",
    "    r'|(www\\.[^\\s]+)'      # URLs commençant par www\n",
    "    r'|([\\U00010000-\\U0010ffff])'  # Émojis et autres caractères au-delà de l'ASCII étendu\n",
    "    r'|([^\\x00-\\xFF])'     # Tout ce qui n'est pas en ASCII étendu (0-255)\n",
    ")\n",
    "  text = text_pattern.sub('', str(text))\n",
    "  text = text.lower()\n",
    "  punctuation = set(string.punctuation)\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  tokens = []\n",
    "  sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "  for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    for word in words:\n",
    "      if word in punctuation or word in stop_words:\n",
    "        continue\n",
    "      word = ''.join([c for c in word if c not in punctuation])\n",
    "      tokens.append(word)\n",
    "  # get the part of speech\n",
    "  pos_tags = nltk.pos_tag(tokens)\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  data = []\n",
    "  for token, pos in pos_tags:\n",
    "    if pos.startswith('J'):\n",
    "      lemma = lemmatizer.lemmatize(token, pos = 'a')\n",
    "    elif pos.startswith('V'):\n",
    "      lemma = lemmatizer.lemmatize(token, pos = 'v')\n",
    "    elif pos.startswith('R'):\n",
    "      lemma = lemmatizer.lemmatize(token, pos = 'r')\n",
    "    elif pos.startswith('N'):\n",
    "      lemma = lemmatizer.lemmatize(token, pos = 'n')\n",
    "    else:\n",
    "      lemma = lemmatizer.lemmatize(token)\n",
    "    data.append([token, lemma, pos])\n",
    "\n",
    "  return data\n",
    "\n",
    "def get_info(texts):\n",
    "  data = []\n",
    "  for text in texts:\n",
    "    text = cleaning_text(text)\n",
    "    data.extend(text)\n",
    "    data.append(['', '', ''])\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./token_lemma_pos.csv\"):\n",
    "  df_tokens = pd.read_csv(\"./token_lemma_pos.csv\")\n",
    "else:\n",
    "  data = get_info(texts = texts)\n",
    "  df_tokens = pd.DataFrame(data, columns = ['token', 'lemma', 'pos'])\n",
    "  df_tokens.to_csv(\"./token_lemma_pos.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens = pd.read_csv('./token_lemma_pos.csv')\n",
    "df_tokens.fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cooking</td>\n",
       "      <td>cook</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microwave</td>\n",
       "      <td>microwave</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pizzas</td>\n",
       "      <td>pizza</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yummy</td>\n",
       "      <td>yummy</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343782</th>\n",
       "      <td>hours</td>\n",
       "      <td>hour</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343783</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343784</th>\n",
       "      <td>missed</td>\n",
       "      <td>miss</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343785</th>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343786</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343787 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            token      lemma  pos\n",
       "0         cooking       cook  VBG\n",
       "1       microwave  microwave   NN\n",
       "2          pizzas      pizza   NN\n",
       "3           yummy      yummy   NN\n",
       "4                                \n",
       "...           ...        ...  ...\n",
       "343782      hours       hour  NNS\n",
       "343783                           \n",
       "343784     missed       miss  VBN\n",
       "343785       play       play   NN\n",
       "343786                           \n",
       "\n",
       "[343787 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2e etape: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = df_tokens['lemma'].tolist()\n",
    "\n",
    "def get_document(lemma: list[str]):\n",
    "  docs = []\n",
    "  for i in range(0, len(lemma)):\n",
    "    for j in range(i, len(lemma)):\n",
    "      if lemma[j] == '':\n",
    "        docs.append(' '.join(lemma[i:j]))\n",
    "        i = j + 1\n",
    "    break\n",
    "  return docs\n",
    "\n",
    "docs = get_document(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "docs = np.array(docs)\n",
    "tfidf = TfidfVectorizer(use_idf = True, norm = 'l2', smooth_idf=True)\n",
    "tfidf_matrix = tfidf.fit_transform(docs).toarray()\n",
    "csr = csr_matrix(tfidf_matrix ,dtype = float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tfidf_matrix\n",
    "\n",
    "if os.path.exists('./tfidf_matrix.npz'):\n",
    "  csr = np.load('./tfidf_matrix.npz', allow_pickle=True)\n",
    "else:\n",
    "  np.savez('./tfidf_matrix', csr)\n",
    "  csr = np.load('./tfidf_matrix.npz', allow_pickle= True)\n",
    "csr = csr['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3e etape: WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "path = './GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(path, binary= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = get_document(lemma= lemma)\n",
    "lemmas = [doc.split() for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(list(model.key_to_index.keys()))\n",
    "\n",
    "def remove_words(lemmas, vocab):\n",
    "    for phrase in lemmas:\n",
    "        for word in phrase:\n",
    "            if word not in vocab:\n",
    "                phrase.remove(word)\n",
    "        if phrase == []:\n",
    "            lemmas.remove(phrase)\n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens['word2vec'] = df_tokens['lemma'].apply(lambda word: model[word] if word in vocab else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cook</td>\n",
       "      <td>[-2.32421875e-01  9.03320312e-02  7.81250000e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>microwave</td>\n",
       "      <td>[-0.30078125 -0.06689453  0.07568359  0.324218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pizza</td>\n",
       "      <td>[-1.25976562e-01  2.53906250e-02  1.66992188e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>yummy</td>\n",
       "      <td>[-1.89453125e-01 -6.59179688e-02 -4.17480469e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>plan</td>\n",
       "      <td>[ 0.07861328  0.09814453  0.16894531  0.083496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290991</th>\n",
       "      <td>290991</td>\n",
       "      <td>start</td>\n",
       "      <td>[-3.44238281e-02  1.03515625e-01  2.16064453e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290992</th>\n",
       "      <td>290992</td>\n",
       "      <td>couple</td>\n",
       "      <td>[ 0.09667969 -0.00326538 -0.37109375  0.104492...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290993</th>\n",
       "      <td>290993</td>\n",
       "      <td>hour</td>\n",
       "      <td>[-2.15820312e-01  1.43432617e-02 -7.91015625e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290994</th>\n",
       "      <td>290994</td>\n",
       "      <td>miss</td>\n",
       "      <td>[ 2.00195312e-01 -1.54296875e-01  1.45507812e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290995</th>\n",
       "      <td>290995</td>\n",
       "      <td>play</td>\n",
       "      <td>[ 0.01226807  0.06225586  0.10693359  0.058105...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      lemma  \\\n",
       "0                0       cook   \n",
       "1                1  microwave   \n",
       "2                2      pizza   \n",
       "3                3      yummy   \n",
       "4                4       plan   \n",
       "...            ...        ...   \n",
       "290991      290991      start   \n",
       "290992      290992     couple   \n",
       "290993      290993       hour   \n",
       "290994      290994       miss   \n",
       "290995      290995       play   \n",
       "\n",
       "                                                 word2vec  \n",
       "0       [-2.32421875e-01  9.03320312e-02  7.81250000e-...  \n",
       "1       [-0.30078125 -0.06689453  0.07568359  0.324218...  \n",
       "2       [-1.25976562e-01  2.53906250e-02  1.66992188e-...  \n",
       "3       [-1.89453125e-01 -6.59179688e-02 -4.17480469e-...  \n",
       "4       [ 0.07861328  0.09814453  0.16894531  0.083496...  \n",
       "...                                                   ...  \n",
       "290991  [-3.44238281e-02  1.03515625e-01  2.16064453e-...  \n",
       "290992  [ 0.09667969 -0.00326538 -0.37109375  0.104492...  \n",
       "290993  [-2.15820312e-01  1.43432617e-02 -7.91015625e-...  \n",
       "290994  [ 2.00195312e-01 -1.54296875e-01  1.45507812e-...  \n",
       "290995  [ 0.01226807  0.06225586  0.10693359  0.058105...  \n",
       "\n",
       "[290996 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(data = [(lemma, word2vec) \\\n",
    "                           for lemma, word2vec in zip(df_tokens['lemma'], df_tokens['word2vec']) \\\n",
    "                            if word2vec is not None], \n",
    "                    columns= ['lemma', 'word2vec']\n",
    ")\n",
    "\n",
    "if os.path.exists('./word2vec.csv'):\n",
    "    df2 = pd.read_csv('./word2vec.csv')\n",
    "else:\n",
    "    df2.to_csv(\"./word2vec.csv\", index = False)\n",
    "    df2 = pd.read_csv('./word2vec.csv')\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cook', 'microwave', 'pizza', 'yummy']</td>\n",
       "      <td>[-0.2121582  -0.00427246  0.06976318  0.358886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['plan', 'allow', 'sub', 'task', 'show', 'widg...</td>\n",
       "      <td>[ 0.02561442  0.02229945  0.04549154  0.049357...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['love', 'humor', 'reword', 'like', 'say', 'gr...</td>\n",
       "      <td>[ 0.05505371 -0.00522178  0.05345481  0.163966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['naw', 'idk', 'ur', 'talkin']</td>\n",
       "      <td>[-5.37261963e-02  5.86547852e-02  1.56799316e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['suck', 'hear', 'hate', 'day', 'like']</td>\n",
       "      <td>[ 0.05214844  0.03173828  0.09024353  0.095996...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36974</th>\n",
       "      <td>['get', 'wrong', 'size', 'coat', 'sheep']</td>\n",
       "      <td>[ 5.19775376e-02  3.69628891e-02 -8.23242217e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36975</th>\n",
       "      <td>['4', 'case', 'swine', 'flu']</td>\n",
       "      <td>[ 0.01879883 -0.00683594 -0.00805664  0.111633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36976</th>\n",
       "      <td>['excellent']</td>\n",
       "      <td>[-2.12890625e-01 -4.30297852e-03 -1.80664062e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36977</th>\n",
       "      <td>['sit', 'thru', 'bore', 'bit', 'titanic', 'wai...</td>\n",
       "      <td>[ 0.04436701  0.07160811 -0.06126265  0.158513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36978</th>\n",
       "      <td>['miss', 'play']</td>\n",
       "      <td>[ 1.06231689e-01 -4.60205078e-02  1.26220703e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36979 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  phrase  \\\n",
       "0                ['cook', 'microwave', 'pizza', 'yummy']   \n",
       "1      ['plan', 'allow', 'sub', 'task', 'show', 'widg...   \n",
       "2      ['love', 'humor', 'reword', 'like', 'say', 'gr...   \n",
       "3                         ['naw', 'idk', 'ur', 'talkin']   \n",
       "4                ['suck', 'hear', 'hate', 'day', 'like']   \n",
       "...                                                  ...   \n",
       "36974          ['get', 'wrong', 'size', 'coat', 'sheep']   \n",
       "36975                      ['4', 'case', 'swine', 'flu']   \n",
       "36976                                      ['excellent']   \n",
       "36977  ['sit', 'thru', 'bore', 'bit', 'titanic', 'wai...   \n",
       "36978                                   ['miss', 'play']   \n",
       "\n",
       "                                              phrase2vec  \n",
       "0      [-0.2121582  -0.00427246  0.06976318  0.358886...  \n",
       "1      [ 0.02561442  0.02229945  0.04549154  0.049357...  \n",
       "2      [ 0.05505371 -0.00522178  0.05345481  0.163966...  \n",
       "3      [-5.37261963e-02  5.86547852e-02  1.56799316e-...  \n",
       "4      [ 0.05214844  0.03173828  0.09024353  0.095996...  \n",
       "...                                                  ...  \n",
       "36974  [ 5.19775376e-02  3.69628891e-02 -8.23242217e-...  \n",
       "36975  [ 0.01879883 -0.00683594 -0.00805664  0.111633...  \n",
       "36976  [-2.12890625e-01 -4.30297852e-03 -1.80664062e-...  \n",
       "36977  [ 0.04436701  0.07160811 -0.06126265  0.158513...  \n",
       "36978  [ 1.06231689e-01 -4.60205078e-02  1.26220703e-...  \n",
       "\n",
       "[36979 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = remove_words(lemmas, vocab)\n",
    "\n",
    "df3 = pd.DataFrame(data = [(phrase, model.get_mean_vector(phrase, pre_normalize=False)) \\\n",
    "                               for phrase in lemmas],\n",
    "                    columns= ['phrase', 'phrase2vec'])\n",
    "\n",
    "if os.path.exists('./phrase2vec.csv'):\n",
    "    df3 = pd.read_csv('./phrase2vec.csv')\n",
    "else:\n",
    "    df3.to_csv(\"./phrase2vec.csv\", index = False)\n",
    "    df3 = pd.read_csv('./phrase2vec.csv')\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.similarity(w1 = 'woman', w2 = 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # king - man + women = queen\n",
    "# model.most_similar(positive=['king', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wv1 = model['king'] - model['man'] + model['women']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors = []\n",
    "\n",
    "# for token in tokens[1]:\n",
    "#     out = model['token']\n",
    "#     vectors.append(out)\n",
    "\n",
    "# np.array(vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_mean_vector(tokens[2], pre_normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.test.utils import common_texts\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "# model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.load('word2vec.model')\n",
    "# model.train([['hello', 'world'], ['how', 'are', 'you']], total_examples=10, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
