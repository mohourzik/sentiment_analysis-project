{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import annotations\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all the csv files into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cooking microwave pizzas, yummy</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Any plans of allowing sub tasks to show up in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love the humor, I just reworded it. Like sa...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naw idk what ur talkin about</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That sucks to hear. I hate days like that</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41639</th>\n",
       "      <td>Fuck no internet damn time warner!</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41640</th>\n",
       "      <td>Looking forward to android 1.5 being pushed t...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41641</th>\n",
       "      <td>Not good. Wasted time.</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41642</th>\n",
       "      <td>U were great, as always. But, can`t we do an ...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41643</th>\n",
       "      <td>- Love your desserts. Used to live in OR but ...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41644 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label sentiment\n",
       "0                        Cooking microwave pizzas, yummy      2  positive\n",
       "1      Any plans of allowing sub tasks to show up in ...      1   neutral\n",
       "2       I love the humor, I just reworded it. Like sa...      2  positive\n",
       "3                           naw idk what ur talkin about      1   neutral\n",
       "4              That sucks to hear. I hate days like that      0  negative\n",
       "...                                                  ...    ...       ...\n",
       "41639                 Fuck no internet damn time warner!      0  negative\n",
       "41640   Looking forward to android 1.5 being pushed t...      1   neutral\n",
       "41641                             Not good. Wasted time.      0  negative\n",
       "41642   U were great, as always. But, can`t we do an ...      2  positive\n",
       "41643   - Love your desserts. Used to live in OR but ...      2  positive\n",
       "\n",
       "[41644 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = 'data/train.csv'\n",
    "test_data = 'data/test.csv'\n",
    "valid_data = 'data/test.csv'\n",
    "\n",
    "file = \"multiclass_dataset.csv\"\n",
    "\n",
    "def save_load_df(file:str):\n",
    "    if os.path.exists(file):\n",
    "        df = pd.read_csv(file, index_col= 0)\n",
    "    else:\n",
    "        df = pd.concat(map(pd.read_csv, [train_data, test_data, valid_data]), axis= 0, ignore_index=True)\n",
    "        df.to_csv(file, columns= ['id', 'text', 'label', 'sentiment'])\n",
    "        df = pd.read_csv(file, index_col= 0)\n",
    "    return df\n",
    "\n",
    "df = save_load_df(file=file)\n",
    "# df = df.sample(frac=1, random_state= 1337).reset_index(drop=True)\n",
    "df = df.drop(columns='id')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1e etape: pre-precessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cooking</td>\n",
       "      <td>cook</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microwave</td>\n",
       "      <td>microwave</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pizzas</td>\n",
       "      <td>pizza</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yummy</td>\n",
       "      <td>yummy</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447665</th>\n",
       "      <td>live</td>\n",
       "      <td>live</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447666</th>\n",
       "      <td>live</td>\n",
       "      <td>live</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447667</th>\n",
       "      <td>tx</td>\n",
       "      <td>tx</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447668</th>\n",
       "      <td>visit</td>\n",
       "      <td>visit</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447669</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447670 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            token      lemma  pos\n",
       "0         cooking       cook  VBG\n",
       "1       microwave  microwave   NN\n",
       "2          pizzas      pizza   NN\n",
       "3           yummy      yummy   NN\n",
       "4                                \n",
       "...           ...        ...  ...\n",
       "447665       live       live   JJ\n",
       "447666       live       live   JJ\n",
       "447667         tx         tx   NN\n",
       "447668      visit      visit   NN\n",
       "447669                           \n",
       "\n",
       "[447670 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_text(text):\n",
    "    text_pattern = re.compile(\n",
    "        r'(<.+?>)'         # Balises HTML\n",
    "        r'|([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'  # Emails\n",
    "        r'|(https?\\W+[^\\s]+)'  # URLs commençant par http ou https\n",
    "        r'|(https?://[^\\s\\n\\r]+)' # URLs commençant par http ou https\n",
    "        r'|(www\\.[^\\s]+)'      # URLs commençant par www\n",
    "        r'|([\\U00010000-\\U0010ffff])'  # Émojis et autres caractères au-delà de l'ASCII étendu\n",
    "        r'|([^\\x00-\\xFF])'     # Tout ce qui n'est pas en ASCII étendu (0-255)\n",
    "    )\n",
    "    text = text_pattern.sub('', str(text))\n",
    "    text = text.lower()\n",
    "    punctuation = set(string.punctuation)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = []\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "      words = nltk.word_tokenize(sentence)\n",
    "      for word in words:\n",
    "        if word not in stop_words:\n",
    "          word = ''.join([c for c in word if c not in punctuation])\n",
    "          if word == '':\n",
    "              continue\n",
    "          tokens.append(word)\n",
    "    \n",
    "    # get the part of speech\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data = []\n",
    "    for token, pos in pos_tags:\n",
    "        if pos.startswith('J'):\n",
    "          lemma = lemmatizer.lemmatize(token, pos = 'a')\n",
    "        elif pos.startswith('V'):\n",
    "          lemma = lemmatizer.lemmatize(token, pos = 'v')\n",
    "        elif pos.startswith('RB'):\n",
    "          lemma = lemmatizer.lemmatize(token, pos = 'r')\n",
    "        elif pos.startswith('N'):\n",
    "          lemma = lemmatizer.lemmatize(token, pos = 'n')\n",
    "        else:\n",
    "          lemma = lemmatizer.lemmatize(token)\n",
    "        data.append([token, lemma, pos])\n",
    "    data.append(['', '', ''])\n",
    "    return data\n",
    "\n",
    "def get_infos(texts):\n",
    "    infos = []\n",
    "    for text in texts:\n",
    "        data = cleaning_text(text=text)\n",
    "        infos.extend(data)\n",
    "    return infos\n",
    "\n",
    "texts = df['text']\n",
    "df_tokens = pd.DataFrame(get_infos(texts), columns = ['token', 'lemma', 'pos'])\n",
    "df_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2e etape: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_document(element: list[str]):\n",
    "  docs = []\n",
    "  for i in range(0, len(element)):\n",
    "    for j in range(i, len(element)):\n",
    "      if element[j] == '':\n",
    "        docs.append(' '.join(element[i:j]))\n",
    "        i = j + 1\n",
    "    break\n",
    "  return docs\n",
    "\n",
    "documents = get_document(df_tokens['lemma'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "docs = np.array(documents)\n",
    "tfidf = TfidfVectorizer(use_idf = True, norm = 'l2', smooth_idf=True)\n",
    "tfidf_matrix = tfidf.fit_transform(docs).toarray()\n",
    "csr = csr_matrix(tfidf_matrix ,dtype = float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tfidf_matrix\n",
    "if os.path.exists('tfidf_matrix.npz'):\n",
    "  csr = np.load('tfidf_matrix.npz', allow_pickle=True)\n",
    "else:\n",
    "  np.savez('tfidf_matrix', csr)\n",
    "  csr = np.load('tfidf_matrix.npz', allow_pickle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3e etape: word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(list(word2vec_model.key_to_index.keys()))\n",
    "lemmas = [doc.split() for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cook</td>\n",
       "      <td>[-0.23242188, 0.09033203, 0.078125, 0.12695312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microwave</td>\n",
       "      <td>[-0.30078125, -0.06689453, 0.075683594, 0.3242...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pizza</td>\n",
       "      <td>[-0.12597656, 0.025390625, 0.16699219, 0.55078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yummy</td>\n",
       "      <td>[-0.18945312, -0.06591797, -0.041748047, 0.433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plan</td>\n",
       "      <td>[0.07861328, 0.09814453, 0.16894531, 0.0834960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387233</th>\n",
       "      <td>use</td>\n",
       "      <td>[0.11279297, -0.13085938, 0.06689453, 0.138671...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387234</th>\n",
       "      <td>live</td>\n",
       "      <td>[0.016967773, 0.017333984, -0.041748047, 0.126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387235</th>\n",
       "      <td>live</td>\n",
       "      <td>[0.016967773, 0.017333984, -0.041748047, 0.126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387236</th>\n",
       "      <td>tx</td>\n",
       "      <td>[0.022949219, 0.049804688, -0.10546875, 0.3300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387237</th>\n",
       "      <td>visit</td>\n",
       "      <td>[-0.12597656, 0.12451172, 0.0035858154, 0.0156...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387238 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lemma                                           word2vec\n",
       "0            cook  [-0.23242188, 0.09033203, 0.078125, 0.12695312...\n",
       "1       microwave  [-0.30078125, -0.06689453, 0.075683594, 0.3242...\n",
       "2           pizza  [-0.12597656, 0.025390625, 0.16699219, 0.55078...\n",
       "3           yummy  [-0.18945312, -0.06591797, -0.041748047, 0.433...\n",
       "4            plan  [0.07861328, 0.09814453, 0.16894531, 0.0834960...\n",
       "...           ...                                                ...\n",
       "387233        use  [0.11279297, -0.13085938, 0.06689453, 0.138671...\n",
       "387234       live  [0.016967773, 0.017333984, -0.041748047, 0.126...\n",
       "387235       live  [0.016967773, 0.017333984, -0.041748047, 0.126...\n",
       "387236         tx  [0.022949219, 0.049804688, -0.10546875, 0.3300...\n",
       "387237      visit  [-0.12597656, 0.12451172, 0.0035858154, 0.0156...\n",
       "\n",
       "[387238 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec = df_tokens['lemma'].apply(lambda word: word2vec_model[word] if word in vocab else None)\n",
    "df2 = pd.DataFrame(data = [(lemma, word2vec) \\\n",
    "                           for lemma, word2vec in zip(df_tokens['lemma'], word2vec) \\\n",
    "                            if word2vec is not None], columns= ['lemma', 'word2vec'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cook, microwave, pizza, yummy]</td>\n",
       "      <td>[-0.2121582, -0.004272461, 0.06976318, 0.35888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[plan, allow, sub, task, show, widget]</td>\n",
       "      <td>[0.02561442, 0.022299448, 0.045491535, 0.04935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[love, humor, reword, like, say, group, therap...</td>\n",
       "      <td>[0.05505371, -0.0052217757, 0.05345481, 0.1639...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[naw, idk, ur, talkin]</td>\n",
       "      <td>[-0.053726196, 0.058654785, 0.15679932, 0.2163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[suck, hear, hate, day, like]</td>\n",
       "      <td>[0.05214844, 0.03173828, 0.09024353, 0.0959961...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41502</th>\n",
       "      <td>[fuck, internet, damn, time, warner]</td>\n",
       "      <td>[0.023242187, -0.06225586, -0.018005371, 0.217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41503</th>\n",
       "      <td>[look, forward, android, 15, push, g1]</td>\n",
       "      <td>[-0.059326172, 0.030419922, -0.070410155, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41504</th>\n",
       "      <td>[good, waste, time]</td>\n",
       "      <td>[-0.068359375, 0.21289062, 0.12904866, 0.14469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41505</th>\n",
       "      <td>[u, great, always, east, germany, noko, least,...</td>\n",
       "      <td>[0.0022521974, 0.013061523, 0.10640259, 0.1460...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41506</th>\n",
       "      <td>[love, dessert, use, live, live, tx, visit]</td>\n",
       "      <td>[0.007847377, -0.04910714, -0.015775409, 0.202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41507 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  phrase  \\\n",
       "0                        [cook, microwave, pizza, yummy]   \n",
       "1                 [plan, allow, sub, task, show, widget]   \n",
       "2      [love, humor, reword, like, say, group, therap...   \n",
       "3                                 [naw, idk, ur, talkin]   \n",
       "4                          [suck, hear, hate, day, like]   \n",
       "...                                                  ...   \n",
       "41502               [fuck, internet, damn, time, warner]   \n",
       "41503             [look, forward, android, 15, push, g1]   \n",
       "41504                                [good, waste, time]   \n",
       "41505  [u, great, always, east, germany, noko, least,...   \n",
       "41506        [love, dessert, use, live, live, tx, visit]   \n",
       "\n",
       "                                              phrase2vec  \n",
       "0      [-0.2121582, -0.004272461, 0.06976318, 0.35888...  \n",
       "1      [0.02561442, 0.022299448, 0.045491535, 0.04935...  \n",
       "2      [0.05505371, -0.0052217757, 0.05345481, 0.1639...  \n",
       "3      [-0.053726196, 0.058654785, 0.15679932, 0.2163...  \n",
       "4      [0.05214844, 0.03173828, 0.09024353, 0.0959961...  \n",
       "...                                                  ...  \n",
       "41502  [0.023242187, -0.06225586, -0.018005371, 0.217...  \n",
       "41503  [-0.059326172, 0.030419922, -0.070410155, 0.06...  \n",
       "41504  [-0.068359375, 0.21289062, 0.12904866, 0.14469...  \n",
       "41505  [0.0022521974, 0.013061523, 0.10640259, 0.1460...  \n",
       "41506  [0.007847377, -0.04910714, -0.015775409, 0.202...  \n",
       "\n",
       "[41507 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr2vec = []\n",
    "for phrase in lemmas:\n",
    "    if len(phrase) == 0:\n",
    "        continue\n",
    "    mean_vect = word2vec_model.get_mean_vector(keys = phrase, pre_normalize = False)\n",
    "    phr2vec.append({\n",
    "        'phrase': phrase,\n",
    "        'phrase2vec': mean_vect,\n",
    "    })\n",
    "\n",
    "df3 = pd.DataFrame(phr2vec)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding Contextuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/envs/gym_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-05 11:22:55.119922: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-05 11:22:55.760550: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-05 11:22:55.763180: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 11:22:57.326623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "\n",
    "tokens = get_document(df_tokens['token'].tolist())\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "embeddings = []\n",
    "i = 0\n",
    "for phrase in tokens:\n",
    "    words = tokenizer(phrase, return_tensors='pt')\n",
    "    # feed to the embedding layer to get the embdeddings for each token\n",
    "    token_embd = model(**words)\n",
    "    embedding = token_embd.last_hidden_state\n",
    "    # sum up all the tokens embedding to get the phrase embedding\n",
    "    phrase_embd = embedding.mean(dim = 1)\n",
    "    embeddings.append(phrase_embd)\n",
    "    i +=1 \n",
    "    if i == 64:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embeddings = torch.cat(embeddings, dim = 0)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dataframe with lemmes and pos and label :\n",
    "\n",
    "pos = get_document(df_tokens['pos'].tolist())\n",
    "pos = [doc.split() for doc in pos]\n",
    "labels = df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cook microwave pizza yummy</td>\n",
       "      <td>[VBG, NN, NN, NN]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plan allow sub task show widget</td>\n",
       "      <td>[NNS, VBG, NN, NNS, VBP, VB]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love humor reword like say group therapy inste...</td>\n",
       "      <td>[VB, NN, VBN, IN, VBG, NN, NN, RB, VBD, VBG, N...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naw idk ur talkin</td>\n",
       "      <td>[JJ, NN, JJ, NN]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suck hear hate day like</td>\n",
       "      <td>[NNS, VBP, JJ, NNS, IN]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41502</th>\n",
       "      <td>fuck internet damn time warner</td>\n",
       "      <td>[JJ, NN, NN, NN, NN]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41503</th>\n",
       "      <td>look forward android 15 push g1</td>\n",
       "      <td>[VBG, RB, JJ, CD, VBD, NN]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41504</th>\n",
       "      <td>good waste time</td>\n",
       "      <td>[JJ, VBD, NN]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41505</th>\n",
       "      <td>u great always east germany noko least provoke...</td>\n",
       "      <td>[JJ, JJ, RB, VBP, JJ, RB, JJS, JJ, VBP, CD, NN]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41506</th>\n",
       "      <td>love dessert use live live tx visit</td>\n",
       "      <td>[NN, NNS, VBD, JJ, JJ, NN, NN]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41507 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                             cook microwave pizza yummy   \n",
       "1                        plan allow sub task show widget   \n",
       "2      love humor reword like say group therapy inste...   \n",
       "3                                      naw idk ur talkin   \n",
       "4                                suck hear hate day like   \n",
       "...                                                  ...   \n",
       "41502                     fuck internet damn time warner   \n",
       "41503                    look forward android 15 push g1   \n",
       "41504                                    good waste time   \n",
       "41505  u great always east germany noko least provoke...   \n",
       "41506                love dessert use live live tx visit   \n",
       "\n",
       "                                                     pos  label  \n",
       "0                                      [VBG, NN, NN, NN]      2  \n",
       "1                           [NNS, VBG, NN, NNS, VBP, VB]      1  \n",
       "2      [VB, NN, VBN, IN, VBG, NN, NN, RB, VBD, VBG, N...      2  \n",
       "3                                       [JJ, NN, JJ, NN]      1  \n",
       "4                                [NNS, VBP, JJ, NNS, IN]      0  \n",
       "...                                                  ...    ...  \n",
       "41502                               [JJ, NN, NN, NN, NN]      0  \n",
       "41503                         [VBG, RB, JJ, CD, VBD, NN]      1  \n",
       "41504                                      [JJ, VBD, NN]      0  \n",
       "41505    [JJ, JJ, RB, VBP, JJ, RB, JJS, JJ, VBP, CD, NN]      2  \n",
       "41506                     [NN, NNS, VBD, JJ, JJ, NN, NN]      2  \n",
       "\n",
       "[41507 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.DataFrame(data = [(doc, p, label) for doc, p, label in zip(documents, pos, labels)], columns= ['text', 'pos', 'label'])\n",
    "corpus = corpus[corpus['text'] != '']\n",
    "corpus = corpus.reset_index(drop= True)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "all_pos_tags = list(set(pos for tag in corpus['pos'] for pos in tag))\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, categories=[all_pos_tags])\n",
    "\n",
    "pos_vectors = []\n",
    "for tags in corpus['pos']:\n",
    "    pos_vectors.append(np.sum(one_hot_encoder.fit_transform([[tag] for tag in tags]), axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_pos = pd.DataFrame(pos_vectors, columns= all_pos_tags)\n",
    "# df_pos['text'] = corpus['text']\n",
    "# df_pos['label'] = corpus['label']\n",
    "\n",
    "# df_pos = df_pos[[\"text\"] + all_pos_tags + [\"label\"]]\n",
    "# df_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase d'entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Y'] = corpus['label']\n",
    "final_dataset = df3.drop(columns='phrase')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase2vec</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.2121582, -0.004272461, 0.06976318, 0.35888...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.02561442, 0.022299448, 0.045491535, 0.04935...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.05505371, -0.0052217757, 0.05345481, 0.1639...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.053726196, 0.058654785, 0.15679932, 0.2163...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.05214844, 0.03173828, 0.09024353, 0.0959961...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41502</th>\n",
       "      <td>[0.023242187, -0.06225586, -0.018005371, 0.217...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41503</th>\n",
       "      <td>[-0.059326172, 0.030419922, -0.070410155, 0.06...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41504</th>\n",
       "      <td>[-0.068359375, 0.21289062, 0.12904866, 0.14469...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41505</th>\n",
       "      <td>[0.0022521974, 0.013061523, 0.10640259, 0.1460...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41506</th>\n",
       "      <td>[0.007847377, -0.04910714, -0.015775409, 0.202...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41507 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase2vec  Y\n",
       "0      [-0.2121582, -0.004272461, 0.06976318, 0.35888...  2\n",
       "1      [0.02561442, 0.022299448, 0.045491535, 0.04935...  1\n",
       "2      [0.05505371, -0.0052217757, 0.05345481, 0.1639...  2\n",
       "3      [-0.053726196, 0.058654785, 0.15679932, 0.2163...  1\n",
       "4      [0.05214844, 0.03173828, 0.09024353, 0.0959961...  0\n",
       "...                                                  ... ..\n",
       "41502  [0.023242187, -0.06225586, -0.018005371, 0.217...  0\n",
       "41503  [-0.059326172, 0.030419922, -0.070410155, 0.06...  1\n",
       "41504  [-0.068359375, 0.21289062, 0.12904866, 0.14469...  0\n",
       "41505  [0.0022521974, 0.013061523, 0.10640259, 0.1460...  2\n",
       "41506  [0.007847377, -0.04910714, -0.015775409, 0.202...  2\n",
       "\n",
       "[41507 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = final_dataset['phrase2vec']\n",
    "Y = final_dataset['Y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, train_size=0.7, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 300])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(x, y, batch_size = 16):\n",
    "    xb, yb = list(x[i:i+batch_size]), list(y[i:i+batch_size])\n",
    "    xb = torch.tensor(np.stack(xb, axis= 0), dtype= torch.float32)\n",
    "    yb = torch.tensor(np.stack(yb, axis= 0), dtype= torch.long)\n",
    "    return xb, yb\n",
    "\n",
    "xb, yb = get_batch(x_train, y_train)\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_size = 128, n_layers= 2):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers = n_layers, \n",
    "                            batch_first=True, dropout=0.3, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(n_layers * hidden_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (h1, c1) = self.lstm(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        logits = self.sigmoid(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0988742113113403\n",
      "1.0972639322280884\n",
      "1.0960090160369873\n",
      "1.0947126150131226\n",
      "1.092895746231079\n",
      "1.0903218984603882\n",
      "1.0868314504623413\n",
      "1.0826807022094727\n",
      "1.076998233795166\n",
      "1.074790120124817\n",
      "1.0757933855056763\n",
      "1.074370265007019\n",
      "1.072308897972107\n",
      "1.0689113140106201\n",
      "1.067621111869812\n",
      "1.0654664039611816\n",
      "1.0640716552734375\n",
      "1.0620238780975342\n",
      "1.0611436367034912\n",
      "1.0586857795715332\n",
      "1.0563926696777344\n",
      "1.0543276071548462\n",
      "1.051666259765625\n",
      "1.0506007671356201\n",
      "1.048697829246521\n",
      "1.0467835664749146\n",
      "1.0433210134506226\n",
      "1.0382575988769531\n",
      "1.034592628479004\n",
      "1.026778221130371\n",
      "1.022049069404602\n",
      "1.0159392356872559\n",
      "1.0073601007461548\n",
      "0.999229371547699\n",
      "0.9915934801101685\n",
      "0.9845032095909119\n",
      "0.9769010543823242\n",
      "0.9771125316619873\n",
      "0.9721494913101196\n",
      "0.9573929309844971\n",
      "0.9512853026390076\n",
      "0.9393582344055176\n",
      "0.922374963760376\n",
      "0.9046894907951355\n",
      "0.9010148048400879\n",
      "0.8898901343345642\n",
      "0.8706144094467163\n",
      "0.8566556572914124\n",
      "0.8334162831306458\n",
      "0.8224446177482605\n",
      "0.8105222582817078\n",
      "0.7821233868598938\n",
      "0.7741371393203735\n",
      "0.7739909887313843\n",
      "0.7504045367240906\n",
      "0.7549729347229004\n",
      "0.7399616837501526\n",
      "0.7210186719894409\n",
      "0.7053514719009399\n",
      "0.6972012519836426\n",
      "0.7005075812339783\n",
      "0.6934150457382202\n",
      "0.6920322179794312\n",
      "0.6806915998458862\n",
      "0.6817529797554016\n",
      "0.7006058096885681\n",
      "0.6689268350601196\n",
      "0.6646254658699036\n",
      "0.6780897378921509\n",
      "0.6611075401306152\n",
      "0.6663703918457031\n",
      "0.6576619148254395\n",
      "0.6568909883499146\n",
      "0.6574912071228027\n",
      "0.653721809387207\n",
      "0.6523941159248352\n",
      "0.6537071466445923\n",
      "0.6524912118911743\n",
      "0.6525196433067322\n",
      "0.6512486338615417\n",
      "0.6516002416610718\n",
      "0.651519238948822\n",
      "0.6503785848617554\n",
      "0.6499693393707275\n",
      "0.6502059698104858\n",
      "0.6500670313835144\n",
      "0.6503576636314392\n",
      "0.6496269106864929\n",
      "0.6498684883117676\n",
      "0.6495875716209412\n",
      "0.6491867303848267\n",
      "0.6496255397796631\n",
      "0.649470865726471\n",
      "0.6497819423675537\n",
      "0.6491022109985352\n",
      "0.6496188044548035\n",
      "0.6493322253227234\n",
      "0.6492254137992859\n",
      "0.6497254967689514\n",
      "0.6489982008934021\n",
      "0.6497961282730103\n",
      "0.6489576101303101\n",
      "0.649043619632721\n",
      "0.6489355564117432\n",
      "0.6488747000694275\n",
      "0.6489503979682922\n",
      "0.649120569229126\n",
      "0.6489435434341431\n",
      "0.6490760445594788\n",
      "0.6489527821540833\n",
      "0.6490472555160522\n",
      "0.6490265727043152\n",
      "0.6489284634590149\n",
      "0.6489493250846863\n",
      "0.6487303972244263\n",
      "0.6488294005393982\n",
      "0.6487537622451782\n",
      "0.6488295197486877\n",
      "0.6487752795219421\n",
      "0.6487677693367004\n",
      "0.6487364172935486\n",
      "0.648734986782074\n",
      "0.6487724781036377\n",
      "0.6488025188446045\n",
      "0.6488457918167114\n",
      "0.6487289071083069\n",
      "0.6487492918968201\n",
      "0.6487748622894287\n",
      "0.6488500833511353\n",
      "0.6488060355186462\n",
      "0.6487476229667664\n",
      "0.6487511992454529\n",
      "0.6487839818000793\n",
      "0.6487603187561035\n",
      "0.6487630605697632\n",
      "0.6487627029418945\n",
      "0.6486890912055969\n",
      "0.6486685872077942\n",
      "0.6487109065055847\n",
      "0.6486817002296448\n",
      "0.6487569212913513\n",
      "0.6486836671829224\n",
      "0.6487073302268982\n",
      "0.6486704349517822\n",
      "0.6486914157867432\n",
      "0.6486719250679016\n",
      "0.6486931443214417\n",
      "0.648767352104187\n",
      "0.6486524939537048\n",
      "0.6487232446670532\n",
      "0.6487985849380493\n",
      "0.6486971378326416\n",
      "0.6487004160881042\n",
      "0.648638904094696\n",
      "0.649262547492981\n",
      "0.648657500743866\n",
      "0.6486492156982422\n",
      "0.6486436724662781\n",
      "0.64862459897995\n",
      "0.6486814618110657\n",
      "0.6486227512359619\n",
      "0.6486200094223022\n",
      "0.648621141910553\n",
      "0.648851215839386\n",
      "0.6486842632293701\n",
      "0.6486859917640686\n",
      "0.6486384272575378\n",
      "0.6486359238624573\n",
      "0.6488620042800903\n",
      "0.6486464142799377\n",
      "0.6486838459968567\n",
      "0.6486791372299194\n",
      "0.6486151814460754\n",
      "0.6486563086509705\n",
      "0.6486914753913879\n",
      "0.6486086249351501\n",
      "0.648655354976654\n",
      "0.6486155390739441\n",
      "0.6486184000968933\n",
      "0.6486150622367859\n",
      "0.6486068964004517\n",
      "0.6486351490020752\n",
      "0.6486178636550903\n",
      "0.648754358291626\n",
      "0.6486778855323792\n",
      "0.6486508846282959\n",
      "0.6485964059829712\n",
      "0.648612380027771\n",
      "0.6486216187477112\n",
      "0.648566722869873\n",
      "0.648678183555603\n",
      "0.6486288905143738\n",
      "0.6485934257507324\n",
      "0.6486098170280457\n",
      "0.6485854387283325\n",
      "0.6485782265663147\n",
      "0.6486180424690247\n",
      "0.6487441658973694\n",
      "0.6486002206802368\n",
      "0.6485705971717834\n",
      "0.6485846638679504\n",
      "0.648615300655365\n",
      "0.6485770344734192\n",
      "0.6486111879348755\n",
      "0.648587167263031\n",
      "0.648601770401001\n",
      "0.6485794186592102\n",
      "0.6485745906829834\n",
      "0.6486002206802368\n",
      "0.6485896110534668\n",
      "0.64854896068573\n",
      "0.6485568881034851\n",
      "0.648614227771759\n",
      "0.6485812664031982\n",
      "0.6486170887947083\n",
      "0.6485768556594849\n",
      "0.6485612988471985\n",
      "0.6485724449157715\n",
      "0.6485753655433655\n",
      "0.6485763788223267\n",
      "0.6485849618911743\n",
      "0.6485694646835327\n",
      "0.648573100566864\n",
      "0.6485662460327148\n",
      "0.6485507488250732\n",
      "0.6485711336135864\n",
      "0.6485758423805237\n",
      "0.648562490940094\n",
      "0.6485806703567505\n",
      "0.648603618144989\n",
      "0.6485373377799988\n",
      "0.6485825777053833\n",
      "0.6486185193061829\n",
      "0.6485705375671387\n",
      "0.6486388444900513\n",
      "0.6487916111946106\n",
      "0.6485579609870911\n",
      "0.6485674381256104\n",
      "0.6485517621040344\n",
      "0.6485540866851807\n",
      "0.6485639810562134\n",
      "0.6485599875450134\n",
      "0.6485714912414551\n",
      "0.6485565304756165\n",
      "0.6485543847084045\n",
      "0.6485710740089417\n",
      "0.6485471129417419\n",
      "0.64853835105896\n",
      "0.6485316753387451\n",
      "0.6485520601272583\n",
      "0.6485472321510315\n",
      "0.6485482454299927\n",
      "0.6485517621040344\n",
      "0.648561418056488\n",
      "0.6485316753387451\n",
      "0.6485503315925598\n",
      "0.6485408544540405\n",
      "0.6485531330108643\n",
      "0.648536205291748\n",
      "0.6485437750816345\n",
      "0.6485471725463867\n",
      "0.648530900478363\n",
      "0.6485430598258972\n",
      "0.6485519409179688\n",
      "0.6485320925712585\n",
      "0.6485286951065063\n",
      "0.6485366225242615\n",
      "0.6485512256622314\n",
      "0.6485375761985779\n",
      "0.6485371589660645\n",
      "0.6485289931297302\n",
      "0.648541271686554\n",
      "0.6485514640808105\n",
      "0.6485560536384583\n",
      "0.6485233902931213\n",
      "0.648543655872345\n",
      "0.6485653519630432\n",
      "0.6485283374786377\n",
      "0.6485316753387451\n",
      "0.6485304236412048\n",
      "0.6485337615013123\n",
      "0.6485207080841064\n",
      "0.6485342383384705\n",
      "0.6485192775726318\n",
      "0.6485375165939331\n",
      "0.6485280990600586\n",
      "0.6485358476638794\n",
      "0.6485288739204407\n",
      "0.6485159993171692\n",
      "0.648527979850769\n",
      "0.6485360264778137\n",
      "0.6485363841056824\n",
      "0.6485198140144348\n",
      "0.6486547589302063\n",
      "0.6485213041305542\n",
      "0.648542046546936\n",
      "0.6485209465026855\n",
      "0.6485156416893005\n",
      "0.6485216617584229\n",
      "0.6485187411308289\n",
      "0.6485264897346497\n",
      "0.648560106754303\n",
      "0.6485153436660767\n",
      "0.6485257148742676\n",
      "0.648523211479187\n",
      "0.6485207080841064\n",
      "0.6485133767127991\n",
      "0.6485216617584229\n",
      "0.6485233902931213\n",
      "0.6485185623168945\n",
      "0.6485202312469482\n",
      "0.6485117673873901\n",
      "0.6485195755958557\n",
      "0.648516833782196\n",
      "0.6485161185264587\n",
      "0.6485364437103271\n",
      "0.6485283374786377\n",
      "0.6485164165496826\n",
      "0.6485377550125122\n",
      "0.6485205292701721\n",
      "0.6485203504562378\n",
      "0.6485097408294678\n",
      "0.6485216021537781\n",
      "0.6485254168510437\n",
      "0.6485142707824707\n",
      "0.64851975440979\n",
      "0.6485127806663513\n",
      "0.6485192179679871\n",
      "0.6485141515731812\n",
      "0.6485320329666138\n",
      "0.6485121846199036\n",
      "0.6485118269920349\n",
      "0.648532509803772\n",
      "0.6485282182693481\n",
      "0.6485239267349243\n",
      "0.6485142707824707\n",
      "0.6485146284103394\n",
      "0.6485211253166199\n",
      "0.6485138535499573\n",
      "0.6485163569450378\n",
      "0.6485243439674377\n",
      "0.6485211849212646\n",
      "0.6485084295272827\n",
      "0.6485177874565125\n",
      "0.6485065221786499\n",
      "0.648506760597229\n",
      "0.6485188603401184\n",
      "0.6485327482223511\n",
      "0.648523211479187\n",
      "0.6485090851783752\n",
      "0.6485037207603455\n",
      "0.6485047936439514\n",
      "0.6485125422477722\n",
      "0.6485133171081543\n",
      "0.6485088467597961\n",
      "0.6485074758529663\n",
      "0.64851313829422\n",
      "0.6485145092010498\n",
      "0.6485236287117004\n",
      "0.6485116481781006\n",
      "0.6485059857368469\n",
      "0.6485195159912109\n",
      "0.6485071778297424\n",
      "0.6485110521316528\n",
      "0.6485047340393066\n",
      "0.6485481858253479\n",
      "0.6485102772712708\n",
      "0.6485021114349365\n",
      "0.6485121846199036\n",
      "0.648505449295044\n",
      "0.6485053896903992\n",
      "0.6485114097595215\n",
      "0.6485092639923096\n",
      "0.6485015749931335\n",
      "0.6485044360160828\n",
      "0.648510217666626\n",
      "0.6485113501548767\n",
      "0.6485028862953186\n",
      "0.6485114693641663\n",
      "0.6485068202018738\n",
      "0.6485083103179932\n",
      "0.6485052704811096\n",
      "0.6485079526901245\n",
      "0.6485012769699097\n",
      "0.6485016345977783\n",
      "0.6485069990158081\n",
      "0.6485454440116882\n",
      "0.6485042572021484\n",
      "0.6485045552253723\n",
      "0.6485145688056946\n",
      "0.6485360860824585\n",
      "0.6485005617141724\n",
      "0.6485041379928589\n",
      "0.6485071182250977\n",
      "0.6485093235969543\n",
      "0.6485190987586975\n",
      "0.6485052108764648\n",
      "0.6484999060630798\n",
      "0.6485191583633423\n",
      "0.6485090851783752\n",
      "0.64850252866745\n",
      "0.6485037207603455\n",
      "0.6485028862953186\n",
      "0.6485010385513306\n",
      "0.648504376411438\n",
      "0.6485098600387573\n",
      "0.6484997868537903\n",
      "0.6485068798065186\n",
      "0.6485041379928589\n",
      "0.6485474705696106\n",
      "0.6485019326210022\n",
      "0.6485055088996887\n",
      "0.6485064029693604\n",
      "0.6484994292259216\n",
      "0.6484997868537903\n",
      "0.6485012173652649\n",
      "0.6485012173652649\n",
      "0.648500919342041\n",
      "0.648500382900238\n",
      "0.648499608039856\n",
      "0.648503303527832\n",
      "0.6484983563423157\n",
      "0.6485092043876648\n",
      "0.6485040783882141\n",
      "0.6485013365745544\n",
      "0.6485012769699097\n",
      "0.6485027074813843\n",
      "0.648499071598053\n",
      "0.6485052704811096\n",
      "0.6484997868537903\n",
      "0.6485010981559753\n",
      "0.6485047936439514\n",
      "0.6485024094581604\n",
      "0.6485148072242737\n",
      "0.6485034227371216\n",
      "0.6485002040863037\n",
      "0.6484989523887634\n",
      "0.6485021710395813\n",
      "0.6485053300857544\n",
      "0.6485193967819214\n",
      "0.648499608039856\n",
      "0.6485034823417664\n",
      "0.6484994292259216\n",
      "0.648499608039856\n",
      "0.6484985947608948\n",
      "0.648501992225647\n",
      "0.6485040187835693\n",
      "0.6484974026679993\n",
      "0.6485031843185425\n",
      "0.6484997868537903\n",
      "0.6484991908073425\n",
      "0.6484976410865784\n",
      "0.6485006213188171\n",
      "0.648499608039856\n",
      "0.6484998464584351\n",
      "0.6484994292259216\n",
      "0.6484991312026978\n",
      "0.6484974026679993\n",
      "0.6485032439231873\n",
      "0.6485044956207275\n",
      "0.648505449295044\n",
      "0.6484994888305664\n",
      "0.648499071598053\n",
      "0.6484976410865784\n",
      "0.6484972834587097\n",
      "0.6484968662261963\n",
      "0.6484962701797485\n",
      "0.6484981775283813\n",
      "0.6484989523887634\n",
      "0.6484995484352112\n",
      "0.6484991908073425\n",
      "0.6484987139701843\n",
      "0.6484979391098022\n",
      "0.6485025882720947\n",
      "0.6485069394111633\n",
      "0.6484968662261963\n",
      "0.6484996676445007\n",
      "0.6484970450401306\n",
      "0.6484976410865784\n",
      "0.6484976410865784\n",
      "0.6485022306442261\n",
      "0.6484964489936829\n",
      "0.648499071598053\n",
      "0.6484987735748291\n",
      "0.6485004425048828\n",
      "0.6484997868537903\n",
      "0.6484969258308411\n",
      "0.6485040187835693\n",
      "0.6485043168067932\n",
      "0.6485137343406677\n",
      "0.6484982967376709\n",
      "0.6484968066215515\n",
      "0.648495614528656\n",
      "0.648497998714447\n",
      "0.6485007405281067\n",
      "0.6484984159469604\n",
      "0.6485124230384827\n",
      "0.6484992504119873\n",
      "0.648496687412262\n",
      "0.6484994292259216\n",
      "0.6484982371330261\n",
      "0.6485013961791992\n",
      "0.6484992504119873\n",
      "0.6484994292259216\n",
      "0.6484968662261963\n",
      "0.6484974026679993\n",
      "0.6484994292259216\n",
      "0.6485000848770142\n",
      "0.6484971046447754\n",
      "0.6484994292259216\n",
      "0.6484984755516052\n",
      "0.6485011577606201\n",
      "0.6484979391098022\n",
      "0.6484969258308411\n",
      "0.6485065817832947\n",
      "0.6484972834587097\n",
      "0.6484999060630798\n",
      "0.6484984755516052\n",
      "0.648496687412262\n",
      "0.6484960317611694\n",
      "0.6484984755516052\n",
      "0.6484967470169067\n",
      "0.6485000848770142\n",
      "0.6485016942024231\n",
      "0.6484952569007874\n",
      "0.648496687412262\n",
      "0.6484967470169067\n",
      "0.6484969854354858\n",
      "0.6484957933425903\n",
      "0.6484955549240112\n",
      "0.6484978795051575\n",
      "0.6484993696212769\n",
      "0.648504912853241\n",
      "0.6484972238540649\n",
      "0.648496687412262\n",
      "0.6484981179237366\n",
      "0.6484957933425903\n",
      "0.6484987139701843\n",
      "0.6484941840171814\n",
      "0.6484956741333008\n",
      "0.6484982371330261\n",
      "0.6484964489936829\n",
      "0.6484968662261963\n",
      "0.6484976410865784\n",
      "0.6484965085983276\n",
      "0.6484968662261963\n",
      "0.6484951972961426\n",
      "0.6484960913658142\n",
      "0.6484957933425903\n",
      "0.6484965682029724\n",
      "0.6484962105751038\n",
      "0.648495614528656\n",
      "0.6484948396682739\n",
      "0.6484951376914978\n",
      "0.6485000252723694\n",
      "0.6484955549240112\n",
      "0.648496687412262\n",
      "0.6484954357147217\n",
      "0.6484951376914978\n",
      "0.6484957933425903\n",
      "0.6484972834587097\n",
      "0.6484944820404053\n",
      "0.6484953761100769\n",
      "0.6485033631324768\n",
      "0.6484950184822083\n",
      "0.6484976410865784\n",
      "0.648495078086853\n",
      "0.6484957337379456\n",
      "0.6484969854354858\n",
      "0.6484951972961426\n",
      "0.6484956741333008\n",
      "0.6485067009925842\n",
      "0.6484965682029724\n",
      "0.6484960913658142\n",
      "0.6484982371330261\n",
      "0.6485008597373962\n",
      "0.6484978199005127\n",
      "0.648496150970459\n",
      "0.648510217666626\n",
      "0.6484967470169067\n",
      "0.6484953761100769\n",
      "0.648496687412262\n",
      "0.6484951376914978\n",
      "0.648495078086853\n",
      "0.6484959721565247\n",
      "0.6484963297843933\n",
      "0.6484951376914978\n",
      "0.648506224155426\n",
      "0.6484965682029724\n",
      "0.6484940648078918\n",
      "0.648496150970459\n",
      "0.6484943628311157\n",
      "0.6484956741333008\n",
      "0.6484999060630798\n",
      "0.6484951972961426\n",
      "0.64849853515625\n",
      "0.6484954953193665\n",
      "0.648494303226471\n",
      "0.6484939455986023\n",
      "0.6484974026679993\n",
      "0.6484994888305664\n",
      "0.6484946608543396\n",
      "0.6484968066215515\n",
      "0.6484952569007874\n",
      "0.6484949588775635\n",
      "0.6484948396682739\n",
      "0.6484955549240112\n",
      "0.6484959125518799\n",
      "0.6484970450401306\n",
      "0.6484949588775635\n",
      "0.6484959125518799\n",
      "0.6484940648078918\n",
      "0.648495078086853\n",
      "0.6484955549240112\n",
      "0.648497462272644\n",
      "0.6484996676445007\n",
      "0.6484948992729187\n",
      "0.6484947204589844\n",
      "0.6484984159469604\n",
      "0.6484964489936829\n",
      "0.6484939455986023\n",
      "0.6485289931297302\n",
      "0.6484951376914978\n",
      "0.6484962105751038\n",
      "0.648495078086853\n",
      "0.6484954357147217\n",
      "0.648494303226471\n",
      "0.648493766784668\n",
      "0.6484937071800232\n",
      "0.6484953165054321\n",
      "0.6484951376914978\n",
      "0.6484956741333008\n",
      "0.6484965682029724\n",
      "0.6484936475753784\n",
      "0.6484938859939575\n",
      "0.648493230342865\n",
      "0.6484946608543396\n",
      "0.6484970450401306\n",
      "0.6484975218772888\n",
      "0.6485012769699097\n",
      "0.6484948396682739\n",
      "0.6484947204589844\n",
      "0.648496150970459\n",
      "0.6484975218772888\n",
      "0.6484960317611694\n",
      "0.6484942436218262\n",
      "0.648495078086853\n",
      "0.6484947204589844\n",
      "0.6484932899475098\n",
      "0.6484946012496948\n",
      "0.6484960913658142\n",
      "0.6484977006912231\n",
      "0.6485005617141724\n",
      "0.648493230342865\n",
      "0.648493766784668\n",
      "0.6484940052032471\n",
      "0.64849454164505\n",
      "0.6484951972961426\n",
      "0.6484932899475098\n",
      "0.6484978795051575\n",
      "0.6484954357147217\n",
      "0.6484943628311157\n",
      "0.6484954953193665\n",
      "0.6484938263893127\n",
      "0.6484941244125366\n",
      "0.6484935879707336\n",
      "0.6484972834587097\n",
      "0.6484948992729187\n",
      "0.6484944820404053\n",
      "0.6484949588775635\n",
      "0.6484930515289307\n",
      "0.6484932899475098\n",
      "0.6484936475753784\n",
      "0.6484943628311157\n",
      "0.6484944820404053\n",
      "0.6484933495521545\n",
      "0.6484934091567993\n",
      "0.6484940052032471\n",
      "0.6484940648078918\n",
      "0.6484965085983276\n",
      "0.6484935879707336\n",
      "0.6484941840171814\n",
      "0.6484934687614441\n",
      "0.6484952569007874\n",
      "0.6484940052032471\n",
      "0.6484934091567993\n",
      "0.648493766784668\n",
      "0.6484941244125366\n",
      "0.6484946608543396\n",
      "0.6484946608543396\n",
      "0.6484931707382202\n",
      "0.6484929919242859\n",
      "0.6484941840171814\n",
      "0.6484928727149963\n",
      "0.6484931707382202\n",
      "0.6484940052032471\n",
      "0.6484949588775635\n",
      "0.6484944820404053\n",
      "0.6484931707382202\n",
      "0.648494303226471\n",
      "0.6484975218772888\n",
      "0.6484930515289307\n",
      "0.6484934091567993\n",
      "0.6484951972961426\n",
      "0.6484959721565247\n",
      "0.6484960317611694\n",
      "0.6484947800636292\n",
      "0.6484930515289307\n",
      "0.6484933495521545\n",
      "0.648494303226471\n",
      "0.6484936475753784\n",
      "0.648492693901062\n",
      "0.6484934687614441\n",
      "0.6484941244125366\n",
      "0.648496150970459\n",
      "0.6484940648078918\n",
      "0.6484934091567993\n",
      "0.6484935283660889\n",
      "0.6484934687614441\n",
      "0.6484928131103516\n",
      "0.6484947800636292\n",
      "0.6484929919242859\n",
      "0.6484932899475098\n",
      "0.6484941840171814\n",
      "0.6484931111335754\n",
      "0.6484929323196411\n",
      "0.6484937071800232\n",
      "0.6484963893890381\n",
      "0.6484930515289307\n",
      "0.6484931111335754\n",
      "0.6484932899475098\n",
      "0.6484929919242859\n",
      "0.64849454164505\n",
      "0.6484929323196411\n",
      "0.6484941840171814\n",
      "0.6484929323196411\n",
      "0.648493230342865\n",
      "0.6484941244125366\n",
      "0.6484936475753784\n",
      "0.6484939455986023\n",
      "0.6484977006912231\n",
      "0.6484963297843933\n",
      "0.648493766784668\n",
      "0.6484932899475098\n",
      "0.6484934687614441\n",
      "0.6484934687614441\n",
      "0.6484926342964172\n",
      "0.6484928727149963\n",
      "0.6484927535057068\n",
      "0.6484928131103516\n",
      "0.6484940052032471\n",
      "0.6484929919242859\n",
      "0.6484936475753784\n",
      "0.6484925746917725\n",
      "0.6484934091567993\n",
      "0.6484948992729187\n",
      "0.6484925746917725\n",
      "0.6485011577606201\n",
      "0.6484924554824829\n",
      "0.6484928131103516\n",
      "0.6484931707382202\n",
      "0.648624062538147\n",
      "0.6484992504119873\n",
      "0.6484933495521545\n",
      "0.6484963297843933\n",
      "0.6484929323196411\n",
      "0.6484938859939575\n",
      "0.6484972834587097\n",
      "0.6485328674316406\n",
      "0.6484982371330261\n",
      "0.6484941244125366\n",
      "0.6484943628311157\n",
      "0.6484942436218262\n",
      "0.6484972238540649\n",
      "0.6484931707382202\n",
      "0.6484988331794739\n",
      "0.6484957337379456\n",
      "0.6484948992729187\n",
      "0.648493766784668\n",
      "0.6484934091567993\n",
      "0.6484944224357605\n",
      "0.648495078086853\n",
      "0.6484968662261963\n",
      "0.6485022902488708\n",
      "0.6484939455986023\n",
      "0.6484948396682739\n",
      "0.6484942436218262\n",
      "0.6484947204589844\n",
      "0.6484932899475098\n",
      "0.6484940052032471\n",
      "0.6485145092010498\n",
      "0.6484976410865784\n",
      "0.6484927535057068\n",
      "0.6484928131103516\n",
      "0.6484934687614441\n",
      "0.6484928727149963\n",
      "0.6484952569007874\n",
      "0.648493766784668\n",
      "0.6484929323196411\n",
      "0.6484934091567993\n",
      "0.6484930515289307\n",
      "0.6484941244125366\n",
      "0.6484925150871277\n",
      "0.6484929323196411\n",
      "0.6484925150871277\n",
      "0.6484936475753784\n",
      "0.6484925150871277\n",
      "0.6484928131103516\n",
      "0.6484928131103516\n",
      "0.6484925150871277\n",
      "0.6484930515289307\n",
      "0.6484959721565247\n",
      "0.6484923958778381\n",
      "0.6484934091567993\n",
      "0.648492693901062\n",
      "0.6484924554824829\n",
      "0.6484944820404053\n",
      "0.6484929323196411\n",
      "0.6484929323196411\n",
      "0.6484926342964172\n",
      "0.6484960317611694\n",
      "0.6484928131103516\n",
      "0.6484931707382202\n",
      "0.6484933495521545\n",
      "0.648499071598053\n",
      "0.648492693901062\n",
      "0.6484929919242859\n",
      "0.6484934091567993\n",
      "0.648492693901062\n",
      "0.6484930515289307\n",
      "0.648492693901062\n",
      "0.648492693901062\n",
      "0.6484930515289307\n",
      "0.6484931707382202\n",
      "0.6484923362731934\n",
      "0.6484923362731934\n",
      "0.6484932899475098\n",
      "0.6484923362731934\n",
      "0.6484942436218262\n",
      "0.6484931707382202\n",
      "0.6484931707382202\n",
      "0.6484943628311157\n",
      "0.6484923362731934\n",
      "0.6484922170639038\n",
      "0.6484928131103516\n",
      "0.6484934091567993\n",
      "0.6484931111335754\n",
      "0.6484977602958679\n",
      "0.6484929323196411\n",
      "0.6484930515289307\n",
      "0.6484923362731934\n",
      "0.648492693901062\n",
      "0.6484922170639038\n",
      "0.6484926342964172\n",
      "0.6484933495521545\n",
      "0.6484955549240112\n",
      "0.6484923362731934\n",
      "0.6484938859939575\n",
      "0.6484925746917725\n",
      "0.6484934091567993\n",
      "0.6484924554824829\n",
      "0.6484927535057068\n",
      "0.6484960317611694\n",
      "0.6484924554824829\n",
      "0.648492693901062\n",
      "0.6484929323196411\n",
      "0.6484923362731934\n",
      "0.6484947204589844\n",
      "0.6484925150871277\n",
      "0.6484939455986023\n",
      "0.6484935283660889\n",
      "0.6484933495521545\n",
      "0.6484936475753784\n",
      "0.6484930515289307\n",
      "0.6484922170639038\n",
      "0.6484926342964172\n",
      "0.648493766784668\n",
      "0.6484942436218262\n",
      "0.6484929323196411\n",
      "0.6484925150871277\n",
      "0.6484925746917725\n",
      "0.6484930515289307\n",
      "0.6484923362731934\n",
      "0.6484929323196411\n",
      "0.648492693901062\n",
      "0.6484929323196411\n",
      "0.6484935283660889\n",
      "0.6484934687614441\n",
      "0.6484920978546143\n",
      "0.6484934091567993\n",
      "0.6484923362731934\n",
      "0.648492693901062\n",
      "0.6484928727149963\n",
      "0.6484923362731934\n",
      "0.6484922170639038\n",
      "0.6484924554824829\n",
      "0.6484925746917725\n",
      "0.6484932899475098\n",
      "0.6484923362731934\n",
      "0.648492693901062\n",
      "0.6484933495521545\n",
      "0.648493766784668\n",
      "0.6484931707382202\n",
      "0.648493230342865\n",
      "0.6484923362731934\n",
      "0.6484923362731934\n",
      "0.6484936475753784\n",
      "0.6484928131103516\n",
      "0.6484923362731934\n",
      "0.6484925746917725\n",
      "0.6484920978546143\n",
      "0.6484924554824829\n",
      "0.6484929323196411\n",
      "0.6484923362731934\n",
      "0.6484923362731934\n",
      "0.6484963893890381\n",
      "0.6484929323196411\n",
      "0.6484924554824829\n",
      "0.6484922766685486\n",
      "0.6484931111335754\n",
      "0.6484929323196411\n",
      "0.648492157459259\n",
      "0.6484926342964172\n",
      "0.6484924554824829\n",
      "0.6484928131103516\n",
      "0.6484922170639038\n",
      "0.6484920978546143\n",
      "0.6484936475753784\n",
      "0.6484925150871277\n",
      "0.6484923362731934\n",
      "0.648492157459259\n",
      "0.6484924554824829\n",
      "0.6484923362731934\n",
      "0.6484931707382202\n",
      "0.6484948396682739\n",
      "0.6484922170639038\n",
      "0.6484923362731934\n",
      "0.6484925150871277\n",
      "0.6484924554824829\n",
      "0.6484922170639038\n",
      "0.6484925746917725\n",
      "0.6484925746917725\n",
      "0.6484923958778381\n",
      "0.6484922170639038\n",
      "0.6485000848770142\n",
      "0.648494303226471\n",
      "0.6484993696212769\n",
      "0.6484922170639038\n",
      "0.6484923362731934\n",
      "0.6484922170639038\n",
      "0.6484936475753784\n",
      "0.6484922170639038\n",
      "0.6484935283660889\n",
      "0.6484920978546143\n",
      "0.6484935283660889\n",
      "0.6484922766685486\n",
      "0.648492693901062\n",
      "0.648492693901062\n",
      "0.6484941244125366\n",
      "0.6484924554824829\n",
      "0.6484927535057068\n",
      "0.6484925746917725\n",
      "0.6484923362731934\n",
      "0.6484924554824829\n",
      "0.6484924554824829\n",
      "0.6484928131103516\n",
      "0.648492693901062\n",
      "0.6484924554824829\n",
      "0.6484928131103516\n",
      "0.6484920978546143\n",
      "0.6484920978546143\n",
      "0.6484923362731934\n",
      "0.6484920978546143\n",
      "0.6484927535057068\n",
      "0.6484923362731934\n",
      "0.6484923362731934\n",
      "0.6484925746917725\n",
      "0.648492157459259\n",
      "0.6484922170639038\n",
      "0.648492693901062\n",
      "0.6484923958778381\n",
      "0.6484919786453247\n",
      "0.6484931707382202\n",
      "0.6484922170639038\n",
      "0.6484926342964172\n",
      "0.6484922766685486\n",
      "0.6484923958778381\n",
      "0.6484924554824829\n",
      "0.6484932899475098\n",
      "0.6484922170639038\n",
      "0.6484923362731934\n",
      "0.6484922170639038\n",
      "0.6484923362731934\n",
      "0.6484922170639038\n",
      "0.6484920978546143\n",
      "0.6484923362731934\n",
      "0.6484922170639038\n",
      "0.6484935879707336\n",
      "0.6484923362731934\n",
      "0.648493230342865\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch(x_train, y_train, batch_size= 32)\n",
    "model = Model(embed_dim=xb.size(1))\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad(set_to_none=False)\n",
    "    # forward pass\n",
    "    logits = model(xb)\n",
    "    loss = F.cross_entropy(logits, yb)\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # update the gradient\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
