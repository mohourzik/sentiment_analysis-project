{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9536</td>\n",
       "      <td>Cooking microwave pizzas, yummy</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6135</td>\n",
       "      <td>Any plans of allowing sub tasks to show up in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17697</td>\n",
       "      <td>I love the humor, I just reworded it. Like sa...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14182</td>\n",
       "      <td>naw idk what ur talkin about</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17840</td>\n",
       "      <td>That sucks to hear. I hate days like that</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41639</th>\n",
       "      <td>10277</td>\n",
       "      <td>Fuck no internet damn time warner!</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41640</th>\n",
       "      <td>8610</td>\n",
       "      <td>Looking forward to android 1.5 being pushed t...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41641</th>\n",
       "      <td>8114</td>\n",
       "      <td>Not good. Wasted time.</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41642</th>\n",
       "      <td>3034</td>\n",
       "      <td>U were great, as always. But, can`t we do an ...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41643</th>\n",
       "      <td>11601</td>\n",
       "      <td>- Love your desserts. Used to live in OR but ...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41644 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  label  \\\n",
       "0       9536                    Cooking microwave pizzas, yummy      2   \n",
       "1       6135  Any plans of allowing sub tasks to show up in ...      1   \n",
       "2      17697   I love the humor, I just reworded it. Like sa...      2   \n",
       "3      14182                       naw idk what ur talkin about      1   \n",
       "4      17840          That sucks to hear. I hate days like that      0   \n",
       "...      ...                                                ...    ...   \n",
       "41639  10277                 Fuck no internet damn time warner!      0   \n",
       "41640   8610   Looking forward to android 1.5 being pushed t...      1   \n",
       "41641   8114                             Not good. Wasted time.      0   \n",
       "41642   3034   U were great, as always. But, can`t we do an ...      2   \n",
       "41643  11601   - Love your desserts. Used to live in OR but ...      2   \n",
       "\n",
       "      sentiment  \n",
       "0      positive  \n",
       "1       neutral  \n",
       "2      positive  \n",
       "3       neutral  \n",
       "4      negative  \n",
       "...         ...  \n",
       "41639  negative  \n",
       "41640   neutral  \n",
       "41641  negative  \n",
       "41642  positive  \n",
       "41643  positive  \n",
       "\n",
       "[41644 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# /teamspace/studios/this_studio/sentiment_analysis-project\n",
    "train_data = './sentiment_analysis-project/data/train.csv'\n",
    "test_data = './sentiment_analysis-project/data/test.csv'\n",
    "valid_data = './sentiment_analysis-project/data/validation.csv'\n",
    "\n",
    "file = './sentiment_analysis-project/multiclass_dataset.csv'\n",
    "\n",
    "def save_load_df(file:str):\n",
    "    if os.path.exists(file):\n",
    "        df = pd.read_csv(file, index_col= 0)\n",
    "    else:\n",
    "        df = pd.concat(map(pd.read_csv, [train_data, test_data, valid_data]), axis= 0, ignore_index=True)\n",
    "        df.to_csv(file, columns= ['id', 'text', 'label', 'sentiment'])\n",
    "        df = pd.read_csv(file, index_col= 0)\n",
    "    return df\n",
    "\n",
    "df = save_load_df(file=file)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP1, TP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cooking, microwave, pizzas, yummy]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[plans, allowing, sub, tasks, show, widget]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[love, humor, reworded, like, saying, group, t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[naw, idk, ur, talkin]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sucks, hear, hate, days, like]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41639</th>\n",
       "      <td>[fuck, internet, damn, time, warner]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41640</th>\n",
       "      <td>[looking, forward, android, 15, pushed, g1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41641</th>\n",
       "      <td>[good, wasted, time]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41642</th>\n",
       "      <td>[u, great, always, east, germany, noko, least,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41643</th>\n",
       "      <td>[love, desserts, used, live, live, tx, visit]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41644 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0                    [cooking, microwave, pizzas, yummy]      2\n",
       "1            [plans, allowing, sub, tasks, show, widget]      1\n",
       "2      [love, humor, reworded, like, saying, group, t...      2\n",
       "3                                 [naw, idk, ur, talkin]      1\n",
       "4                        [sucks, hear, hate, days, like]      0\n",
       "...                                                  ...    ...\n",
       "41639               [fuck, internet, damn, time, warner]      0\n",
       "41640        [looking, forward, android, 15, pushed, g1]      1\n",
       "41641                               [good, wasted, time]      0\n",
       "41642  [u, great, always, east, germany, noko, least,...      2\n",
       "41643      [love, desserts, used, live, live, tx, visit]      2\n",
       "\n",
       "[41644 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PreProcess():\n",
    "    def __init__(self):\n",
    "        self.text_pattern = re.compile(\n",
    "        r'(<.+?>)'         # Balises HTML\n",
    "        r'(#|@)\\w+'  # @ and # words\n",
    "        r'|([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'  # Emails\n",
    "        r'|(https?://[^\\s\\n\\r]+)' # URLs commençant par http ou https\n",
    "        r'|(www\\.[^\\s]+)'      # URLs commençant par www\n",
    "        r'|([\\U00010000-\\U0010ffff])'  # Émojis et autres caractères au-delà de l'ASCII étendu\n",
    "        r'|([^\\x00-\\xFF])'     # Tout ce qui n'est pas en ASCII étendu (0-255)\n",
    "        )\n",
    "        self.emoji_pattern = re.compile(\n",
    "            \"[\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "            \"\\U0001F300-\\U0001F5FF\"  # Miscellaneous Symbols and Pictographs\n",
    "            \"\\U0001F680-\\U0001F6FF\"  # Transport and Map Symbols\n",
    "            \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "            \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "            \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "            \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "            \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "            \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "            \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "            \"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "            \"]+\",\n",
    "            flags=re.UNICODE,\n",
    "        )\n",
    "        self.punctuation = set(string.punctuation)\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = self.text_pattern.sub('', str(text))\n",
    "        text = self.emoji_pattern.sub('', str(text))\n",
    "        text = text.lower()\n",
    "        return text\n",
    "    \n",
    "    def get_tokens(self, text):\n",
    "        text = self.clean_text(text)\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        tokens = []\n",
    "        for sentence in sentences:\n",
    "            words = nltk.word_tokenize(sentence)\n",
    "            for word in words:\n",
    "                if word not in self.stop_words:\n",
    "                    # clean all the punctuation and the StopWords\n",
    "                    word = ''.join([c for c in word if c not in self.punctuation])\n",
    "                    if word == '':\n",
    "                        continue\n",
    "                    tokens.append(word)\n",
    "        return tokens\n",
    "\n",
    "    def lemmetize_with_pos(self, tokens):\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        lemmes = [] \n",
    "        pos_tag = []\n",
    "        for token, pos in pos_tags:\n",
    "            if pos.startswith('J'):\n",
    "                lemma = self.lemmatizer.lemmatize(token, pos = 'a')\n",
    "            elif pos.startswith('V'):\n",
    "                lemma =  self.lemmatizer.lemmatize(token, pos = 'v')\n",
    "            elif pos.startswith('RB'):\n",
    "                lemma = self.lemmatizer.lemmatize(token, pos = 'r')\n",
    "            elif pos.startswith('N'):\n",
    "                lemma = self.lemmatizer.lemmatize(token, pos = 'n')\n",
    "            else:\n",
    "                lemma = self.lemmatizer.lemmatize(token)\n",
    "            lemmes.append(lemma)\n",
    "            pos_tag.append(pos)\n",
    "        return lemmes, pos_tag\n",
    "    \n",
    "    def get_lemmes(self, text):\n",
    "        tokens = self.get_tokens(text)\n",
    "        lemmes, _ = self.lemmetize_with_pos(tokens)\n",
    "        return lemmes\n",
    "    \n",
    "    def visualize_data(self, text):\n",
    "        text = self.clean_text(text)\n",
    "        tokens = self.get_tokens(text)\n",
    "        lemmes, pos_tag = self.lemmetize_with_pos(tokens)\n",
    "        data = [[token, lemme, pos] for token, lemme, pos in zip(tokens, lemmes, pos_tag)]\n",
    "        return data\n",
    "    \n",
    "texts = list(df['text'])\n",
    "labels = list(df['label'])\n",
    "process_text = PreProcess()\n",
    "corpus = pd.DataFrame(data = [(process_text.get_tokens(text), label) for text, label in zip(texts, labels)], columns=['sentence', 'label'])\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cooking, microwave, pizzas, yummy]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[plans, allowing, sub, tasks, show, widget]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[love, humor, reworded, like, saying, group, t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[naw, idk, ur, talkin]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sucks, hear, hate, days, like]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41502</th>\n",
       "      <td>[fuck, internet, damn, time, warner]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41503</th>\n",
       "      <td>[looking, forward, android, 15, pushed, g1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41504</th>\n",
       "      <td>[good, wasted, time]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41505</th>\n",
       "      <td>[u, great, always, east, germany, noko, least,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41506</th>\n",
       "      <td>[love, desserts, used, live, live, tx, visit]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41507 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0                    [cooking, microwave, pizzas, yummy]      2\n",
       "1            [plans, allowing, sub, tasks, show, widget]      1\n",
       "2      [love, humor, reworded, like, saying, group, t...      2\n",
       "3                                 [naw, idk, ur, talkin]      1\n",
       "4                        [sucks, hear, hate, days, like]      0\n",
       "...                                                  ...    ...\n",
       "41502               [fuck, internet, damn, time, warner]      0\n",
       "41503        [looking, forward, android, 15, pushed, g1]      1\n",
       "41504                               [good, wasted, time]      0\n",
       "41505  [u, great, always, east, germany, noko, least,...      2\n",
       "41506      [love, desserts, used, live, live, tx, visit]      2\n",
       "\n",
       "[41507 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the empty rows\n",
    "corpus = corpus[corpus['sentence'].str.len() != 0]\n",
    "corpus = corpus.reset_index(drop = True)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_file = './sentiment_analysis-project/GoogleNews-vectors-negative300.bin'\n",
    "sentences = list(corpus['sentence'])\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_file, binary= True)\n",
    "\n",
    "def sentence_to_vec(sentence):\n",
    "    sentence_to_vec = [word2vec_model[word] for word in sentence if word in word2vec_model]\n",
    "    return sentence_to_vec\n",
    "\n",
    "df1 = pd.DataFrame(data = [(sentence_to_vec(sentence), label) for sentence, label in zip(sentences, list(corpus['label']))], \n",
    "                   columns=['vec', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.14160156, 0.25390625, 0.052246094, 0.1279...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.15234375, 0.21484375, 0.30273438, 0.000576...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.103027344, -0.15234375, 0.025878906, 0.165...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.084472656, -0.0625, 0.15625, 0.22167969, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.099609375, -0.10839844, 0.049072266, 0.127...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41348</th>\n",
       "      <td>[[0.10449219, -0.3125, 0.21386719, 0.30859375,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41349</th>\n",
       "      <td>[[0.027832031, 0.25585938, 0.15820312, -0.0480...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41350</th>\n",
       "      <td>[[0.040527344, 0.0625, -0.017456055, 0.0786132...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41351</th>\n",
       "      <td>[[-0.25390625, 0.04663086, 0.1640625, -0.01831...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41352</th>\n",
       "      <td>[[0.103027344, -0.15234375, 0.025878906, 0.165...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41353 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     vec  label\n",
       "0      [[-0.14160156, 0.25390625, 0.052246094, 0.1279...      2\n",
       "1      [[0.15234375, 0.21484375, 0.30273438, 0.000576...      1\n",
       "2      [[0.103027344, -0.15234375, 0.025878906, 0.165...      2\n",
       "3      [[0.084472656, -0.0625, 0.15625, 0.22167969, 0...      1\n",
       "4      [[0.099609375, -0.10839844, 0.049072266, 0.127...      0\n",
       "...                                                  ...    ...\n",
       "41348  [[0.10449219, -0.3125, 0.21386719, 0.30859375,...      0\n",
       "41349  [[0.027832031, 0.25585938, 0.15820312, -0.0480...      1\n",
       "41350  [[0.040527344, 0.0625, -0.017456055, 0.0786132...      0\n",
       "41351  [[-0.25390625, 0.04663086, 0.1640625, -0.01831...      2\n",
       "41352  [[0.103027344, -0.15234375, 0.025878906, 0.165...      2\n",
       "\n",
       "[41353 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1[df1['vec'].str.len() != 0]\n",
    "# df1 = df1.sort_values(by = 'vec', key = lambda vec: vec.str.len(), ascending=False)\n",
    "df1 = df1.reset_index(drop= True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.14160156, 0.25390625, 0.052246094, 0.1279...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.15234375, 0.21484375, 0.30273438, 0.000576...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.103027344, -0.15234375, 0.025878906, 0.165...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.084472656, -0.0625, 0.15625, 0.22167969, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.099609375, -0.10839844, 0.049072266, 0.127...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41295</th>\n",
       "      <td>[[0.10449219, -0.3125, 0.21386719, 0.30859375,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41296</th>\n",
       "      <td>[[0.027832031, 0.25585938, 0.15820312, -0.0480...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41297</th>\n",
       "      <td>[[0.040527344, 0.0625, -0.017456055, 0.0786132...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41298</th>\n",
       "      <td>[[-0.25390625, 0.04663086, 0.1640625, -0.01831...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41299</th>\n",
       "      <td>[[0.103027344, -0.15234375, 0.025878906, 0.165...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     vec  label\n",
       "0      [[-0.14160156, 0.25390625, 0.052246094, 0.1279...      2\n",
       "1      [[0.15234375, 0.21484375, 0.30273438, 0.000576...      1\n",
       "2      [[0.103027344, -0.15234375, 0.025878906, 0.165...      2\n",
       "3      [[0.084472656, -0.0625, 0.15625, 0.22167969, 0...      1\n",
       "4      [[0.099609375, -0.10839844, 0.049072266, 0.127...      0\n",
       "...                                                  ...    ...\n",
       "41295  [[0.10449219, -0.3125, 0.21386719, 0.30859375,...      0\n",
       "41296  [[0.027832031, 0.25585938, 0.15820312, -0.0480...      1\n",
       "41297  [[0.040527344, 0.0625, -0.017456055, 0.0786132...      0\n",
       "41298  [[-0.25390625, 0.04663086, 0.1640625, -0.01831...      2\n",
       "41299  [[0.103027344, -0.15234375, 0.025878906, 0.165...      2\n",
       "\n",
       "[41300 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [len(vec) for vec in list(df1['vec']) if len(vec) <= 64]\n",
    "df1 = df1[df1['vec'].str.len() <= 64]\n",
    "df1 = df1.reset_index(drop= True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41300, 64, 300])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequence([torch.from_numpy(np.array(vec)) for vec in list(df1['vec'])], batch_first=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41300])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.from_numpy(np.array(list(df1['label'])))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size=0.5, train_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126147 parameters\n",
      "epoch 0 || train_loss 1.096, valid_loss 1.085, train_accu 0.359 , valid_accu 0.364, dt= 1.06\n",
      "epoch 1 || train_loss 1.094, valid_loss 1.085, train_accu 0.371 , valid_accu 0.364, dt= 1.05\n",
      "epoch 2 || train_loss 1.094, valid_loss 1.085, train_accu 0.371 , valid_accu 0.364, dt= 1.06\n",
      "epoch 3 || train_loss 1.093, valid_loss 1.076, train_accu 0.378 , valid_accu 0.409, dt= 1.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 || train_loss 1.092, valid_loss 1.085, train_accu 0.379 , valid_accu 0.364, dt= 1.20\n",
      "epoch 5 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.19\n",
      "epoch 6 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.23\n",
      "epoch 7 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.19\n",
      "epoch 8 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.19\n",
      "epoch 9 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.22\n",
      "epoch 10 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.19\n",
      "epoch 11 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.22\n",
      "epoch 12 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.22\n",
      "epoch 13 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.19\n",
      "epoch 14 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.20\n",
      "epoch 15 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.20\n",
      "epoch 16 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.20\n",
      "epoch 17 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.19\n",
      "epoch 18 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.21\n",
      "epoch 19 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.21\n",
      "epoch 20 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.22\n",
      "epoch 21 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.22\n",
      "epoch 22 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.19\n",
      "epoch 23 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.20\n",
      "epoch 24 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.22\n",
      "epoch 25 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.21\n",
      "epoch 26 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.364, dt= 1.21\n",
      "epoch 27 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.363, dt= 1.20\n",
      "epoch 28 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.363, dt= 1.21\n",
      "epoch 29 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.363, dt= 1.22\n",
      "epoch 30 || train_loss 1.093, valid_loss 1.085, train_accu 0.372 , valid_accu 0.363, dt= 1.21\n",
      "epoch 31 || train_loss 1.093, valid_loss 1.086, train_accu 0.372 , valid_accu 0.363, dt= 1.20\n",
      "epoch 32 || train_loss 1.077, valid_loss 0.998, train_accu 0.405 , valid_accu 0.499, dt= 1.19\n",
      "epoch 33 || train_loss 0.968, valid_loss 0.936, train_accu 0.545 , valid_accu 0.584, dt= 1.22\n",
      "epoch 34 || train_loss 0.911, valid_loss 0.890, train_accu 0.627 , valid_accu 0.639, dt= 1.21\n",
      "epoch 35 || train_loss 0.890, valid_loss 0.872, train_accu 0.650 , valid_accu 0.661, dt= 1.22\n",
      "epoch 36 || train_loss 0.876, valid_loss 0.863, train_accu 0.666 , valid_accu 0.667, dt= 1.23\n",
      "epoch 37 || train_loss 0.866, valid_loss 0.862, train_accu 0.676 , valid_accu 0.664, dt= 1.19\n",
      "epoch 38 || train_loss 0.861, valid_loss 0.850, train_accu 0.682 , valid_accu 0.685, dt= 1.22\n",
      "epoch 39 || train_loss 0.854, valid_loss 0.847, train_accu 0.689 , valid_accu 0.684, dt= 1.22\n",
      "epoch 40 || train_loss 0.850, valid_loss 0.846, train_accu 0.695 , valid_accu 0.686, dt= 1.21\n",
      "epoch 41 || train_loss 0.845, valid_loss 0.847, train_accu 0.698 , valid_accu 0.684, dt= 1.20\n",
      "epoch 42 || train_loss 0.843, valid_loss 0.846, train_accu 0.702 , valid_accu 0.683, dt= 1.21\n",
      "epoch 43 || train_loss 0.840, valid_loss 0.844, train_accu 0.705 , valid_accu 0.687, dt= 1.23\n",
      "epoch 44 || train_loss 0.837, valid_loss 0.843, train_accu 0.708 , valid_accu 0.689, dt= 1.18\n",
      "epoch 45 || train_loss 0.834, valid_loss 0.846, train_accu 0.712 , valid_accu 0.683, dt= 1.21\n",
      "epoch 46 || train_loss 0.836, valid_loss 0.843, train_accu 0.709 , valid_accu 0.690, dt= 1.21\n",
      "epoch 47 || train_loss 0.833, valid_loss 0.844, train_accu 0.712 , valid_accu 0.687, dt= 1.20\n",
      "epoch 48 || train_loss 0.830, valid_loss 0.843, train_accu 0.716 , valid_accu 0.689, dt= 1.21\n",
      "epoch 49 || train_loss 0.826, valid_loss 0.846, train_accu 0.721 , valid_accu 0.686, dt= 1.21\n",
      "epoch 50 || train_loss 0.823, valid_loss 0.847, train_accu 0.725 , valid_accu 0.686, dt= 1.20\n",
      "epoch 51 || train_loss 0.822, valid_loss 0.842, train_accu 0.725 , valid_accu 0.689, dt= 1.18\n",
      "epoch 52 || train_loss 0.821, valid_loss 0.844, train_accu 0.726 , valid_accu 0.689, dt= 1.23\n",
      "epoch 53 || train_loss 0.820, valid_loss 0.848, train_accu 0.727 , valid_accu 0.683, dt= 1.20\n",
      "epoch 54 || train_loss 0.816, valid_loss 0.847, train_accu 0.731 , valid_accu 0.686, dt= 1.21\n",
      "epoch 55 || train_loss 0.815, valid_loss 0.841, train_accu 0.732 , valid_accu 0.689, dt= 1.20\n",
      "epoch 56 || train_loss 0.813, valid_loss 0.841, train_accu 0.735 , valid_accu 0.690, dt= 1.17\n",
      "epoch 57 || train_loss 0.811, valid_loss 0.840, train_accu 0.736 , valid_accu 0.691, dt= 1.22\n",
      "epoch 58 || train_loss 0.811, valid_loss 0.843, train_accu 0.737 , valid_accu 0.689, dt= 1.20\n",
      "epoch 59 || train_loss 0.810, valid_loss 0.839, train_accu 0.738 , valid_accu 0.694, dt= 1.20\n",
      "epoch 60 || train_loss 0.810, valid_loss 0.840, train_accu 0.738 , valid_accu 0.692, dt= 1.21\n",
      "epoch 61 || train_loss 0.806, valid_loss 0.845, train_accu 0.742 , valid_accu 0.689, dt= 1.20\n",
      "epoch 62 || train_loss 0.804, valid_loss 0.844, train_accu 0.745 , valid_accu 0.690, dt= 1.20\n",
      "epoch 63 || train_loss 0.803, valid_loss 0.838, train_accu 0.745 , valid_accu 0.697, dt= 1.20\n",
      "epoch 64 || train_loss 0.803, valid_loss 0.840, train_accu 0.746 , valid_accu 0.696, dt= 1.21\n",
      "epoch 65 || train_loss 0.800, valid_loss 0.841, train_accu 0.748 , valid_accu 0.692, dt= 1.18\n",
      "epoch 66 || train_loss 0.799, valid_loss 0.838, train_accu 0.749 , valid_accu 0.697, dt= 1.08\n",
      "epoch 67 || train_loss 0.798, valid_loss 0.841, train_accu 0.751 , valid_accu 0.693, dt= 1.08\n",
      "epoch 68 || train_loss 0.798, valid_loss 0.838, train_accu 0.751 , valid_accu 0.698, dt= 1.07\n",
      "epoch 69 || train_loss 0.795, valid_loss 0.840, train_accu 0.754 , valid_accu 0.695, dt= 1.08\n",
      "epoch 70 || train_loss 0.794, valid_loss 0.840, train_accu 0.755 , valid_accu 0.694, dt= 1.19\n",
      "epoch 71 || train_loss 0.795, valid_loss 0.840, train_accu 0.755 , valid_accu 0.695, dt= 1.23\n",
      "epoch 72 || train_loss 0.794, valid_loss 0.839, train_accu 0.756 , valid_accu 0.696, dt= 1.20\n",
      "epoch 73 || train_loss 0.792, valid_loss 0.839, train_accu 0.757 , valid_accu 0.696, dt= 1.20\n",
      "epoch 74 || train_loss 0.790, valid_loss 0.837, train_accu 0.760 , valid_accu 0.698, dt= 1.20\n",
      "epoch 75 || train_loss 0.793, valid_loss 0.838, train_accu 0.756 , valid_accu 0.696, dt= 1.20\n",
      "epoch 76 || train_loss 0.798, valid_loss 0.839, train_accu 0.751 , valid_accu 0.697, dt= 1.21\n",
      "epoch 77 || train_loss 0.788, valid_loss 0.841, train_accu 0.761 , valid_accu 0.695, dt= 1.21\n",
      "epoch 78 || train_loss 0.788, valid_loss 0.838, train_accu 0.762 , valid_accu 0.698, dt= 1.19\n",
      "epoch 79 || train_loss 0.786, valid_loss 0.836, train_accu 0.764 , valid_accu 0.702, dt= 1.20\n",
      "epoch 80 || train_loss 0.786, valid_loss 0.837, train_accu 0.764 , valid_accu 0.700, dt= 1.24\n",
      "epoch 81 || train_loss 0.790, valid_loss 0.837, train_accu 0.760 , valid_accu 0.700, dt= 1.20\n",
      "epoch 82 || train_loss 0.786, valid_loss 0.837, train_accu 0.764 , valid_accu 0.699, dt= 1.23\n",
      "epoch 83 || train_loss 0.783, valid_loss 0.836, train_accu 0.767 , valid_accu 0.701, dt= 1.20\n",
      "epoch 84 || train_loss 0.784, valid_loss 0.839, train_accu 0.766 , valid_accu 0.696, dt= 1.20\n",
      "epoch 85 || train_loss 0.780, valid_loss 0.837, train_accu 0.770 , valid_accu 0.700, dt= 1.22\n",
      "epoch 86 || train_loss 0.782, valid_loss 0.837, train_accu 0.768 , valid_accu 0.700, dt= 1.21\n",
      "epoch 87 || train_loss 0.782, valid_loss 0.839, train_accu 0.768 , valid_accu 0.697, dt= 1.20\n",
      "epoch 88 || train_loss 0.786, valid_loss 0.837, train_accu 0.764 , valid_accu 0.699, dt= 1.19\n",
      "epoch 89 || train_loss 0.782, valid_loss 0.838, train_accu 0.768 , valid_accu 0.699, dt= 1.21\n",
      "epoch 90 || train_loss 0.780, valid_loss 0.836, train_accu 0.769 , valid_accu 0.701, dt= 1.21\n",
      "epoch 91 || train_loss 0.783, valid_loss 0.835, train_accu 0.766 , valid_accu 0.702, dt= 1.19\n",
      "epoch 92 || train_loss 0.778, valid_loss 0.839, train_accu 0.773 , valid_accu 0.698, dt= 1.19\n",
      "epoch 93 || train_loss 0.781, valid_loss 0.838, train_accu 0.769 , valid_accu 0.697, dt= 1.20\n",
      "epoch 94 || train_loss 0.778, valid_loss 0.834, train_accu 0.771 , valid_accu 0.702, dt= 1.21\n",
      "epoch 95 || train_loss 0.775, valid_loss 0.834, train_accu 0.775 , valid_accu 0.704, dt= 1.20\n",
      "epoch 96 || train_loss 0.774, valid_loss 0.835, train_accu 0.777 , valid_accu 0.702, dt= 1.20\n",
      "epoch 97 || train_loss 0.783, valid_loss 0.840, train_accu 0.767 , valid_accu 0.696, dt= 1.19\n",
      "epoch 98 || train_loss 0.780, valid_loss 0.837, train_accu 0.770 , valid_accu 0.699, dt= 1.20\n",
      "epoch 99 || train_loss 0.787, valid_loss 0.835, train_accu 0.763 , valid_accu 0.701, dt= 1.21\n",
      "epoch 100 || train_loss 0.776, valid_loss 0.834, train_accu 0.774 , valid_accu 0.702, dt= 1.20\n",
      "epoch 101 || train_loss 0.774, valid_loss 0.831, train_accu 0.776 , valid_accu 0.704, dt= 1.19\n",
      "epoch 102 || train_loss 0.774, valid_loss 0.832, train_accu 0.777 , valid_accu 0.705, dt= 1.20\n",
      "epoch 103 || train_loss 0.772, valid_loss 0.834, train_accu 0.778 , valid_accu 0.702, dt= 1.21\n",
      "epoch 104 || train_loss 0.774, valid_loss 0.838, train_accu 0.776 , valid_accu 0.698, dt= 1.22\n",
      "epoch 105 || train_loss 0.772, valid_loss 0.834, train_accu 0.778 , valid_accu 0.702, dt= 1.19\n",
      "epoch 106 || train_loss 0.772, valid_loss 0.834, train_accu 0.778 , valid_accu 0.703, dt= 1.21\n",
      "epoch 107 || train_loss 0.772, valid_loss 0.832, train_accu 0.779 , valid_accu 0.705, dt= 1.20\n",
      "epoch 108 || train_loss 0.774, valid_loss 0.833, train_accu 0.776 , valid_accu 0.703, dt= 1.22\n",
      "epoch 109 || train_loss 0.770, valid_loss 0.834, train_accu 0.780 , valid_accu 0.704, dt= 1.21\n",
      "epoch 110 || train_loss 0.772, valid_loss 0.833, train_accu 0.778 , valid_accu 0.705, dt= 1.20\n",
      "epoch 111 || train_loss 0.772, valid_loss 0.833, train_accu 0.778 , valid_accu 0.705, dt= 1.20\n",
      "epoch 112 || train_loss 0.772, valid_loss 0.834, train_accu 0.778 , valid_accu 0.702, dt= 1.20\n",
      "epoch 113 || train_loss 0.770, valid_loss 0.832, train_accu 0.780 , valid_accu 0.705, dt= 1.21\n",
      "epoch 114 || train_loss 0.770, valid_loss 0.833, train_accu 0.780 , valid_accu 0.703, dt= 1.19\n",
      "epoch 115 || train_loss 0.770, valid_loss 0.831, train_accu 0.780 , valid_accu 0.705, dt= 1.19\n",
      "epoch 116 || train_loss 0.770, valid_loss 0.832, train_accu 0.780 , valid_accu 0.705, dt= 1.22\n",
      "epoch 117 || train_loss 0.770, valid_loss 0.833, train_accu 0.780 , valid_accu 0.705, dt= 1.21\n",
      "epoch 118 || train_loss 0.767, valid_loss 0.829, train_accu 0.783 , valid_accu 0.709, dt= 1.22\n",
      "epoch 119 || train_loss 0.785, valid_loss 0.858, train_accu 0.765 , valid_accu 0.678, dt= 1.10\n",
      "epoch 120 || train_loss 0.781, valid_loss 0.834, train_accu 0.769 , valid_accu 0.703, dt= 1.08\n",
      "epoch 121 || train_loss 0.768, valid_loss 0.829, train_accu 0.782 , valid_accu 0.708, dt= 1.08\n",
      "epoch 122 || train_loss 0.769, valid_loss 0.829, train_accu 0.781 , valid_accu 0.709, dt= 1.08\n",
      "epoch 123 || train_loss 0.766, valid_loss 0.830, train_accu 0.785 , valid_accu 0.708, dt= 1.08\n",
      "epoch 124 || train_loss 0.767, valid_loss 0.833, train_accu 0.783 , valid_accu 0.705, dt= 1.16\n",
      "epoch 125 || train_loss 0.765, valid_loss 0.832, train_accu 0.785 , valid_accu 0.705, dt= 1.20\n",
      "epoch 126 || train_loss 0.769, valid_loss 0.833, train_accu 0.781 , valid_accu 0.704, dt= 1.21\n",
      "epoch 127 || train_loss 0.768, valid_loss 0.832, train_accu 0.782 , valid_accu 0.705, dt= 1.22\n",
      "epoch 128 || train_loss 0.766, valid_loss 0.832, train_accu 0.784 , valid_accu 0.704, dt= 1.20\n",
      "epoch 129 || train_loss 0.765, valid_loss 0.832, train_accu 0.785 , valid_accu 0.706, dt= 1.21\n",
      "epoch 130 || train_loss 0.765, valid_loss 0.831, train_accu 0.785 , valid_accu 0.707, dt= 1.21\n",
      "epoch 131 || train_loss 0.767, valid_loss 0.834, train_accu 0.783 , valid_accu 0.703, dt= 1.21\n",
      "epoch 132 || train_loss 0.764, valid_loss 0.832, train_accu 0.787 , valid_accu 0.704, dt= 1.21\n",
      "epoch 133 || train_loss 0.766, valid_loss 0.834, train_accu 0.785 , valid_accu 0.704, dt= 1.20\n",
      "epoch 134 || train_loss 0.763, valid_loss 0.830, train_accu 0.787 , valid_accu 0.708, dt= 1.23\n",
      "epoch 135 || train_loss 0.763, valid_loss 0.840, train_accu 0.787 , valid_accu 0.698, dt= 1.22\n",
      "epoch 136 || train_loss 0.765, valid_loss 0.829, train_accu 0.785 , valid_accu 0.707, dt= 1.21\n",
      "epoch 137 || train_loss 0.763, valid_loss 0.831, train_accu 0.788 , valid_accu 0.707, dt= 1.22\n",
      "epoch 138 || train_loss 0.772, valid_loss 0.833, train_accu 0.778 , valid_accu 0.703, dt= 1.20\n",
      "epoch 139 || train_loss 0.765, valid_loss 0.832, train_accu 0.785 , valid_accu 0.706, dt= 1.20\n",
      "epoch 140 || train_loss 0.763, valid_loss 0.834, train_accu 0.788 , valid_accu 0.702, dt= 1.21\n",
      "epoch 141 || train_loss 0.763, valid_loss 0.836, train_accu 0.787 , valid_accu 0.702, dt= 1.22\n",
      "epoch 142 || train_loss 0.764, valid_loss 0.833, train_accu 0.786 , valid_accu 0.703, dt= 1.11\n",
      "epoch 143 || train_loss 0.765, valid_loss 0.831, train_accu 0.786 , valid_accu 0.707, dt= 1.06\n",
      "epoch 144 || train_loss 0.790, valid_loss 0.846, train_accu 0.760 , valid_accu 0.691, dt= 1.07\n",
      "epoch 145 || train_loss 0.788, valid_loss 0.832, train_accu 0.762 , valid_accu 0.705, dt= 1.06\n",
      "epoch 146 || train_loss 0.765, valid_loss 0.827, train_accu 0.785 , valid_accu 0.711, dt= 1.06\n",
      "epoch 147 || train_loss 0.763, valid_loss 0.831, train_accu 0.787 , valid_accu 0.707, dt= 1.07\n",
      "epoch 148 || train_loss 0.762, valid_loss 0.836, train_accu 0.789 , valid_accu 0.700, dt= 1.07\n",
      "epoch 149 || train_loss 0.761, valid_loss 0.832, train_accu 0.789 , valid_accu 0.705, dt= 1.06\n",
      "epoch 150 || train_loss 0.760, valid_loss 0.838, train_accu 0.790 , valid_accu 0.700, dt= 1.20\n",
      "epoch 151 || train_loss 0.767, valid_loss 0.837, train_accu 0.783 , valid_accu 0.700, dt= 1.19\n",
      "epoch 152 || train_loss 0.761, valid_loss 0.833, train_accu 0.790 , valid_accu 0.705, dt= 1.21\n",
      "epoch 153 || train_loss 0.763, valid_loss 0.830, train_accu 0.787 , valid_accu 0.707, dt= 1.22\n",
      "epoch 154 || train_loss 0.764, valid_loss 0.832, train_accu 0.786 , valid_accu 0.705, dt= 1.19\n",
      "epoch 155 || train_loss 0.763, valid_loss 0.829, train_accu 0.787 , valid_accu 0.708, dt= 1.20\n",
      "epoch 156 || train_loss 0.758, valid_loss 0.830, train_accu 0.792 , valid_accu 0.708, dt= 1.21\n",
      "epoch 157 || train_loss 0.760, valid_loss 0.827, train_accu 0.790 , valid_accu 0.711, dt= 1.20\n",
      "epoch 158 || train_loss 0.758, valid_loss 0.830, train_accu 0.792 , valid_accu 0.707, dt= 1.20\n",
      "epoch 159 || train_loss 0.758, valid_loss 0.830, train_accu 0.792 , valid_accu 0.708, dt= 1.22\n",
      "epoch 160 || train_loss 0.770, valid_loss 0.907, train_accu 0.780 , valid_accu 0.630, dt= 1.20\n",
      "epoch 161 || train_loss 0.801, valid_loss 0.834, train_accu 0.748 , valid_accu 0.702, dt= 1.21\n",
      "epoch 162 || train_loss 0.763, valid_loss 0.834, train_accu 0.787 , valid_accu 0.703, dt= 1.23\n",
      "epoch 163 || train_loss 0.759, valid_loss 0.835, train_accu 0.791 , valid_accu 0.702, dt= 1.21\n",
      "epoch 164 || train_loss 0.759, valid_loss 0.837, train_accu 0.791 , valid_accu 0.700, dt= 1.22\n",
      "epoch 165 || train_loss 0.757, valid_loss 0.831, train_accu 0.794 , valid_accu 0.706, dt= 1.20\n",
      "epoch 166 || train_loss 0.757, valid_loss 0.832, train_accu 0.793 , valid_accu 0.706, dt= 1.20\n",
      "epoch 167 || train_loss 0.758, valid_loss 0.830, train_accu 0.793 , valid_accu 0.708, dt= 1.19\n",
      "epoch 168 || train_loss 0.757, valid_loss 0.828, train_accu 0.793 , valid_accu 0.710, dt= 1.22\n",
      "epoch 169 || train_loss 0.755, valid_loss 0.828, train_accu 0.795 , valid_accu 0.710, dt= 1.21\n",
      "epoch 170 || train_loss 0.755, valid_loss 0.828, train_accu 0.795 , valid_accu 0.710, dt= 1.19\n",
      "epoch 171 || train_loss 0.755, valid_loss 0.828, train_accu 0.795 , valid_accu 0.710, dt= 1.23\n",
      "epoch 172 || train_loss 0.754, valid_loss 0.830, train_accu 0.796 , valid_accu 0.707, dt= 1.20\n",
      "epoch 173 || train_loss 0.754, valid_loss 0.828, train_accu 0.796 , valid_accu 0.710, dt= 1.18\n",
      "epoch 174 || train_loss 0.756, valid_loss 0.831, train_accu 0.795 , valid_accu 0.706, dt= 1.22\n",
      "epoch 175 || train_loss 0.761, valid_loss 0.834, train_accu 0.789 , valid_accu 0.703, dt= 1.19\n",
      "epoch 176 || train_loss 0.756, valid_loss 0.829, train_accu 0.794 , valid_accu 0.709, dt= 1.19\n",
      "epoch 177 || train_loss 0.757, valid_loss 0.835, train_accu 0.794 , valid_accu 0.702, dt= 1.22\n",
      "epoch 178 || train_loss 0.757, valid_loss 0.831, train_accu 0.793 , valid_accu 0.706, dt= 1.19\n",
      "epoch 179 || train_loss 0.755, valid_loss 0.834, train_accu 0.795 , valid_accu 0.703, dt= 1.18\n",
      "epoch 180 || train_loss 0.759, valid_loss 0.827, train_accu 0.792 , valid_accu 0.710, dt= 1.22\n",
      "epoch 181 || train_loss 0.752, valid_loss 0.831, train_accu 0.798 , valid_accu 0.706, dt= 1.19\n",
      "epoch 182 || train_loss 0.754, valid_loss 0.833, train_accu 0.796 , valid_accu 0.703, dt= 1.18\n",
      "epoch 183 || train_loss 0.755, valid_loss 0.830, train_accu 0.796 , valid_accu 0.708, dt= 1.19\n",
      "epoch 184 || train_loss 0.753, valid_loss 0.829, train_accu 0.798 , valid_accu 0.708, dt= 1.19\n",
      "epoch 185 || train_loss 0.779, valid_loss 0.833, train_accu 0.770 , valid_accu 0.704, dt= 1.17\n",
      "epoch 186 || train_loss 0.758, valid_loss 0.829, train_accu 0.792 , valid_accu 0.709, dt= 1.21\n",
      "epoch 187 || train_loss 0.753, valid_loss 0.830, train_accu 0.797 , valid_accu 0.708, dt= 1.18\n",
      "epoch 188 || train_loss 0.752, valid_loss 0.829, train_accu 0.799 , valid_accu 0.708, dt= 1.21\n",
      "epoch 189 || train_loss 0.751, valid_loss 0.829, train_accu 0.800 , valid_accu 0.707, dt= 1.21\n",
      "epoch 190 || train_loss 0.752, valid_loss 0.830, train_accu 0.799 , valid_accu 0.707, dt= 1.21\n",
      "epoch 191 || train_loss 0.752, valid_loss 0.831, train_accu 0.798 , valid_accu 0.707, dt= 1.20\n",
      "epoch 192 || train_loss 0.752, valid_loss 0.831, train_accu 0.798 , valid_accu 0.707, dt= 1.19\n",
      "epoch 193 || train_loss 0.751, valid_loss 0.833, train_accu 0.800 , valid_accu 0.704, dt= 1.22\n",
      "epoch 194 || train_loss 0.750, valid_loss 0.831, train_accu 0.801 , valid_accu 0.707, dt= 1.19\n",
      "epoch 195 || train_loss 0.751, valid_loss 0.830, train_accu 0.800 , valid_accu 0.706, dt= 1.20\n",
      "epoch 196 || train_loss 0.750, valid_loss 0.831, train_accu 0.801 , valid_accu 0.706, dt= 1.21\n",
      "epoch 197 || train_loss 0.753, valid_loss 0.834, train_accu 0.797 , valid_accu 0.704, dt= 1.20\n",
      "epoch 198 || train_loss 0.753, valid_loss 0.830, train_accu 0.797 , valid_accu 0.708, dt= 1.23\n",
      "epoch 199 || train_loss 0.751, valid_loss 0.828, train_accu 0.799 , valid_accu 0.709, dt= 1.21\n",
      "epoch 200 || train_loss 0.750, valid_loss 0.831, train_accu 0.801 , valid_accu 0.706, dt= 1.20\n",
      "epoch 201 || train_loss 0.750, valid_loss 0.833, train_accu 0.800 , valid_accu 0.704, dt= 1.20\n",
      "epoch 202 || train_loss 0.753, valid_loss 0.832, train_accu 0.797 , valid_accu 0.705, dt= 1.22\n",
      "epoch 203 || train_loss 0.752, valid_loss 0.829, train_accu 0.799 , valid_accu 0.708, dt= 1.25\n",
      "epoch 204 || train_loss 0.750, valid_loss 0.829, train_accu 0.800 , valid_accu 0.709, dt= 1.18\n",
      "epoch 205 || train_loss 0.752, valid_loss 0.831, train_accu 0.798 , valid_accu 0.707, dt= 1.21\n",
      "epoch 206 || train_loss 0.753, valid_loss 0.828, train_accu 0.797 , valid_accu 0.710, dt= 1.19\n",
      "epoch 207 || train_loss 0.749, valid_loss 0.829, train_accu 0.801 , valid_accu 0.707, dt= 1.20\n",
      "epoch 208 || train_loss 0.750, valid_loss 0.830, train_accu 0.800 , valid_accu 0.708, dt= 1.20\n",
      "epoch 209 || train_loss 0.752, valid_loss 0.829, train_accu 0.799 , valid_accu 0.708, dt= 1.17\n",
      "epoch 210 || train_loss 0.749, valid_loss 0.828, train_accu 0.801 , valid_accu 0.709, dt= 1.19\n",
      "epoch 211 || train_loss 0.749, valid_loss 0.826, train_accu 0.802 , valid_accu 0.712, dt= 1.19\n",
      "epoch 212 || train_loss 0.750, valid_loss 0.825, train_accu 0.801 , valid_accu 0.712, dt= 1.20\n",
      "epoch 213 || train_loss 0.749, valid_loss 0.826, train_accu 0.802 , valid_accu 0.713, dt= 1.20\n",
      "epoch 214 || train_loss 0.748, valid_loss 0.826, train_accu 0.803 , valid_accu 0.712, dt= 1.22\n",
      "epoch 215 || train_loss 0.748, valid_loss 0.827, train_accu 0.802 , valid_accu 0.711, dt= 1.20\n",
      "epoch 216 || train_loss 0.749, valid_loss 0.827, train_accu 0.802 , valid_accu 0.711, dt= 1.22\n",
      "epoch 217 || train_loss 0.752, valid_loss 0.830, train_accu 0.798 , valid_accu 0.708, dt= 1.11\n",
      "epoch 218 || train_loss 0.753, valid_loss 0.832, train_accu 0.797 , valid_accu 0.706, dt= 1.06\n",
      "epoch 219 || train_loss 0.750, valid_loss 0.831, train_accu 0.801 , valid_accu 0.706, dt= 1.06\n",
      "epoch 220 || train_loss 0.750, valid_loss 0.829, train_accu 0.801 , valid_accu 0.709, dt= 1.08\n",
      "epoch 221 || train_loss 0.751, valid_loss 0.829, train_accu 0.800 , valid_accu 0.708, dt= 1.15\n",
      "epoch 222 || train_loss 0.747, valid_loss 0.828, train_accu 0.804 , valid_accu 0.708, dt= 1.19\n",
      "epoch 223 || train_loss 0.747, valid_loss 0.831, train_accu 0.803 , valid_accu 0.707, dt= 1.20\n",
      "epoch 224 || train_loss 0.747, valid_loss 0.829, train_accu 0.804 , valid_accu 0.708, dt= 1.19\n",
      "epoch 225 || train_loss 0.747, valid_loss 0.828, train_accu 0.803 , valid_accu 0.710, dt= 1.19\n",
      "epoch 226 || train_loss 0.748, valid_loss 0.828, train_accu 0.803 , valid_accu 0.709, dt= 1.17\n",
      "epoch 227 || train_loss 0.747, valid_loss 0.829, train_accu 0.804 , valid_accu 0.709, dt= 1.22\n",
      "epoch 228 || train_loss 0.748, valid_loss 0.829, train_accu 0.802 , valid_accu 0.708, dt= 1.19\n",
      "epoch 229 || train_loss 0.750, valid_loss 0.828, train_accu 0.800 , valid_accu 0.710, dt= 1.21\n",
      "epoch 230 || train_loss 0.754, valid_loss 0.827, train_accu 0.796 , valid_accu 0.710, dt= 1.19\n",
      "epoch 231 || train_loss 0.747, valid_loss 0.831, train_accu 0.803 , valid_accu 0.707, dt= 1.21\n",
      "epoch 232 || train_loss 0.746, valid_loss 0.830, train_accu 0.804 , valid_accu 0.708, dt= 1.19\n",
      "epoch 233 || train_loss 0.746, valid_loss 0.830, train_accu 0.804 , valid_accu 0.706, dt= 1.22\n",
      "epoch 234 || train_loss 0.745, valid_loss 0.830, train_accu 0.805 , valid_accu 0.707, dt= 1.16\n",
      "epoch 235 || train_loss 0.745, valid_loss 0.831, train_accu 0.805 , valid_accu 0.707, dt= 1.07\n",
      "epoch 236 || train_loss 0.749, valid_loss 0.831, train_accu 0.801 , valid_accu 0.707, dt= 1.09\n",
      "epoch 237 || train_loss 0.748, valid_loss 0.829, train_accu 0.802 , valid_accu 0.708, dt= 1.07\n",
      "epoch 238 || train_loss 0.747, valid_loss 0.829, train_accu 0.803 , valid_accu 0.708, dt= 1.08\n",
      "epoch 239 || train_loss 0.746, valid_loss 0.832, train_accu 0.804 , valid_accu 0.705, dt= 1.08\n",
      "epoch 240 || train_loss 0.745, valid_loss 0.830, train_accu 0.805 , valid_accu 0.708, dt= 1.08\n",
      "epoch 241 || train_loss 0.745, valid_loss 0.827, train_accu 0.806 , valid_accu 0.712, dt= 1.08\n",
      "epoch 242 || train_loss 0.744, valid_loss 0.825, train_accu 0.806 , valid_accu 0.712, dt= 1.08\n",
      "epoch 243 || train_loss 0.744, valid_loss 0.828, train_accu 0.806 , valid_accu 0.709, dt= 1.10\n",
      "epoch 244 || train_loss 0.744, valid_loss 0.831, train_accu 0.807 , valid_accu 0.707, dt= 1.07\n",
      "epoch 245 || train_loss 0.748, valid_loss 0.830, train_accu 0.802 , valid_accu 0.708, dt= 1.08\n",
      "epoch 246 || train_loss 0.744, valid_loss 0.832, train_accu 0.807 , valid_accu 0.705, dt= 1.07\n",
      "epoch 247 || train_loss 0.744, valid_loss 0.829, train_accu 0.806 , valid_accu 0.708, dt= 1.13\n",
      "epoch 248 || train_loss 0.746, valid_loss 0.828, train_accu 0.804 , valid_accu 0.710, dt= 1.19\n",
      "epoch 249 || train_loss 0.746, valid_loss 0.827, train_accu 0.805 , valid_accu 0.711, dt= 1.19\n",
      "epoch 250 || train_loss 0.745, valid_loss 0.827, train_accu 0.806 , valid_accu 0.710, dt= 1.20\n",
      "epoch 251 || train_loss 0.744, valid_loss 0.827, train_accu 0.807 , valid_accu 0.711, dt= 1.20\n",
      "epoch 252 || train_loss 0.743, valid_loss 0.827, train_accu 0.807 , valid_accu 0.711, dt= 1.21\n",
      "epoch 253 || train_loss 0.749, valid_loss 0.836, train_accu 0.801 , valid_accu 0.701, dt= 1.20\n",
      "epoch 254 || train_loss 0.747, valid_loss 0.829, train_accu 0.804 , valid_accu 0.708, dt= 1.22\n",
      "epoch 255 || train_loss 0.744, valid_loss 0.829, train_accu 0.806 , valid_accu 0.708, dt= 1.23\n",
      "epoch 256 || train_loss 0.745, valid_loss 0.825, train_accu 0.806 , valid_accu 0.712, dt= 1.20\n",
      "epoch 257 || train_loss 0.744, valid_loss 0.828, train_accu 0.807 , valid_accu 0.709, dt= 1.20\n",
      "epoch 258 || train_loss 0.744, valid_loss 0.830, train_accu 0.806 , valid_accu 0.708, dt= 1.18\n",
      "epoch 259 || train_loss 0.746, valid_loss 0.829, train_accu 0.805 , valid_accu 0.709, dt= 1.19\n",
      "epoch 260 || train_loss 0.745, valid_loss 0.827, train_accu 0.805 , valid_accu 0.710, dt= 1.21\n",
      "epoch 261 || train_loss 0.745, valid_loss 0.837, train_accu 0.805 , valid_accu 0.700, dt= 1.19\n",
      "epoch 262 || train_loss 0.744, valid_loss 0.831, train_accu 0.806 , valid_accu 0.705, dt= 1.22\n",
      "epoch 263 || train_loss 0.743, valid_loss 0.831, train_accu 0.808 , valid_accu 0.706, dt= 1.19\n",
      "epoch 264 || train_loss 0.743, valid_loss 0.831, train_accu 0.808 , valid_accu 0.705, dt= 1.21\n",
      "epoch 265 || train_loss 0.742, valid_loss 0.831, train_accu 0.808 , valid_accu 0.706, dt= 1.22\n",
      "epoch 266 || train_loss 0.744, valid_loss 0.833, train_accu 0.806 , valid_accu 0.705, dt= 1.18\n",
      "epoch 267 || train_loss 0.747, valid_loss 0.833, train_accu 0.803 , valid_accu 0.705, dt= 1.20\n",
      "epoch 268 || train_loss 0.743, valid_loss 0.832, train_accu 0.807 , valid_accu 0.704, dt= 1.18\n",
      "epoch 269 || train_loss 0.741, valid_loss 0.830, train_accu 0.809 , valid_accu 0.706, dt= 1.18\n",
      "epoch 270 || train_loss 0.743, valid_loss 0.829, train_accu 0.808 , valid_accu 0.708, dt= 1.20\n",
      "epoch 271 || train_loss 0.744, valid_loss 0.831, train_accu 0.806 , valid_accu 0.705, dt= 1.20\n",
      "epoch 272 || train_loss 0.741, valid_loss 0.828, train_accu 0.809 , valid_accu 0.708, dt= 1.20\n",
      "epoch 273 || train_loss 0.741, valid_loss 0.831, train_accu 0.810 , valid_accu 0.706, dt= 1.22\n",
      "epoch 274 || train_loss 0.742, valid_loss 0.832, train_accu 0.808 , valid_accu 0.704, dt= 1.22\n",
      "epoch 275 || train_loss 0.742, valid_loss 0.830, train_accu 0.809 , valid_accu 0.708, dt= 1.20\n",
      "epoch 276 || train_loss 0.743, valid_loss 0.829, train_accu 0.807 , valid_accu 0.708, dt= 1.20\n",
      "epoch 277 || train_loss 0.742, valid_loss 0.830, train_accu 0.808 , valid_accu 0.708, dt= 1.21\n",
      "epoch 278 || train_loss 0.743, valid_loss 0.827, train_accu 0.807 , valid_accu 0.710, dt= 1.20\n",
      "epoch 279 || train_loss 0.741, valid_loss 0.830, train_accu 0.809 , valid_accu 0.708, dt= 1.18\n",
      "epoch 280 || train_loss 0.740, valid_loss 0.832, train_accu 0.811 , valid_accu 0.704, dt= 1.21\n",
      "epoch 281 || train_loss 0.743, valid_loss 0.829, train_accu 0.807 , valid_accu 0.707, dt= 1.20\n",
      "epoch 282 || train_loss 0.742, valid_loss 0.835, train_accu 0.808 , valid_accu 0.701, dt= 1.19\n",
      "epoch 283 || train_loss 0.743, valid_loss 0.832, train_accu 0.807 , valid_accu 0.704, dt= 1.22\n",
      "epoch 284 || train_loss 0.741, valid_loss 0.828, train_accu 0.809 , valid_accu 0.709, dt= 1.18\n",
      "epoch 285 || train_loss 0.741, valid_loss 0.829, train_accu 0.810 , valid_accu 0.708, dt= 1.18\n",
      "epoch 286 || train_loss 0.742, valid_loss 0.828, train_accu 0.808 , valid_accu 0.709, dt= 1.20\n",
      "epoch 287 || train_loss 0.739, valid_loss 0.827, train_accu 0.811 , valid_accu 0.709, dt= 1.16\n",
      "epoch 288 || train_loss 0.739, valid_loss 0.830, train_accu 0.812 , valid_accu 0.705, dt= 1.07\n",
      "epoch 289 || train_loss 0.741, valid_loss 0.830, train_accu 0.810 , valid_accu 0.707, dt= 1.04\n",
      "epoch 290 || train_loss 0.742, valid_loss 0.828, train_accu 0.809 , valid_accu 0.708, dt= 1.06\n",
      "epoch 291 || train_loss 0.739, valid_loss 0.829, train_accu 0.812 , valid_accu 0.708, dt= 1.04\n",
      "epoch 292 || train_loss 0.745, valid_loss 0.830, train_accu 0.806 , valid_accu 0.707, dt= 1.04\n",
      "epoch 293 || train_loss 0.749, valid_loss 0.828, train_accu 0.801 , valid_accu 0.710, dt= 1.05\n",
      "epoch 294 || train_loss 0.742, valid_loss 0.827, train_accu 0.808 , valid_accu 0.711, dt= 1.05\n",
      "epoch 295 || train_loss 0.741, valid_loss 0.826, train_accu 0.810 , valid_accu 0.712, dt= 1.07\n",
      "epoch 296 || train_loss 0.742, valid_loss 0.827, train_accu 0.808 , valid_accu 0.709, dt= 1.06\n",
      "epoch 297 || train_loss 0.743, valid_loss 0.826, train_accu 0.808 , valid_accu 0.711, dt= 1.05\n",
      "epoch 298 || train_loss 0.739, valid_loss 0.827, train_accu 0.811 , valid_accu 0.709, dt= 1.06\n",
      "epoch 299 || train_loss 0.739, valid_loss 0.827, train_accu 0.812 , valid_accu 0.709, dt= 1.21\n",
      "epoch 300 || train_loss 0.740, valid_loss 0.826, train_accu 0.810 , valid_accu 0.711, dt= 1.19\n",
      "epoch 301 || train_loss 0.741, valid_loss 0.830, train_accu 0.809 , valid_accu 0.706, dt= 1.21\n",
      "epoch 302 || train_loss 0.739, valid_loss 0.827, train_accu 0.812 , valid_accu 0.709, dt= 1.20\n",
      "epoch 303 || train_loss 0.738, valid_loss 0.826, train_accu 0.812 , valid_accu 0.710, dt= 1.21\n",
      "epoch 304 || train_loss 0.739, valid_loss 0.827, train_accu 0.811 , valid_accu 0.710, dt= 1.18\n",
      "epoch 305 || train_loss 0.740, valid_loss 0.828, train_accu 0.810 , valid_accu 0.710, dt= 1.21\n",
      "epoch 306 || train_loss 0.742, valid_loss 0.828, train_accu 0.809 , valid_accu 0.708, dt= 1.20\n",
      "epoch 307 || train_loss 0.741, valid_loss 0.828, train_accu 0.809 , valid_accu 0.709, dt= 1.19\n",
      "epoch 308 || train_loss 0.741, valid_loss 0.827, train_accu 0.809 , valid_accu 0.710, dt= 1.08\n",
      "epoch 309 || train_loss 0.739, valid_loss 0.830, train_accu 0.811 , valid_accu 0.707, dt= 1.09\n",
      "epoch 310 || train_loss 0.738, valid_loss 0.833, train_accu 0.812 , valid_accu 0.704, dt= 1.10\n",
      "epoch 311 || train_loss 0.739, valid_loss 0.833, train_accu 0.811 , valid_accu 0.702, dt= 1.10\n",
      "epoch 312 || train_loss 0.738, valid_loss 0.832, train_accu 0.812 , valid_accu 0.703, dt= 1.20\n",
      "epoch 313 || train_loss 0.738, valid_loss 0.830, train_accu 0.812 , valid_accu 0.707, dt= 1.20\n",
      "epoch 314 || train_loss 0.739, valid_loss 0.832, train_accu 0.812 , valid_accu 0.703, dt= 1.21\n",
      "epoch 315 || train_loss 0.737, valid_loss 0.830, train_accu 0.813 , valid_accu 0.707, dt= 1.21\n",
      "epoch 316 || train_loss 0.737, valid_loss 0.825, train_accu 0.813 , valid_accu 0.711, dt= 1.11\n",
      "epoch 317 || train_loss 0.738, valid_loss 0.834, train_accu 0.812 , valid_accu 0.703, dt= 1.05\n",
      "epoch 318 || train_loss 0.738, valid_loss 0.829, train_accu 0.812 , valid_accu 0.707, dt= 1.05\n",
      "epoch 319 || train_loss 0.736, valid_loss 0.831, train_accu 0.814 , valid_accu 0.704, dt= 1.10\n",
      "epoch 320 || train_loss 0.738, valid_loss 0.826, train_accu 0.812 , valid_accu 0.709, dt= 1.12\n",
      "epoch 321 || train_loss 0.736, valid_loss 0.831, train_accu 0.815 , valid_accu 0.705, dt= 1.19\n",
      "epoch 322 || train_loss 0.737, valid_loss 0.830, train_accu 0.814 , valid_accu 0.707, dt= 1.21\n",
      "epoch 323 || train_loss 0.737, valid_loss 0.829, train_accu 0.814 , valid_accu 0.707, dt= 1.20\n",
      "epoch 324 || train_loss 0.738, valid_loss 0.831, train_accu 0.812 , valid_accu 0.706, dt= 1.19\n",
      "epoch 325 || train_loss 0.737, valid_loss 0.833, train_accu 0.814 , valid_accu 0.703, dt= 1.10\n",
      "epoch 326 || train_loss 0.736, valid_loss 0.830, train_accu 0.814 , valid_accu 0.705, dt= 1.09\n",
      "epoch 327 || train_loss 0.735, valid_loss 0.831, train_accu 0.816 , valid_accu 0.707, dt= 1.09\n",
      "epoch 328 || train_loss 0.737, valid_loss 0.832, train_accu 0.814 , valid_accu 0.704, dt= 1.09\n",
      "epoch 329 || train_loss 0.738, valid_loss 0.831, train_accu 0.813 , valid_accu 0.705, dt= 1.15\n",
      "epoch 330 || train_loss 0.736, valid_loss 0.833, train_accu 0.814 , valid_accu 0.703, dt= 1.18\n",
      "epoch 331 || train_loss 0.735, valid_loss 0.834, train_accu 0.816 , valid_accu 0.702, dt= 1.21\n",
      "epoch 332 || train_loss 0.737, valid_loss 0.831, train_accu 0.813 , valid_accu 0.706, dt= 1.21\n",
      "epoch 333 || train_loss 0.739, valid_loss 0.833, train_accu 0.811 , valid_accu 0.704, dt= 1.20\n",
      "epoch 334 || train_loss 0.738, valid_loss 0.831, train_accu 0.812 , valid_accu 0.703, dt= 1.22\n",
      "epoch 335 || train_loss 0.734, valid_loss 0.830, train_accu 0.816 , valid_accu 0.707, dt= 1.21\n",
      "epoch 336 || train_loss 0.734, valid_loss 0.836, train_accu 0.817 , valid_accu 0.698, dt= 1.20\n",
      "epoch 337 || train_loss 0.733, valid_loss 0.831, train_accu 0.817 , valid_accu 0.705, dt= 1.21\n",
      "epoch 338 || train_loss 0.734, valid_loss 0.829, train_accu 0.817 , valid_accu 0.706, dt= 1.20\n",
      "epoch 339 || train_loss 0.733, valid_loss 0.829, train_accu 0.818 , valid_accu 0.708, dt= 1.20\n",
      "epoch 340 || train_loss 0.735, valid_loss 0.830, train_accu 0.815 , valid_accu 0.708, dt= 1.19\n",
      "epoch 341 || train_loss 0.737, valid_loss 0.827, train_accu 0.814 , valid_accu 0.709, dt= 1.21\n",
      "epoch 342 || train_loss 0.737, valid_loss 0.836, train_accu 0.813 , valid_accu 0.700, dt= 1.17\n",
      "epoch 343 || train_loss 0.733, valid_loss 0.831, train_accu 0.818 , valid_accu 0.705, dt= 1.08\n",
      "epoch 344 || train_loss 0.735, valid_loss 0.831, train_accu 0.816 , valid_accu 0.706, dt= 1.05\n",
      "epoch 345 || train_loss 0.733, valid_loss 0.832, train_accu 0.818 , valid_accu 0.705, dt= 1.04\n",
      "epoch 346 || train_loss 0.733, valid_loss 0.834, train_accu 0.817 , valid_accu 0.703, dt= 1.06\n",
      "epoch 347 || train_loss 0.733, valid_loss 0.832, train_accu 0.817 , valid_accu 0.704, dt= 1.09\n",
      "epoch 348 || train_loss 0.734, valid_loss 0.831, train_accu 0.816 , valid_accu 0.707, dt= 1.10\n",
      "epoch 349 || train_loss 0.734, valid_loss 0.831, train_accu 0.816 , valid_accu 0.707, dt= 1.08\n",
      "epoch 350 || train_loss 0.732, valid_loss 0.829, train_accu 0.818 , valid_accu 0.707, dt= 1.09\n",
      "epoch 351 || train_loss 0.733, valid_loss 0.832, train_accu 0.818 , valid_accu 0.704, dt= 1.09\n",
      "epoch 352 || train_loss 0.734, valid_loss 0.832, train_accu 0.817 , valid_accu 0.705, dt= 1.07\n",
      "epoch 353 || train_loss 0.731, valid_loss 0.834, train_accu 0.819 , valid_accu 0.703, dt= 1.07\n",
      "epoch 354 || train_loss 0.735, valid_loss 0.831, train_accu 0.815 , valid_accu 0.706, dt= 1.05\n",
      "epoch 355 || train_loss 0.733, valid_loss 0.832, train_accu 0.817 , valid_accu 0.704, dt= 1.07\n",
      "epoch 356 || train_loss 0.732, valid_loss 0.831, train_accu 0.819 , valid_accu 0.706, dt= 1.19\n",
      "epoch 357 || train_loss 0.734, valid_loss 0.829, train_accu 0.816 , valid_accu 0.709, dt= 1.22\n",
      "epoch 358 || train_loss 0.732, valid_loss 0.830, train_accu 0.819 , valid_accu 0.708, dt= 1.20\n",
      "epoch 359 || train_loss 0.733, valid_loss 0.832, train_accu 0.818 , valid_accu 0.704, dt= 1.20\n",
      "epoch 360 || train_loss 0.732, valid_loss 0.833, train_accu 0.819 , valid_accu 0.703, dt= 1.10\n",
      "epoch 361 || train_loss 0.731, valid_loss 0.831, train_accu 0.820 , valid_accu 0.704, dt= 1.08\n",
      "epoch 362 || train_loss 0.730, valid_loss 0.834, train_accu 0.820 , valid_accu 0.702, dt= 1.09\n",
      "epoch 363 || train_loss 0.732, valid_loss 0.830, train_accu 0.818 , valid_accu 0.708, dt= 1.08\n",
      "epoch 364 || train_loss 0.732, valid_loss 0.832, train_accu 0.818 , valid_accu 0.705, dt= 1.08\n",
      "epoch 365 || train_loss 0.731, valid_loss 0.829, train_accu 0.819 , valid_accu 0.708, dt= 1.09\n",
      "epoch 366 || train_loss 0.732, valid_loss 0.831, train_accu 0.819 , valid_accu 0.704, dt= 1.09\n",
      "epoch 367 || train_loss 0.731, valid_loss 0.832, train_accu 0.820 , valid_accu 0.704, dt= 1.09\n",
      "epoch 368 || train_loss 0.728, valid_loss 0.829, train_accu 0.822 , valid_accu 0.708, dt= 1.09\n",
      "epoch 369 || train_loss 0.728, valid_loss 0.833, train_accu 0.822 , valid_accu 0.704, dt= 1.19\n",
      "epoch 370 || train_loss 0.730, valid_loss 0.836, train_accu 0.820 , valid_accu 0.700, dt= 1.20\n",
      "epoch 371 || train_loss 0.733, valid_loss 0.833, train_accu 0.817 , valid_accu 0.704, dt= 1.19\n",
      "epoch 372 || train_loss 0.733, valid_loss 0.833, train_accu 0.817 , valid_accu 0.704, dt= 1.22\n",
      "epoch 373 || train_loss 0.738, valid_loss 0.829, train_accu 0.812 , valid_accu 0.709, dt= 1.16\n",
      "epoch 374 || train_loss 0.734, valid_loss 0.830, train_accu 0.816 , valid_accu 0.708, dt= 1.08\n",
      "epoch 375 || train_loss 0.731, valid_loss 0.833, train_accu 0.820 , valid_accu 0.704, dt= 1.07\n",
      "epoch 376 || train_loss 0.729, valid_loss 0.830, train_accu 0.821 , valid_accu 0.707, dt= 1.06\n",
      "epoch 377 || train_loss 0.729, valid_loss 0.834, train_accu 0.822 , valid_accu 0.701, dt= 1.06\n",
      "epoch 378 || train_loss 0.729, valid_loss 0.837, train_accu 0.822 , valid_accu 0.700, dt= 1.22\n",
      "epoch 379 || train_loss 0.734, valid_loss 0.830, train_accu 0.817 , valid_accu 0.706, dt= 1.21\n",
      "epoch 380 || train_loss 0.730, valid_loss 0.829, train_accu 0.821 , valid_accu 0.708, dt= 1.20\n",
      "epoch 381 || train_loss 0.728, valid_loss 0.832, train_accu 0.822 , valid_accu 0.704, dt= 1.19\n",
      "epoch 382 || train_loss 0.729, valid_loss 0.829, train_accu 0.822 , valid_accu 0.708, dt= 1.20\n",
      "epoch 383 || train_loss 0.729, valid_loss 0.835, train_accu 0.822 , valid_accu 0.702, dt= 1.20\n",
      "epoch 384 || train_loss 0.734, valid_loss 0.833, train_accu 0.817 , valid_accu 0.704, dt= 1.21\n",
      "epoch 385 || train_loss 0.733, valid_loss 0.837, train_accu 0.818 , valid_accu 0.699, dt= 1.20\n",
      "epoch 386 || train_loss 0.728, valid_loss 0.827, train_accu 0.823 , valid_accu 0.709, dt= 1.20\n",
      "epoch 387 || train_loss 0.729, valid_loss 0.829, train_accu 0.822 , valid_accu 0.708, dt= 1.21\n",
      "epoch 388 || train_loss 0.727, valid_loss 0.833, train_accu 0.824 , valid_accu 0.703, dt= 1.22\n",
      "epoch 389 || train_loss 0.727, valid_loss 0.835, train_accu 0.824 , valid_accu 0.700, dt= 1.22\n",
      "epoch 390 || train_loss 0.730, valid_loss 0.829, train_accu 0.820 , valid_accu 0.708, dt= 1.22\n",
      "epoch 391 || train_loss 0.728, valid_loss 0.829, train_accu 0.822 , valid_accu 0.707, dt= 1.21\n",
      "epoch 392 || train_loss 0.727, valid_loss 0.834, train_accu 0.823 , valid_accu 0.703, dt= 1.19\n",
      "epoch 393 || train_loss 0.727, valid_loss 0.834, train_accu 0.823 , valid_accu 0.702, dt= 1.20\n",
      "epoch 394 || train_loss 0.732, valid_loss 0.829, train_accu 0.818 , valid_accu 0.708, dt= 1.23\n",
      "epoch 395 || train_loss 0.727, valid_loss 0.830, train_accu 0.824 , valid_accu 0.708, dt= 1.21\n",
      "epoch 396 || train_loss 0.726, valid_loss 0.826, train_accu 0.824 , valid_accu 0.711, dt= 1.19\n",
      "epoch 397 || train_loss 0.727, valid_loss 0.828, train_accu 0.824 , valid_accu 0.710, dt= 1.20\n",
      "epoch 398 || train_loss 0.727, valid_loss 0.831, train_accu 0.824 , valid_accu 0.704, dt= 1.21\n",
      "epoch 399 || train_loss 0.725, valid_loss 0.828, train_accu 0.825 , valid_accu 0.708, dt= 1.20\n",
      "epoch 400 || train_loss 0.726, valid_loss 0.827, train_accu 0.825 , valid_accu 0.710, dt= 1.12\n",
      "epoch 401 || train_loss 0.727, valid_loss 0.831, train_accu 0.823 , valid_accu 0.707, dt= 1.08\n",
      "epoch 402 || train_loss 0.729, valid_loss 0.834, train_accu 0.821 , valid_accu 0.704, dt= 1.09\n",
      "epoch 403 || train_loss 0.729, valid_loss 0.832, train_accu 0.822 , valid_accu 0.705, dt= 1.09\n",
      "epoch 404 || train_loss 0.727, valid_loss 0.831, train_accu 0.824 , valid_accu 0.707, dt= 1.09\n",
      "epoch 405 || train_loss 0.726, valid_loss 0.828, train_accu 0.824 , valid_accu 0.709, dt= 1.08\n",
      "epoch 406 || train_loss 0.725, valid_loss 0.830, train_accu 0.826 , valid_accu 0.707, dt= 1.09\n",
      "epoch 407 || train_loss 0.726, valid_loss 0.830, train_accu 0.824 , valid_accu 0.707, dt= 1.12\n",
      "epoch 408 || train_loss 0.726, valid_loss 0.831, train_accu 0.825 , valid_accu 0.707, dt= 1.19\n",
      "epoch 409 || train_loss 0.725, valid_loss 0.833, train_accu 0.825 , valid_accu 0.702, dt= 1.22\n",
      "epoch 410 || train_loss 0.727, valid_loss 0.828, train_accu 0.823 , valid_accu 0.709, dt= 1.20\n",
      "epoch 411 || train_loss 0.726, valid_loss 0.827, train_accu 0.824 , valid_accu 0.709, dt= 1.21\n",
      "epoch 412 || train_loss 0.726, valid_loss 0.829, train_accu 0.825 , valid_accu 0.708, dt= 1.21\n",
      "epoch 413 || train_loss 0.729, valid_loss 0.838, train_accu 0.822 , valid_accu 0.699, dt= 1.22\n",
      "epoch 414 || train_loss 0.727, valid_loss 0.831, train_accu 0.823 , valid_accu 0.706, dt= 1.19\n",
      "epoch 415 || train_loss 0.726, valid_loss 0.832, train_accu 0.824 , valid_accu 0.705, dt= 1.21\n",
      "epoch 416 || train_loss 0.726, valid_loss 0.832, train_accu 0.825 , valid_accu 0.705, dt= 1.17\n",
      "epoch 417 || train_loss 0.725, valid_loss 0.831, train_accu 0.825 , valid_accu 0.706, dt= 1.08\n",
      "epoch 418 || train_loss 0.724, valid_loss 0.829, train_accu 0.826 , valid_accu 0.708, dt= 1.09\n",
      "epoch 419 || train_loss 0.724, valid_loss 0.831, train_accu 0.826 , valid_accu 0.706, dt= 1.08\n",
      "epoch 420 || train_loss 0.725, valid_loss 0.831, train_accu 0.826 , valid_accu 0.706, dt= 1.08\n",
      "epoch 421 || train_loss 0.725, valid_loss 0.829, train_accu 0.826 , valid_accu 0.708, dt= 1.07\n",
      "epoch 422 || train_loss 0.727, valid_loss 0.831, train_accu 0.824 , valid_accu 0.707, dt= 1.07\n",
      "epoch 423 || train_loss 0.729, valid_loss 0.834, train_accu 0.822 , valid_accu 0.702, dt= 1.08\n",
      "epoch 424 || train_loss 0.726, valid_loss 0.831, train_accu 0.825 , valid_accu 0.707, dt= 1.08\n",
      "epoch 425 || train_loss 0.728, valid_loss 0.833, train_accu 0.822 , valid_accu 0.703, dt= 1.09\n",
      "epoch 426 || train_loss 0.725, valid_loss 0.831, train_accu 0.825 , valid_accu 0.706, dt= 1.08\n",
      "epoch 427 || train_loss 0.725, valid_loss 0.834, train_accu 0.826 , valid_accu 0.702, dt= 1.09\n",
      "epoch 428 || train_loss 0.723, valid_loss 0.836, train_accu 0.828 , valid_accu 0.701, dt= 1.10\n",
      "epoch 429 || train_loss 0.723, valid_loss 0.834, train_accu 0.827 , valid_accu 0.702, dt= 1.11\n",
      "epoch 430 || train_loss 0.723, valid_loss 0.832, train_accu 0.828 , valid_accu 0.704, dt= 1.18\n",
      "epoch 431 || train_loss 0.725, valid_loss 0.834, train_accu 0.825 , valid_accu 0.702, dt= 1.20\n",
      "epoch 432 || train_loss 0.724, valid_loss 0.832, train_accu 0.826 , valid_accu 0.705, dt= 1.18\n",
      "epoch 433 || train_loss 0.723, valid_loss 0.835, train_accu 0.827 , valid_accu 0.701, dt= 1.21\n",
      "epoch 434 || train_loss 0.723, valid_loss 0.833, train_accu 0.828 , valid_accu 0.704, dt= 1.12\n",
      "epoch 435 || train_loss 0.722, valid_loss 0.831, train_accu 0.829 , valid_accu 0.706, dt= 1.09\n",
      "epoch 436 || train_loss 0.724, valid_loss 0.837, train_accu 0.826 , valid_accu 0.700, dt= 1.09\n",
      "epoch 437 || train_loss 0.724, valid_loss 0.830, train_accu 0.826 , valid_accu 0.708, dt= 1.09\n",
      "epoch 438 || train_loss 0.724, valid_loss 0.830, train_accu 0.827 , valid_accu 0.707, dt= 1.15\n",
      "epoch 439 || train_loss 0.728, valid_loss 0.830, train_accu 0.823 , valid_accu 0.707, dt= 1.20\n",
      "epoch 440 || train_loss 0.723, valid_loss 0.831, train_accu 0.827 , valid_accu 0.706, dt= 1.22\n",
      "epoch 441 || train_loss 0.724, valid_loss 0.833, train_accu 0.827 , valid_accu 0.705, dt= 1.23\n",
      "epoch 442 || train_loss 0.723, valid_loss 0.831, train_accu 0.827 , valid_accu 0.706, dt= 1.21\n",
      "epoch 443 || train_loss 0.722, valid_loss 0.833, train_accu 0.829 , valid_accu 0.703, dt= 1.21\n",
      "epoch 444 || train_loss 0.722, valid_loss 0.831, train_accu 0.829 , valid_accu 0.707, dt= 1.20\n",
      "epoch 445 || train_loss 0.722, valid_loss 0.830, train_accu 0.829 , valid_accu 0.707, dt= 1.20\n",
      "epoch 446 || train_loss 0.722, valid_loss 0.832, train_accu 0.828 , valid_accu 0.704, dt= 1.21\n",
      "epoch 447 || train_loss 0.723, valid_loss 0.831, train_accu 0.828 , valid_accu 0.707, dt= 1.22\n",
      "epoch 448 || train_loss 0.724, valid_loss 0.833, train_accu 0.826 , valid_accu 0.705, dt= 1.21\n",
      "epoch 449 || train_loss 0.725, valid_loss 0.836, train_accu 0.825 , valid_accu 0.701, dt= 1.21\n",
      "epoch 450 || train_loss 0.723, valid_loss 0.835, train_accu 0.827 , valid_accu 0.702, dt= 1.21\n",
      "epoch 451 || train_loss 0.724, valid_loss 0.832, train_accu 0.826 , valid_accu 0.706, dt= 1.20\n",
      "epoch 452 || train_loss 0.722, valid_loss 0.830, train_accu 0.828 , valid_accu 0.708, dt= 1.20\n",
      "epoch 453 || train_loss 0.725, valid_loss 0.829, train_accu 0.825 , valid_accu 0.708, dt= 1.22\n",
      "epoch 454 || train_loss 0.724, valid_loss 0.832, train_accu 0.827 , valid_accu 0.705, dt= 1.21\n",
      "epoch 455 || train_loss 0.722, valid_loss 0.830, train_accu 0.829 , valid_accu 0.708, dt= 1.19\n",
      "epoch 456 || train_loss 0.722, valid_loss 0.831, train_accu 0.829 , valid_accu 0.707, dt= 1.21\n",
      "epoch 457 || train_loss 0.725, valid_loss 0.831, train_accu 0.825 , valid_accu 0.705, dt= 1.19\n",
      "epoch 458 || train_loss 0.722, valid_loss 0.830, train_accu 0.828 , valid_accu 0.708, dt= 1.18\n",
      "epoch 459 || train_loss 0.723, valid_loss 0.831, train_accu 0.827 , valid_accu 0.706, dt= 1.22\n",
      "epoch 460 || train_loss 0.722, valid_loss 0.831, train_accu 0.829 , valid_accu 0.705, dt= 1.17\n",
      "epoch 461 || train_loss 0.721, valid_loss 0.831, train_accu 0.830 , valid_accu 0.706, dt= 1.08\n",
      "epoch 462 || train_loss 0.720, valid_loss 0.832, train_accu 0.830 , valid_accu 0.706, dt= 1.08\n",
      "epoch 463 || train_loss 0.721, valid_loss 0.835, train_accu 0.830 , valid_accu 0.702, dt= 1.13\n",
      "epoch 464 || train_loss 0.721, valid_loss 0.832, train_accu 0.829 , valid_accu 0.706, dt= 1.22\n",
      "epoch 465 || train_loss 0.721, valid_loss 0.836, train_accu 0.829 , valid_accu 0.700, dt= 1.21\n",
      "epoch 466 || train_loss 0.723, valid_loss 0.833, train_accu 0.828 , valid_accu 0.705, dt= 1.23\n",
      "epoch 467 || train_loss 0.723, valid_loss 0.836, train_accu 0.827 , valid_accu 0.701, dt= 1.20\n",
      "epoch 468 || train_loss 0.723, valid_loss 0.830, train_accu 0.828 , valid_accu 0.708, dt= 1.19\n",
      "epoch 469 || train_loss 0.721, valid_loss 0.832, train_accu 0.829 , valid_accu 0.704, dt= 1.20\n",
      "epoch 470 || train_loss 0.722, valid_loss 0.831, train_accu 0.828 , valid_accu 0.706, dt= 1.20\n",
      "epoch 471 || train_loss 0.720, valid_loss 0.830, train_accu 0.831 , valid_accu 0.708, dt= 1.21\n",
      "epoch 472 || train_loss 0.719, valid_loss 0.832, train_accu 0.832 , valid_accu 0.704, dt= 1.15\n",
      "epoch 473 || train_loss 0.719, valid_loss 0.831, train_accu 0.831 , valid_accu 0.708, dt= 1.08\n",
      "epoch 474 || train_loss 0.720, valid_loss 0.832, train_accu 0.830 , valid_accu 0.704, dt= 1.08\n",
      "epoch 475 || train_loss 0.719, valid_loss 0.837, train_accu 0.832 , valid_accu 0.700, dt= 1.08\n",
      "epoch 476 || train_loss 0.720, valid_loss 0.831, train_accu 0.831 , valid_accu 0.706, dt= 1.08\n",
      "epoch 477 || train_loss 0.720, valid_loss 0.832, train_accu 0.831 , valid_accu 0.704, dt= 1.08\n",
      "epoch 478 || train_loss 0.721, valid_loss 0.833, train_accu 0.829 , valid_accu 0.704, dt= 1.10\n",
      "epoch 479 || train_loss 0.719, valid_loss 0.835, train_accu 0.832 , valid_accu 0.702, dt= 1.09\n",
      "epoch 480 || train_loss 0.719, valid_loss 0.835, train_accu 0.832 , valid_accu 0.700, dt= 1.09\n",
      "epoch 481 || train_loss 0.719, valid_loss 0.832, train_accu 0.831 , valid_accu 0.705, dt= 1.06\n",
      "epoch 482 || train_loss 0.720, valid_loss 0.833, train_accu 0.830 , valid_accu 0.705, dt= 1.08\n",
      "epoch 483 || train_loss 0.719, valid_loss 0.831, train_accu 0.831 , valid_accu 0.706, dt= 1.09\n",
      "epoch 484 || train_loss 0.719, valid_loss 0.836, train_accu 0.831 , valid_accu 0.702, dt= 1.08\n",
      "epoch 485 || train_loss 0.720, valid_loss 0.833, train_accu 0.830 , valid_accu 0.704, dt= 1.06\n",
      "epoch 486 || train_loss 0.720, valid_loss 0.833, train_accu 0.830 , valid_accu 0.703, dt= 1.05\n",
      "epoch 487 || train_loss 0.720, valid_loss 0.832, train_accu 0.831 , valid_accu 0.704, dt= 1.09\n",
      "epoch 488 || train_loss 0.720, valid_loss 0.835, train_accu 0.831 , valid_accu 0.700, dt= 1.06\n",
      "epoch 489 || train_loss 0.721, valid_loss 0.837, train_accu 0.830 , valid_accu 0.699, dt= 1.05\n",
      "epoch 490 || train_loss 0.719, valid_loss 0.834, train_accu 0.832 , valid_accu 0.703, dt= 1.13\n",
      "epoch 491 || train_loss 0.720, valid_loss 0.834, train_accu 0.830 , valid_accu 0.702, dt= 1.21\n",
      "epoch 492 || train_loss 0.719, valid_loss 0.833, train_accu 0.832 , valid_accu 0.703, dt= 1.20\n",
      "epoch 493 || train_loss 0.722, valid_loss 0.833, train_accu 0.828 , valid_accu 0.705, dt= 1.20\n",
      "epoch 494 || train_loss 0.721, valid_loss 0.835, train_accu 0.830 , valid_accu 0.703, dt= 1.19\n",
      "epoch 495 || train_loss 0.719, valid_loss 0.831, train_accu 0.831 , valid_accu 0.706, dt= 1.21\n",
      "epoch 496 || train_loss 0.721, valid_loss 0.835, train_accu 0.830 , valid_accu 0.702, dt= 1.20\n",
      "epoch 497 || train_loss 0.718, valid_loss 0.835, train_accu 0.833 , valid_accu 0.702, dt= 1.19\n",
      "epoch 498 || train_loss 0.719, valid_loss 0.834, train_accu 0.831 , valid_accu 0.703, dt= 1.21\n",
      "epoch 499 || train_loss 0.718, valid_loss 0.834, train_accu 0.833 , valid_accu 0.702, dt= 1.20\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+oAAAFrCAYAAABG7XOGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACfv0lEQVR4nOzdeXxU1d3H8c+dyR5IICxJQGRHG4GwKIigrBpEcfdRXEsrrVhalVYFCwS0SK0VsYqiFh4X6q51eaRURNEqKBVEjQiyBBGSAAmQQCCTZGaeP25mSybJZJnMJPm+X6+8yNyce+fcyZA7v3t+53cMp9PpRERERERERETCgiXUHRARERERERERDwXqIiIiIiIiImFEgbqIiIiIiIhIGFGgLiIiIiIiIhJGFKiLiIiIiIiIhBEF6iIiIiIiIiJhRIG6iIiIiIiISBhRoC4iIiIiIiISRiJC3YFQcDgc5OTk0LZtWwzDCHV3REREcDqdHDt2jC5dumCx6D56Q+laLyIi4aYu1/pWGajn5OTQrVu3UHdDRESkip9++olTTjkl1N1o9nStFxGRcBXItb5VBupt27YFzBcoISEhxL0RERGBoqIiunXr5r5GScPoWi8iIuGmLtf6Vhmou1LgEhISdPEWEWlkTqcTm80W6m40C9HR0VXSspWm3Tj8Xev13qwbf+9PERFpuED+trbKQF1ERIInJyeHoqKiUHejWUhISKBr166h7karofdm3ej9KSISOgrURUSk0ZSXl1NUVESHDh2qzViyO5x8+eNRDh230alNNGd2b4fV0vpG7YqKiigoKCA5OZmICF2Og03vzbrR+1NEJLT0l1dERBpNeXk5YM4PjomJqfLz1Vm5LHh3K7mFJe5tqYkxZE5OY2L/1CbrZzhwOp0UFBRQXl6uQKgJ6L1ZN3p/ioiEVlDXf/nkk0+YPHkyXbp0wTAM3nrrrRrb5+bmct1119GvXz8sFgt33HGH33avvfYap59+OjExMQwYMIBVq1Y1fudFRKTe/M29Wp2Vy/SVm30CIYC8whKmr9zM6qzcGo958uRJbr31Vi655BLOPfdcbr31Vnbt2oXT6azS9q677qrxWOvWrePxxx8P4EyCR3N/QyPc35vhQu9PEZHQCuot0uLiYtLT0/nFL37BFVdcUWt7m81Gp06dmDNnDo888ojfNuvXr2fKlCksWrSIiy++mBdffJHLLruMzZs3079//8Y+BRERqQen08mJ0nL3Y7vDSeY731E1bAEnYADz39nKyD4d3anGsZFWn2AhNjaWZcuWsW7dOrKysnjppZd47bXXmDJlCk8//TQFBQVMnDiRyy67jOzsbAAGDBjAz3/+czZt2sTy5cuJjY31ee6CggLuuOMOEhISGDhwIFdccQW/+c1v6NGjBxdffDH79u1j3bp1tG3blgceeIDo6OjGfqmkiYX7ezMnJ4elS5f67HPXXXdRXl7Oqaeeym9/+1tuu+022rZt6z6GiIi0PEEN1C+88EIuvPDCgNv36NGDRx99FIAVK1b4bfPoo48yceJE9x3p+++/nzVr1vD444+zbNmyhndaREQa7GSZgyEL/h1weyeQV1TCgPnvu7dtvS+DuKjqL1NpaWnMmjWLgwcPYrPZSE5O5h//+AeXXXaZu80pp5zC73//ex577DG2bNnCiBEjfI7x0ksv8Ytf/IKxY8dy9dVXM378eKxWK5dddhkjRozgT3/6EwMHDuTSSy9VkN5ChPt7MyIiwmeffv36ERUVxUMPPQTAqlWrOOuss5g2bVrdTlxERJqVZjfpaMOGDcycOdNnW0ZGRo1p9TabzWc5lsaq+Gp3ONmYfZiDx0ro3DaGYT2TWm3RGRGRppaYmAjACy+8wCWXXMLw4cO59NJLfdrEx8cDEBkZ6XdZLqfT6TMy2qdPH/72t7/x5ptvsmbNGjIzM/n666+56667uP/+++nbt28Qz0haioa8Nyvv43Q6sVg8MxUrPxYREZMrNssrPMnh4lKS2kSTkhDDoG7tePGLH/nx8Am6J8Vx44geREVYatyvc5toMOBgUYnPsZoy3mt2gXpeXh7Jyck+25KTk8nLy6t2n0WLFrFgwYJG7Ye/ojNxURYmnpFMcmIs+w+fIP94KSXldqKtFgzDqPJ9TISVDvFRFBRX385md9CtfRxXDjmFc7zS7kREwllspIWt92W4H2/MPszP//e/te737NSzGNYzqeIY1oCe65xzzmHZsmV89tlnREVF1amfU6ZM4c477+TNN99k7NixfPvttyxfvpySkhImTJjA008/zY4dO7BYLHTo0KFOx5bwFO7vzcr7nHHGGZw8eZK77rqL7t278+tf/5rf/OY3/PDDDwwcOJDRo0ezdOlSFi1aFNDxRUSaq5oGSVd9k8uct7M4XFxa63Huf+97OreJpHenNhw5UUZ2wQls5Y6A+tCURUYNp79KJ8F4IsPgn//8p0/aV03GjBnDoEGDWLJkic/2qKgonnvuOaZMmeLe9sQTT7BgwQIOHDjg91j+RtS7detGYWFhtUu01MRVdKZJXjgv8VFWHv6f9FZZfVZEmoeSkhKys7Pp2bOnT2Vtu8PJqAc/JK+wxO/fTgNISYzh03vGtZobkpVfq6KiIhITE+t9bRJflV9PvTfrprrXS0QkUNUF1naHk/U78nl980/sP1rCKe1j3YOSgHt0O/+4jcMnSsk9WsLJMjvrdxVwrMRTYyQmwsKY0zphMQxWZVU/aNvYDODJG4bUKyary7W+2Y2op6SkVAnIDxw4QEpKSrX7REdHN9rcQrvDyYJ3tzZ5kA5QXGrn1pWbWVbPN4aISKhYLQaZk9OYvnIzBvj8DXWFPpmT01pVICThQe9NEZGGsTucfL6rgM92HSLnaAmp7WI4UGjj31vzKLbZ3e3iIi2ktothT8EJ7F4D2F/+eIS3tuRgNSA60sqJUrufZ6mqpNzB6u/8D9QGkxNY8O5Wzk9LCeq1odkF6iNGjGDt2rU+S7etWbOmSoGgYNmYfbjK8i1NrSneGCIijW3i6Uk8ef1gFvzf9z5/R1Na8VrVEh703hSR1sAVUG/YnQ8YjOjdgbN6JLHpxyPuEeyjJ8twOqF9XBQd25pztR1OJ5/tOsQ3PxVSUm4nNjKC9FPaMbJvR/KP27jnjW8oKas9dfxEmYNdh05U3z8nAQfpoZZbWMLG7MOM6B28aXFBDdSPHz/Ozp073Y+zs7PZsmULSUlJnHrqqcyePZv9+/fz/PPPu9ts2bLFve+hQ4fYsmULUVFRpKWlAXD77bczevRoHn74YS666CJefvllvvzyS55++ulgnorbwWOhDdKhad4YIiKNqnAfPD2WiYldOf/KOWy0DOfgcZsKcUro6b0pIi1A5SB8eM8kLBaDg0UlHDxWwgdbD7D5p6M+I9mPf7SzSiZRoD7bVcATH+9qpN43T8GOC4MaqH/55ZeMHTvW/dhVrf3mm2/m2WefJTc3l7179/rsM3jwYPf3mzZt4sUXX6R79+7s2bMHMIusvPjii8yZM4d7772Xvn378tZbbzXZGuqd24bHPK1wuGEgIhKw4nwoPgjF+VhfvJIRXQbDuDnQazwYCoQkhPTeFJEw4W/E++xeHdzzul0/czghMTaSoyc987c//uGQz6j24x8F9pyhmM7bUgQ7LgxqoD5mzBhqqlX37LPPVtkWSG27q6++mquvvrohXau3YT2TSI6DIyd8KwqWEolrNlsUZYDTvc37cRTluP5LuH4ezwnKsAIGkZRRRgSlROGZHVdVuNwwEBHxy+mE0mLP4/KTFd9UfIjI/QZWXgmp6TD6Hug5umpQFBnns+2KK67gxRdfJCYmhm+//ZaVK1fy4IMP+uxy1VVX8frrr3PXXXe5150G83rTsWNHLr74Yp/269atIysrixkzZrBs2TLOP/98evfuHfBpzp8/n6uuuqrJbhZLI2gl700RCW+l5Q5e2LDHvWRY54QY5r6dxdETZe42j3+0k7goC2P6deLDbYcoCbAyuQRfh/go90ogwdLs5qiHmvXYfj6JuA1LdBGG+x6UwV5nJ/5Ufj0/OjrzavRCEjjBT84OLC2/hHsjXyGBYnKc7WlvFBNLKQaw19mJf5SP497Il9xpJ64V/fKc7bmnfBqfONKpHLCnJsYE/Y0hItIgZSfgwV7V/9xZMQct92t4+Tr/be7Ngah498Mrr7ySN954g+uvv54VK1YwdepU5syZw9GjR0lPT2fatGnuttnZ2QDMmjULp9PJ9u3bueWWW/jss8949913ycvLY86cOXz66aesX7+edu3akZeXx8mTJ/n888954oknALjtttsoKSlh8eLFjBo1itzcXB555JEqXfW3z4oVK0hOTmbmzJn87W9/o6SkhG7durmzyyREWsl7s/LxOnXqxO9+9zs6duzI6NGjSU9PZ86cOXTu3JnLL7+cUaNG1fMFFZHKqluX2+F08kV2AZ/uzOfrnwoDGs0+UepgVVbTF0yTmt1/af+gT41SoF5XxflElx6tFDs76WUcYEXUYpxOz032XsZBHo76u7tVd6PA51C9jAPMjXrJ79OkGkd4Puov5DqqBuyqPisirdGVV17JDTfcwNVXX82PP/5I3759KS8vJykpiVdffdUnGAIoLCwkLy+PZ5991j26GRUVRWlpKXFxcbz55puMGjWKdu3accMNNzB//nwAHnvsMZYvXw7AtGnT+OUvf8nIkSO5++67fZYG9VZ5nwsuuIDu3btz4403kpqayr59+7jkkkvIyMjwu780b+H43qx8vDZt2nDDDTdw/vnnA3D33Xczb948+vbtG+RXR6Rl8K5svv/ISQzDoGv7WM7uadaM2rA7n/1HTpJbWMJ3uUU+1c6lZfn1eT2ZNDD4RUYVqDeyxp7OlmrxBOyZxq+54qqbVX1WRMJfZJw56uiS9w2smFi1nWE1RzBT02HMbOh5nu8xvMTExJCamsojjzzCZZddxqpVq0hLS+Omm27yqYfiLSoqCsC9ROeDDz7ISy+9xPr16/noo4+wWCxV9nE6nRgVf8xd07Hi4+N9Hte2z4033siOHTtYsmQJV111FStWrOCzzz7j2muvZdWqVX6PIU2klbw3Kx8vPj7e55hOp9Pvc4i0JpXX+R7avT2bfjxS5fGarXm8+uU+jtvKqxxj6Uetu6Baa9Im2spfrhzIpIFdmuT5FKg3E6mWIzzNn+H95yHuCejt/8IvIhIWDMMnNZiI2Eo/dwVBA83CXb0DK9w1depULrjgAn766Sdyc3OZNWsWubm52O1VRy4SExNJTU3l4Ycf5rPPPqNPnz6MHj2azMxMiouLad++Pf369WPx4sXuYAdgxowZ3HrrrYCZXlxaWlrl2JVV3uf111/n888/5+jRo5xyyin88Y9/xOFw0KtXDSnX0jRayXuz8vGuv/567rjjDtasWcO5557Lbbfdxvz580lNTeWSSy5h//79REdHc8kll9R6riLNUeVibAeKSvjg+4MUniyrfWdptiKtBmV2z43M2AiDU5PiiI+J4HhJOXsKTlJqr37uf6QFxv8smRtH9HAX9msqhjOQ6m0tTFFREYmJiRQWFpKQkFC3nXO2wNOjg9KvgHU8DWZsDG0fRET8KCkpITs7m549exIT41X00v230wI4wFVZO8AgqCWq/Fo16NokVVR+PfXerJtqXy+RJuA90t0xPhoMyPdaNhGotgJ61/axnNO7o8/64P/ZcYh3v8n1CdikeUuMiaCwpGqGg0tqYgyZk9M4Py3FJ2ui8rKbld9rrjoClavuN5a6XOs1ot7MONt2wbjwwdobioiEk/hO0KYzJHRVECThRe9NkZCpnHo+rGcSa7bmMf+dreQV+V+KuF1cJKXlDk6UVj8HfOlHu+q9Prg0rbhICyfLHQQ6dJwUH8mfLu3PpIFdKC138Nz6bP675whxkRbSuiTSKSGGlATfgHxE7w7VHs9qMar8/Nx+nep9Po1JgXozccQZz+1lv2GHbTiZJ0/Hz2w6EZGwcfLkSd8N0R3g1i/BGmUGQTZbaDoWRqq8RtIk9N4MjN6f0hi8q5/nH7eRX2wja18RsVEWSsudfL2v0Cf1PMpqUFrLqLf38mU1UZAeOlcN6UpcdATd2sdSdLKMx/zM43fdDl18zSDGnZ7MCxv2kF1QjAGkn9KOwpNl7mr5lTMqXAF4VISFaef1Ztp5VQ7fIihQD3M2p5Vow87sslv4xDEIo8jG9JWbefKGISoqJyJhJyoqipiYGPLy8kLdlWYhJibGXVRMgkvvzbrT+7P1qa2yuXdK8JBT2/PiFz+61wG/bnh3Nv94hM92HSLnaAkny+ys31XAsRrSkyurLUiX4Eo/pS2TBnTlq5+O8J8fDlFc6pm73T4ukoWX9cdiMarNeHClm1eOUc7omsiCd7eSW+jZJ6VS21+eqxoulWmOel3nARbuh6fOhZNHwekgGPfrnMAhkvhD6S3cFvEOZ1u28ZvS3/Ge42zAvAOVkhjDp/eM0zJtIhJ2HA5HQAXYxAweXZW3NUe9cfl7PfXerBvv96e0HN5F1cBgeMWc75Vf/MiH2w5qHncL5poO0C4u0iczwTud3MXftARX3OFvnfjK6eaV1XS81kRz1IMpsSvM/B6cTsj9Blac779dz3GQ/aH5fVwnsJdA2UlodyqMnAlr5oGtsOKYp8IFC6HPOLCX8sWPx7j22S2Awa+d7wFgxXNHywnkFpawMftwjXMuRERCwWKxqPiUhCW9N6Wlc83Z3Zh9mBO2cjq2jeGUJLO42pBT2zPnrW95e0sO5Q5PMP74RyHssATN+NM78dVPhRwu9tycTAmwwBr4n7sdyM+qU599WjsF6vUREV3xb3XpYIYZpKcMgDFz4LQMsJeawX1EtDkHLv1/cFdNcG0DIJYDJcdxzdywY97JtlB12YCDx/wX2RARERGR5q/yHO+jJ8uwO5wUnSzjYJGNkjI7A09px8i+HVm3/SB//0+231xPrfUd3tJPaUv3pHgKisvILTzJ7vwT9T5W+7hIFl0xgIn9U2scxVbQHP4UqAdFxZ/IvG/hg3lw+kRPcO9S+bGXzm09d/sdFYG61U+g7t1ORERERMKTvyWgNuzO95kHPqx7Ej8cPM5PR07QrX0sx0rKeX7DjxytZZ3vT3cV8MTHCsSbo+pSzkf++cNqq9679pt78Rl0blPzcmIaxW7eFKgHg2EFp91ci3V8Zp13H9YzidTEGPIKSzwj6oYnUHfNUXetIykiItIcLF26lIceeoi8vDzS09N57LHHGDZsWLXtlyxZwpNPPsnevXvp2LEjV111FYsWLVL6uoQtfyOY/87KY87bWT4pyP4sRcF2cxcfZeUXo3qQEBPFT0c8Rfa2/HS02jXh/aWcz78kjekrNwO+1bBcLR+4fIBPwbZwWU5MGpcC9cbkCtBTBzZoLVarxSBzsvkftPKIuutomZPTWmUBBhERaZ5eeeUVZs6cybJlyxg+fDhLliwhIyOD7du307lz5yrtX3zxRWbNmsWKFSs455xz+OGHH/j5z3+OYRgsXrw4BGcg4lHd+t+VK1tHWAyf+eDSckw7twdj+iW7i/JVHs32VtdR7Yn9U3nyhiG1VkqXlk2BeqOwAI4GB+jeXP9BI9+MAIcnUNd/UBERaY4WL17MtGnTmDp1KgDLli3jvffeY8WKFcyaNatK+/Xr1zNy5Eiuu+46AHr06MGUKVP44osvmrTfIi52h5P1O/L524c/sGVfoU919Pgoi89SVi4K0sOL1YBLB6VyafopfLGngJyjJe7l5ywWwz3SPbR7ezb9eIQ1W/N4a0uOTzZE5XT1kX07BqWvE/unBlT0TVouBeoNEd8J2nSGhK6NFqB7m9g/Fed3KfC9WUxu6XVDmNg/Rf9BRUSkWSktLWXTpk3Mnj3bvc1isTBhwgQ2bNjgd59zzjmHlStXsnHjRoYNG8bu3btZtWoVN954o9/2NpsNm83mflxUVNS4JyGtUmm5gxc27OHjHYdYv7Og2sDbX5AuTc+1/Fhl0REG00f35rfj+7k/R48+vWomj7cRvTswoncH/nhRWsiCZc0xb90UqDdEYle4IwusUY0aoHszLFbAHFEffGo7BekiItLs5OfnY7fbSU5O9tmenJzMtm3b/O5z3XXXkZ+fz6hRo3A6nZSXl3Prrbdy7733+m2/aNEiFixY0Oh9l5bPta74Z7sO+YywvrRxL//KyvMb+EnwxURYKCmv/QZI25gI/mfoKUxIS2Fo9/b8N/uwz+/ynN4dq01JD4SCZQkVBeoNVUP19kbhDtTt2JU+JSIircS6det44IEHeOKJJxg+fDg7d+7k9ttv5/7772fu3LlV2s+ePZuZM2e6HxcVFdGtW7em7LI0A97LnR0uLmXf0ZO89uU+jtvKfdppObPgSUmIZsqwUzk1KY7DxaW0i4vi6AnPv0ltoklJMNPPRz/0kc8c7cqS4iP5fPYEoiIs7m0j+3YMWjq6SFNSoB7uDM+IulNxuoiINEMdO3bEarVy4MABn+0HDhwgJSXF7z5z587lxhtv5JZbbgFgwIABFBcX86tf/Yo//vGPWCwWn/bR0dFERwf55rmErcoBuCvY805TfvfrHO7957ccKymv5WhSF9FWuPmcnnyXU0RctJW20ZGs236Iwyd853VfPqgrE9JS6pQ67iquDNVXP/cO0kVaEgXq4c49ou7EoUhdRESaoaioKIYOHcratWu57LLLAHA4HKxdu5YZM2b43efEiRNVgnGr1bwmOnU9bPW8A/NPd+az+rs8im32Ku3io61MG9WTb/cXsXbbwRD0tHkZcmoiOUdtPmt4t4m2ctzPa+vy6JQhVYoc+6uKX5/Uc1U/l9ZMgXq4MyrWUceBXR9MRESkmZo5cyY333wzZ555JsOGDWPJkiUUFxe7q8DfdNNNdO3alUWLFgEwefJkFi9ezODBg92p73PnzmXy5MnugF1atsqj5O3iojhcbOPLH4/w8Q+HKCmrff5ysc3OkrU7m6C3zZt3JfNAl55LrSFYbsx53ap+Lq2VAvVwZ/FOfVegLiIizdM111zDoUOHmDdvHnl5eQwaNIjVq1e7C8zt3bvXZwR9zpw5GIbBnDlz2L9/P506dWLy5MksXLgwVKcgTcAVJPpbFks82sVG0rtzPJt+PFptm8evHcTCf20jr7Ck2oJ47WIjWXr9EJ9ia/6C7FAHyyroJq2RAvVw55qjbjiwa+UPERFpxmbMmFFtqvu6det8HkdERJCZmUlmZmYT9EzCweqs3Cqjti3ZsB7t2Zp7rEohu+r4m+e96ptc5ryd5XNDw3ukOyLCwvSVm6ssW+YKr/985QBG9gms8JqCZZGmpUA93FWMqFtwaI66iIiINHveqdVJsVFszSvivW9y+GZ/Uai71mRSE2N46VcjAPh8VwEbducDBsN7JmGxGOQft9ExPhoMyD9uq3YEe9LAVDL6Vz/SrTneIs2XAvVw51X1XcuziYiISHPiCspzjpxg809H+HZfEdsPFGErb52faVxhdubkNHcw3dDlxGob6Q512rqI1I8C9XDnNaKuAXUREREJV94j5R3jo/kiu4AVn2XXWDG8OTIMAvpMFh9lpbjU99xDNZKttHWR5ieoCw9+8sknTJ48mS5dumAYBm+99Vat+6xbt44hQ4YQHR1Nnz59ePbZZ31+Pn/+fAzD8Pk6/fTTg3MC4aCi6rtVqe8iIiISplZ9k8tZCz9gyjOfc/vLW7h++Rf87cOdLSpIT4yN4B+3DGfplCEYeEbHK/vlyB68NO1snrh+iHvbyN4deGna2Xx6zzilm4tIQII6ol5cXEx6ejq/+MUvuOKKK2ptn52dzUUXXcStt97KP/7xD9auXcstt9xCamoqGRkZ7nZnnHEGH3zwgftxREQLTgzwqvqu5dlEREQkXLhG0J/5zy4+3HYo1N0Jul+M7OUuvPakpeq878rLlW368Yj7ZwO7tdOItojUSVAj3AsvvJALL7ww4PbLli2jZ8+ePPzwwwD87Gc/49NPP+WRRx7xCdQjIiJISUlp9P6GJcM79V2BuoiIiIRea6vQDtCjY5z7+0DmfcdHW93ft41pwYNKIhIUYfVXY8OGDUyYMMFnW0ZGBnfccYfPth07dtClSxdiYmIYMWIEixYt4tRTT632uDabDZvN5n5cVNSMqop6j6hreTYREREJAe/553vyT7Dkgx+qXZu7percNsbncW3zvmMiPIF6/jEbdodTBdxEJGBhFajn5eWRnJzssy05OZmioiJOnjxJbGwsw4cP59lnn+W0004jNzeXBQsWcO6555KVlUXbtm39HnfRokUsWLCgKU6h8XlVfdccdREREWlqLWX0PDUhmmuHdeeljXvJK/JaqiwhmpJyB4UnyvzefDAwi8AN65kU8HOtzspl3tvfuR+v+GwP/8rK05JoIhKwsArUA+GdSj9w4ECGDx9O9+7defXVV/nlL3/pd5/Zs2czc+ZM9+OioiK6desW9L42CotZTM6CA4eWZxMREZEmtDorl+krN4ft6PnUc7rz9te5HCkurbWPXdvHcfuEvswY16dKyvqarXlMX7kZA/wex3s5tdpU95rlFZYwfeVmnrxhiIJ1EalVWAXqKSkpHDhwwGfbgQMHSEhIIDY21u8+7dq1o1+/fuzcubPa40ZHRxMdHd2ofW0yPiPqIe6LiIiItAp2h5PPdxVw+8tbwjJIT0mIZv4lZzCxfyrDe3XwG2RXftymYp64v5T1if1TefKGIcx/dyt5XpkDndpGc/+lZwQcWNsdTha8u9Xva+as6NOCd7dyflqK0uBFpEZBXZ6trkaMGMHatWt9tq1Zs4YRI0ZUu8/x48fZtWsXqakt9M6kax11Q6nvIiIiEnyupdauX/4FtvLwKpAzY2wfXpp2Np/NGu8Onl1Bdkqi7xzylMQYUr22tY2JrPHYE/un8tk944iO8Hw8fnP6OXUa/d6YfbjGKQJOILewhI3ZhwM+poi0TkEdUT9+/LjPSHd2djZbtmwhKSmJU089ldmzZ7N//36ef/55AG699VYef/xx7r77bn7xi1/w4Ycf8uqrr/Lee++5j/GHP/yByZMn0717d3JycsjMzMRqtTJlypRgnkroGFqeTURERJrGwve28sx/spvs+WIiLYzp1wkwWP1dXq3t+ya38VvArboq7Fc++Zk7cC62ldda0M1qMYiLsrpvUMRH1+2j8sFjgc3jD7SdiLReQQ3Uv/zyS8aOHet+7JonfvPNN/Pss8+Sm5vL3r173T/v2bMn7733HnfeeSePPvoop5xyCn//+999lmbbt28fU6ZMoaCggE6dOjFq1Cg+//xzOnXqFMxTCR2vqu9ank1ERESCwe5w8ruXNvPet7UHyw1x+/g+DOvZgfzjNncwDXDWwjUB7V+58rq3yintq7Ny2ZpzzP34w20HGfnnD5l/Sc0F3bwDee/R9Yb2rz7tRKT1CmqgPmbMmBqDy2effdbvPl999VW1+7z88suN0bXmw2sddS3PJiIiIo1t1Te53PX61xSX2oP6PO3iIvnd+H5VRrQ37CrgcHFZrft3iI8KuPL66qxcbl25ucr2vKISbl25mWU1FHQzDE//YiKtfttUZ1jPJFITY8grLGm0CvIi0jqF1Rx18aOi6rsVp+aoi4iISKNa+N5Wbntxc9CDdICjJ8r8zs0ONA380kFdAirAZnc4mfXmtzW2mf3mt9irqdLr/RR1LfhmtRhkTk4DzKDcm+txXSrIi0jrpUA93HlXfVfZdxEREWkEdoeT6S982aTz0cF/UB5oGvj5aSkBtft8dwFHT9Q8Qn/kRBmf7y7w+zOL0bAguqbidlqaTUQCFVbLs4kfFk/qu+J0ERERaajVWbn89qWvKLM3/QcLf0F5beniAKl1SBffsMt/AO6v3cg+Hatsb2igDtUXt9NIuogESoF6uPNZR12RuoiIiNTfqm9yue3FqnO3G4NhQHUfVWqam+1KF69uLXSoa7p4oJ+Xgvu5yt967SIigVLqe7jzGVFXoC4iIiL1839bcho9SE+Kj+SXI3vw0rSzWTplCAb1m5vdmOniI3pVHSWvSzuLPh2LSBjQiHq404i6iIiINNCiVVt56pPGmY8eH23lT5cNICWhajr3k5YhLHh3q3vtcjCD7czJNS+JBo2XLn527w60i4uscZ56u7hIzq5mtNv72TbsKlDKuoiEhAL1cOdaR93Q8mwiIiJSd/+3JafRgnSAh69Orzbobmiw3Rjp4laLwZ+vGOB3eTaXP18xwG+fVmflsv+o5ybDlGc+JzXAGw0iIo1JyT3hTqnvIiIiUk//tyWHGS9/1SjHSk2MqXH9cRdXsH3poK6M6N0hJKPRE/unsuyGIaQkRPtsT0mIrvYcVmflMn3l5irLtuUVljB95WZWZ+UGtc8iIt40oh7utDybiIiI1ENjprvPGNubO88/rVmlgNdldN/ucLLg3a1+y8s5MdPhF7y7lfPTUprVayAizZcC9XBn8Z6jHuK+iIiISLOw6pvGTXcf2adTswxQA02l35h92GdefWVOILewhI3Zh1XJXUSahAL1cGco9V1EREQCZ3c4ueuNbxrlWDUtq9aSHDxWfZBen3YiIg2lOerhrmKNEFV9FxERkUCs35lPsc3e4OPUbw3z5qlz25jaG9WhnYhIQylQD3feI+rKfRcREZEarM7K5Zbn/lvn/aad25PURljDvLka1jOJ1MSYKmvAuxiYxfRaemaBiIQPpb6Hu4o56hE4sCtOFxERkWqszsqtcUmy6jx+7WAuHtSFWRf+rMFrmDdXVotB5uQ0pq/cjAE+ReVaU2aBiIQPBerhzmtE3anUdxEREfHD7nAy85Utdd7v1+f15OJBXYDGWcO8OZvYP5UnbxjCgne3+hSWS9E66iISAgrUw51X1ffK63qKiIiIAPz2xU2cKHPUaR/XSLp41GVJNxGRYFKgHu4MLc8mIiIi1Vv43nesyjpQp31+fk53BenVaO2ZBSISHlRMLtxVVH23GKr6LiIiIr5WfZPDM//ZU+f9Ms5QGreISDhToB7uvEfUNaQuIiIiFeq7Xrqql4uIhD8F6uHOotR3ERERqep3L22u13rpql4uIhL+FKiHO6+q73alvouIiAjmvPT3vs2r0z7x0VaWtZJ10UVEmjsVkwt3XiPqWp5NRERE6jMvfVL/ZB67bqhG0kVEmgkF6uHOe0Rdue8iIiKtWn3mpf9yVA/mXnxGkHokIiLBoNT3cFdR9V1z1EVEROTxD3fUaV76oFMSFKSLiDRDCtTDnaHUdxERETFH0//3sz112ueujJ8FpzMiIhJUCtTDnUWp7yIiIgIbsw9z9GRZwO3bxUVydu8OQeyRiIgES1AD9U8++YTJkyfTpUsXDMPgrbfeqnWfdevWMWTIEKKjo+nTpw/PPvtslTZLly6lR48exMTEMHz4cDZu3Nj4nQ8XhpZnExEREcgrKqlT+z9fMUDF41qCchuUlcDJQnA4gnPsQLM2y22Bt21MoXpekRAKaqBeXFxMeno6S5cuDah9dnY2F110EWPHjmXLli3ccccd3HLLLfz73/92t3nllVeYOXMmmZmZbN68mfT0dDIyMjh48GCwTiM0XH+QXFXfDSeOxv7jLCIiIs3C6qxc7nv3u4DaRkcYWoYNAgvuamvjCmRrCmaDGUQW7oOHfwYLU+HBU+FPyfDhA2APsE5BTX1zHXtRV3h8KOz4wNPW+7xd5164Dx7pD8+MhZ0fNF3gXLAbHjkDnh4NO9aYz+s6r8q/n+rOt7UG+t7n3Vpfg2bMcDbRxGfDMPjnP//JZZddVm2be+65h/fee4+srCz3tmuvvZajR4+yevVqAIYPH85ZZ53F448/DoDD4aBbt2789re/ZdasWQH1paioiMTERAoLC0lISKj/SQVL4T54eiwkdoVzbofXfw5A5qBPWHBZemj7JiIiQRH216ZmpiW9nquzcpm+cjOBfmB7Yeowzj2tU1D71OjKbWCNAnupGUxERIPRgGwA789S4+ZA7/G+xyu3wfGD8My46tsU7oNl50HJUfNx+x5wwULolwGOMrO/Rfv9P48rgIxu6y4MXON5u/ZxfSx3nf+ez+DZSf73HXgtXPSI5/gR0ebr53reI3tgxQWQ0AXGzYU+E3zPL2eLGfx669AbzrkTPpgHJYVmfwzDPPczb4H3ZwMG4ISUgTB+XtXjVnd+1W3z97t3fV+03/wduX4HAAndoLTIPK/CfVB6omJ7V7AVQlIv399F5fdC91ENe3/5O6fG3ifQ9q73jL/zKdwHT40xz/vs6fD+HEg8xfPa2Etrfu/Vt+9NJVz7VYu6XJvCanm2DRs2MGHCBJ9tGRkZ3HHHHQCUlpayadMmZs+e7f65xWJhwoQJbNiwoSm7GlzF+VB80Py3IkgHcJaXh65PIiIi0uTsDicL3t0acJAOcPhkadD6ExSuQKpNJzi61wy82neHCx+CPuOrBnSBBBbFhyo+Sx2ClVdCl8GeIK34kBn8xSZWtDno28YV4BXlwskCz3EP74KXrwVLFFgjoVM/SL/O85lt5ZWQMgCG3warZ5lBoyUKRt0JI+/wDagNwxwpXnGBGTwNvxVWzzaDY4B23WHoVPhgbvWv2zcvm18AWMxAteQwlBaDEQlWK5SXmOf7j6ugfS8Ynwl9LzD7Uu7nfVKwC96d4bvNWXHu78/22gDkfWMeN6kXXPiXqgG79/mNvgd6joFjObAiwwyyR8+C5P7w9/EQ38F8H5SdhLZdoOSI+T5wOoFKGaVFP5n/ul4rl8K95r85X3l+n6Pvgdgk39+RJcJ8f42bD6dfVPE61RD0ef/s4DZ47mLfgNe1T0kRWCIhMqbqDR9XwDx+rm+QXPlf7xsLCanma9RvYsXvy+bbtmi/eSPJVmiez/kLodcY8/ntpbB/C5w4ZH7989dmX1z/Hzr/DAr3mzdgzvqV58YMmNsu/Iv5f8/7RpTrd2gYgd3oqO7/aEkRRLXx3Ozy/v9defy4uufxvvky+h7om1H1eC1AWI2o9+vXj6lTp/oE4qtWreKiiy7ixIkTHDlyhK5du7J+/XpGjBjhbnP33Xfz8ccf88UXX/g9rs1mw2azuR8XFRXRrVu38L3L7u8OJ7Av9jROufKBqnd8RUSk2WtJI8DhoKW8nht2FTDlmc/rtM9L085mRCiLyNU0Yuov0M79Blacj3uk1lu7HjDpr9Chlxng+QtqvUe6j+WYH+BjEyF/h9eBKo5tiYD4ZDi230/HK9p0GQxDboYP5vuO5DYGw2oG4aNmwpo5jX/8OrFQJQhuiHY9YOKDcFoGHM42U+SrnF+l37El0gywQum0ybDvc88Nhb5+MiYSUuGMq6reOEnub978iG0Hy883t7VNhcmPQc9zzUBz2yp45TrPPp3TzOMmdIGiHPN5C/d5MgHiOsDTYzztrdEw7FfmTZk2nT1t06+Df91V9XziO0P5SbAV06Dfb7uecNY0WHOv73bDAu17ev7P+csYKdht3oBxZWW07wEZD5jntuICiIgCI8K82TVujnm8v0+Ak0e9nscw/69csBC6nwMxCZ7fy74vYfkE3O+niGjP8Vy/Q1e//P39qU4TjNLX5drUKgL1+fPns2DBgirbw/biXU2g7sCCBYd5ARmfCb3HNn3fREQkKFpKYBkuWsrr+faW/dz+8paA27eLi2TTnPObrohc5Q+23qOo4+ZAx9PM0es2ncwAo30PGD7dDLRtRV4jaI0QMFqjIX0KbH624ceS+ovrBGXFUHYi1D2pH2u0eUOnYx8YdD386+7a94lKMNPxvRkWSDjFHMUuPxn483foAwU769bnULFGw3l3wYgZnpH2am/SYN6ocvqpr1Dddp82Eebxk3rAkR+h9Hj1bSNiYOTtkH69GdDHdzBvirTvYWYp9BrryTxwBfGF+zw3A/1NhWkkzTb1PSUlhQMHDvhsO3DgAAkJCcTGxmK1WrFarX7bpKSkVHvc2bNnM3PmTPdj14h6c2NxXcRyvoJ/3QMzWnC1exERESH7UA0fRv2Yek7P+gfp1Y2EV/6w6tp+ONt3DnRSL898YleKbYc+nvRygNyv4a1b69e/2thtCtLDwYlDoe5Bw9ht5lfu1+ZXICoH6QBOhycdvy6aS5AO5uv00Z/ML8Ni1g84WVB9EF1dMF5bkA7gLIeycjgQQFHN8hL4+EHzC3z//rw8xfw+vrPZf+9aB067529XIDUYgiysAvURI0awatUqn21r1qxxj55HRUUxdOhQ1q5d6x6ZdzgcrF27lhkzZlQ+nFt0dDTR0dFB63dTqTKiLiIiIi2W3eHk6f/sDrh9XJSVGeP61O/JKs/57HyGmbrqPQfUYvGMmLfp7BnVcs2B9pe63pyCDhGpP6cDCn8MdS8C5wreK9c6cKmtBkMTCOrybMePH2fLli1s2bIFMJdf27JlC3v3mneXZs+ezU033eRuf+utt7J7927uvvtutm3bxhNPPMGrr77KnXfe6W4zc+ZMnnnmGZ577jm+//57pk+fTnFxMVOnTg3mqYSFnOhecMMbMO0jpb2LiEizs3TpUnr06EFMTAzDhw9n48bqM8PGjBmDYRhVvi666KIm7HFoPf7hDk6UBp4S/uvzetc8mu6vWJNrm6uQbc5X8NK15nJd3o8fSIV/zTJTWosPmaNaVUbNtPSTiLQwh3ebAftjQ2Dnh0361EEN1L/88ksGDx7M4MGDATPIHjx4MPPmzQMgNzfXHbQD9OzZk/fee481a9aQnp7Oww8/zN///ncyMjLcba655hr++te/Mm/ePAYNGsSWLVtYvXo1ycnJwTyVEDF/Pa7L3tNdF4Y0/UJERKS+XnnlFWbOnElmZiabN28mPT2djIwMDh486Lf9m2++SW5urvsrKysLq9XK1Vdf3cQ9Dw27w8lTnwQ+mt4mOqLqaLr3WtNHf/JdA7usxLPt6dHwU6U6P/ZKFcHLS+CLJ0Nc/ExEJEQO74YX/wd2fNBk69E3WTG5cBL2BWYK98MzY8xlNsbNofwf1xHhtJHZ6yUW3FTNWpoiItKshf21qYGGDx/OWWedxeOPPw6YU9e6devGb3/7W2bNmlXr/kuWLGHevHnk5uYSHx9fa/vm/no++sEPPPLBjtobVnjiuiFMGpjq2eBKZXcVUWqTAvnbPT+3RECbZLP6tDQzjVytXUTqpkMfczWKemQ4N9ticlIhsSvckeUu4OKwRIDdhmHXOuoiItL8lJaWsmnTJp9VXSwWCxMmTGDDhg0BHWP58uVce+211Qbp/pZiba7sDif/+9megNtPO7enJ0h3FXpzpbJXNw/TUa4gvTmJSYLLn4Je53ktZ9faeCcC60aFhFDBziYp7B3U1HdpgIhod4q702LeTzGcCtRFRKT5yc/Px263V5mmlpycTF5eXq37b9y4kaysLG655ZZq2yxatIjExET3V3Nc3cVlY/Zhjp4MbG3piwak8MeL0swHhfuqT2WX5sewmGtZT3kN7tkNp11gLimV2BWi2/pv374XTFpiVrROTTeD+5h2tT9XUu+q21IHwYUPNfAkGsow+3HDG/DHXPPrF//2/Awg+QzzHFPTYewfQ9RPaVU69IELHwz602hEvRlwGNaKbxSoi4hI67N8+XIGDBjAsGHDqm3TUpZiBfhga9WbF1GUUUoE7uAEiI208LcpQ8wH5TYozPGMoge6rFS4CGQd5WCK7+zJPvDHsJhVrdv3hCPZgR83Nd1ctzmug1ktvzZJveGCP5nrPLvWpa5cmyixK1z3Ojw70Vwv+tzfw9kzfNsPuc6ztF634eZzt02FUb+HPufD8byKpfW6wvi55prRh36A5y42j+9aR7ra91GA6feGFayRZo0Dl479IP+H2vdNHWQG3n3P930NEruaqw4kePXTtR527tfw0cLajy3mTaCMhRDfMbD3ZpMz8KwkESYztZN6V1SAD84a65UpUG8GnEbFiLoCdRERaYY6duyI1WrlwIEDPtsPHDhASkpKjfsWFxfz8ssvc99999XYrqUsxWp3OPnnFt+U9FPJ443oBeQ4O/Bo+eV86BhMFHZ+M6oPVgNzybS/j4eTR0PS5wZxBQsJXcz6PN5LvEUlmHPpS4ug3alw1q/g3xX1DOI6won8mo/dJgWOH6DGD/muD94nC+DNX1X9uStAT003g8K4DvD0GP/HMqyQeIo5zSCppyeINAyz/pAruDzrFvhgvtl2+HR4fw4kpJpr0QdaNLj72XDPXohqYy6bV1mE1/+FpJ4+UyoBiO4Fd37nu63zaXBnpXb+ztFphy7pkH4d/Osu/23adYcLFsJpE+Hoj56bAuPmQKfTzaKGMe196ya4gv/UQZ6bB/76UWmKqM/5xneC2PZw8oj/foHv72jA/8C/PVNysFbc6PC+sVAX8Z2htBjKij3bImLgrGmw5cWKfnnd4OjQ10yjjog2C5TZbVUO2SCWKIiING+ODJ8Oa+aYN2y832s5W1yNqf7mi5+lF+vKGuVbpLLyY5f2vWDSX6DHuZ5t+76E52pZ8cOIMNdaD4YmDtBdFKg3A57U9xDeaRYREamnqKgohg4dytq1a7nssssAs5jc2rVrmTFjRo37vvbaa9hsNm644YYm6Gnobcw+zOFiT9r7qeTxdvQ82hvH6UAhK6Ie5qQzEicWYr+ww9YucPKwn6XSwlRCNyg9Bu27+wYLrkA2tgMc+t5s2zYZpn9mBjCukeLB14MlEvK3+Q+YLZEw+EbYtAKOH6Ta4KLyB+99m/y3cwXolQPu+E5m1fyyE+a5TPwL9Bhl9tM1ult5FNg7uBxwtef7My6rOTiuTkwdiiRG+LmJFeg2wBNED/Qz2u76Wbr5O+1xrm8mgL8bBXdkwcGtFb/DiiCwS6XXuq7nA+brPO0j88ZAXAcoyvXcNOk+yrOv63dUlAOfPWLeRBh9D/TN8NxYiOtg/o69/2/5ZH5U9NsSYd5ImvgX6DsBjuyB5ReYfXEd02Ixbz4U7ocVGb5ZC7Zj5g2X/Ztg+QTPc6Wmw9m3wepZFQF+xfN1ToMje6Gshv/z1mg47y4z28JRVvN7Lb6T5yZS5Zsv7hszgzyBvuu9X1pcKQummmC+y2DzdUjuD38f53mt26RU3JyrkNTbTCf3d7MqqafZxyo3dzDXOb/gAWib4nuzr10POLrH0871exp6C6y51//r1jYVjuVWnI7FzKAJQYDuokC9GXBW3AHUiLqIiDRXM2fO5Oabb+bMM89k2LBhLFmyhOLiYqZOnQrATTfdRNeuXVm0aJHPfsuXL+eyyy6jQ4cOoeh2k8s/WkQUpZQSSSqH3UE6gGuJ9BjKzM+MDqBwb7XHCiuuIK7PhJoD2aJc+Fu6uS26bdWAzB2cuvatCBJTBsKY2dBvIuR9Ywbq/kYH26bC5MfMgMr7+U8ZCrN+gqfHweGKavv9JsGUF6sPuO2lvjcRXKoLIr23V/d9uPEO4ioH0TX9rLLK5xgRbY4+B7p/XXjfGPD3XvPuj7/Ree/9931ZETx73ahwBayufncfVfXGhL/MhIho6NCr6s9c7+mELv5fD9fUBe/tlftlifDcMDrlLPP/jivTwlLLe837Nahy82Wgb19cgb691Lzp8L8ZnhH6pN7m4/hO5s8qZ5WA72vtuulVeYTfH1cfiw/BU+eZGRGu8+1T6Saad+bG02M9N0Vcv6eiHPj0Id+bHykDYfw8sw+2Y+YNv+qmnjQhBerNgIrJiYhIc3fNNddw6NAh5s2bR15eHoMGDWL16tXuAnN79+7FUimFd/v27Xz66ae8//77oehy0yvcR8b7Y5kYXchPzk48b5/gDtK9hfBzYwAqPuAnn1H9h/WaAtnoNp7HUTUsw1eXINHNMEfL1i0Ea0TVpZViEiDGq0hbUk//x3T1P5wD7MbiL5AN5GcNPXZD1eV3VFNmQXXBc21ZEDU9b03ZAP5eD38ZCZX7VflmQV15Tx2o6f+V9+vaoZf/TIlAbpDUdL419THxFJj5vf8bZP6O5++GiXfWhb/zrEumSpApUG8GHBVz1C0Opb6LiEjzNWPGjGpT3detW1dl22mnnYbTGSZFhJpCcT5RtiNgQC/jAPMt/whNP9r3MudRv38v7hEnw2qmjY6eZW53jWgNu7UiVdZP+nJ1H9ZrEhnr+d5irb5dvYK8ivdSzlfVL61k8fpobNXHZKB+QWdjHDscVPc+C1a/A8nGqKlfDVWf4Nnf40Bfn/q8jnV5P1bX1t/NjzCkv0DNgUbURUREJFjiOpnzWL3njRflwPol/kfs+l/uGdEqyoH/POR/ZKpeH8K9AnWjhkC9Psd3z7cdDOMz/bfxDtQt+pgshO/NhKa+WdDSNIPz1F+gZsCp5dlERESkMbVJhYsfgV5jzLW5K49+1zSy1pD01eqU28xjeE9/qGlEvS5cAXrl+bb+eI+iWyIb5/lFROpBgXoz4JqjblXVdxERkRbL7nTSSKGpf9YoOO9uGDHDDM5rS+UNZvqqt8J9vkWfXAw/y47VSTUFsWrcRanvIhIe9BeoGXAF6kFbG1BERERC7rv9RQwMxoG9K6L7W3M71Irzofig+e/KK71+UM++1qvQnOsplfouIuFBf4GaAVfq+4kSGxt2FTCsZxJWS/gWPhAREZG6+yK7oPECdcMK7XvApL803rJXQVdpObW9n8HOD+re/4ak43unuyv1XURCSIF6mFudlUvCoRLOAY4eO8GUZz4nNTGGzMlpTOyfGuruiYiISCOwO5x8tP0g0+p9hIqq66mDYPzchi/XFA5KCs0Rdlfxt8rLqdWkvun43vPirQrURSR0wjD/SVxWZ+UyfeVmSuzmRTbCMOeo5xWWMH3lZlZn5YayeyIiItJINmYfZveJOI444/z+3LVKXRkWM9Mu4RTfBl0GwQ1vwK/WmVXbK89Bb85cy6k1BZ/U96BWDBARqZEC9TBldzhZ8O5WnIC9orSMtSIlzLWi7IJ3t2J3tKL1ZUVERFqog8dKyKMDl9gWku9sg73i8n7MGcNRZzzfOHtxU+k9/GXQWox7c+CX/zbnYXcZbAbo0z4yA/SWEpyDZ3m2LoPhwgeb5jmtSn0XkfCg1PcwtTH7MLmFJQCUVQTqEXiqvjuB3MISNmYfZkTvDqHoooiIiDSS5Dgzdf0nkjnHtpQ/RLzEryJW87J9LA+VX0spEYDB9AHdzdHyxFMaZ1m0cFSX5dQam4rJiUiY0F+gMHXwWIn7e3tF4oN3oO6vnYiIiDRDhfsY/vYYVsUm8qDtSj52DKQNpQAcc8ZTijmym5oYw7CeSZ79GrosWtipx3Jqjd4FzVEXkfCgQD1MdW4b4/6+3J36XjVQ924nIiIizVBxPkbxIU7nEM9FPcjXjl6UOKMAOEYsYJaKy5yc1jJXfWnIcmqNTSPqIhIm9BcoTA3rmURqYgx5hSXuOeoRXsuWGEBK5TvrIiIi0my5Cgf1N7KxWsxJ6qkcBpz86rxeLXe1l4Ysp9bYfJZn08dkEQkdFZMLU1aLQebkNADKnL5z1F2XsBZ7Z11ERKQVsTt9C8NaDc/jX0W+x9tRc8n9anXLLiAbLkvJeQfnSn0XkRBSoB7GJvZP5ckbhhAZaV4oXIF6SmIMT94wpOXeWRcREWlFtu/cVePP0y27+a3tGTZmH26iHrVi3nPUNaIuIiGkv0BhbmL/VA5/3wW+g9gIJy/94myG9UzSSLqIiEgLcaKooNY2Fpw4d30Iva9ugh61YlalvotIeNCIejNgiTAvGpGGnRG9OyhIFxERaUESY2pPse5tyWXQd39ugt60ckp9F5EwoUC9GbBUXCgMR9Wq7yIiItK89eocX2ubH+lC9OS/NkFvWjlVfReRMKFAvRkwrOaFwuJUoC4iItLSWGPb19qmQ5sYrH3GNkFvWjmfQF0j6iISOk0SqC9dupQePXoQExPD8OHD2bhxY7Vty8rKuO++++jduzcxMTGkp6ezevVqnzbz58/HMAyfr9NPPz3YpxEyrhF1K+Uh7omIiIg0ujad/W62O82pbkfb96fN5Yubsketl0/qu0bURSR0gh6ov/LKK8ycOZPMzEw2b95Meno6GRkZHDx40G/7OXPm8NRTT/HYY4+xdetWbr31Vi6//HK++uorn3ZnnHEGubm57q9PP/002KcSMu5A3Wlv2UuziIiIiFuWsye3R8zh83GvQW+NpjcJpb6LSJgIeqC+ePFipk2bxtSpU0lLS2PZsmXExcWxYsUKv+1feOEF7r33XiZNmkSvXr2YPn06kyZN4uGHH/ZpFxERQUpKivurY8eOwT6VkLFEmBcKKw7KHY4Q90ZERESCwfte/PLyiVxaej/vHE9j+j++YnVWbug61poo9V1EwkRQA/XS0lI2bdrEhAkTPE9osTBhwgQ2bNjgdx+bzUZMTIzPttjY2Coj5jt27KBLly706tWL66+/nr179zb+CYQJ14h6hGGn3K4RdRERkZbEHteRAtrxrbMX2xynALDZ0Q8wcF31F7y7VVl1TcE73d17TXURkSYW1EA9Pz8fu91OcnKyz/bk5GTy8vL87pORkcHixYvZsWMHDoeDNWvW8Oabb5Kb67mTPHz4cJ599llWr17Nk08+SXZ2Nueeey7Hjh3ze0ybzUZRUZHPV3PiWp4tAgXqIiIiLc3GglhGlDzKpaX346z4aFZEnPvnTiC3sISN2YdD1MNWRMuziUiYCLuq748++ih9+/bl9NNPJyoqihkzZjB16lQsFk9XL7zwQq6++moGDhxIRkYGq1at4ujRo7z66qt+j7lo0SISExPdX926dWuq02kUFqsr9d1OmVLfRUREWpSDx0ooJRIwaGucAKDIGee3nQSZUt9FJEwENVDv2LEjVquVAwcO+Gw/cOAAKSkpfvfp1KkTb731FsXFxfz4449s27aNNm3a0KtXr2qfp127dvTr14+dO3f6/fns2bMpLCx0f/3000/1P6kQMFyp7ziU9iYiItLCJMcZUJHknkBFoE7VtdU7t42psk0amYrJiUiYCGqgHhUVxdChQ1m7dq17m8PhYO3atYwYMaLGfWNiYujatSvl5eW88cYbXHrppdW2PX78OLt27SI1NdXvz6Ojo0lISPD5alYqLhQRlFNm14i6iIhIi1G4j+Fvn8eq2ExGW7bQhqoj6gaQmhjDsJ5JIepkK6Xl2UQkhIL+F2jmzJncfPPNnHnmmQwbNowlS5ZQXFzM1KlTAbjpppvo2rUrixYtAuCLL75g//79DBo0iP379zN//nwcDgd33323+5h/+MMfmDx5Mt27dycnJ4fMzEysVitTpkwJ9umEhjtQd2iOuoiISEtSnI9RfIifkc9zUX9xbz5GLGAG6QCZk9OwWgw/B5CgUeq7iIRQ0AP1a665hkOHDjFv3jzy8vIYNGgQq1evdheY27t3r8/885KSEubMmcPu3btp06YNkyZN4oUXXqBdu3buNvv27WPKlCkUFBTQqVMnRo0axeeff06nTp2CfTqhUXGhsGKnXKnvIiIiLY6nvrvptaj7eLj8ana0GUbmJWcwsb//rEEJIqW+i0gINclfoBkzZjBjxgy/P1u3bp3P49GjR7N169Yaj/fyyy83VtfCW7kNrFHu5UEiDbvWURcREWkFBlj28HzUgzg7DsaIzQQUqDcJp9cNE1V9F5EQCruq71KhcB880h+eGQsHzRsXVi3PJiIi0ipYMG/MGzlfwb/uCXFvWilDH5NFJHSU0xOuivOh+KD5b85XALTnGMfK7SHumIiIiASb07BiOO3QZTCMzwx1d1o+VxajN0M1AUQkdBSohz1PqnsfSy7F71wKF2ZC7/G6gIiIiLRQRxJ/RuKkBVj76nofdIX74OmxkNgVepwX6t6IiABKfW924g5nwcorzZT4XR+FujsiIiLSCJx4gvFdjlSG5M1m1BsGq7/LC2GvWglXFmPO17D+Uc92p6YbikjoKFBvZgxnxQi75qyJiIg0f/GdsEV35BtHT/5WdhkABSQABnmFJUxfuZnVWbkh7WLrUalg7zNjYecHCthFJCQUqDczDldhky6D4cIHQ9sZERERaRB72y6c71zKpaX3s9N5CgBlTnNmois8XPDuVuxanrXp5X6jLEYRCRkF6s3MsXZnwA1vwLSPoPfYUHdHREREGmBj9mH2FtkBg0jKASjzKiHkBHILS9iYfTg0HWzNnBUFfJXFKCIhoEA97Hl+RUed8awf+yr0maDCMiIiIi3AwWMl7u8jjaqBur920kQMq/mvshhFJARU9T1cxXeCNp0hoSsMnQrv/g4nBuXKfBMREWkxOreNcX/vGlEvxVpjOwkyw2qOpqcOhHFztNKOiISEAvVwldgV7sgy1/Q8kg2YF/Byh6OWHUVERKS5GNYzidTEGPIKS4jyk/puACmJMQzrmRSiHrYmFsChAF1EwoJS38NZRLR5gbBGAWagXmbXkLqIiEhLYbUYZE5OAzwj6q5icq4QMXNyGlaLAsagcWUxdkn31AHSNEMRCTGNqDcH7kDdTnm5RtRFRERakon9U3nyhiHsfuNtcHpG1FMSY8icnMbE/qkh7mEL553FqOBcRMKERtSbA2skABbDicNeFuLOiIhIa/a73/2OrVu3hrobLc7E/qlMPN1Mb4+OieGlaWfz6T3jFKQ3FVcWo4hImFCg3hxUjKgD2MtLQ9gRERFp7f74xz/yxhtvcNNNN/H222+HujstiuEwb8ZHRsUwoncHpbuLiLRiCtSbA0uk+1unAnUREQmhdu3a0aVLFwC2bdvGzTffHOIetSAVWXN2QzMTRURaO10JmgOrV6BuV6AuIiKhc+utt3LzzTfzy1/+EoD/+7//C3GPWpCKa7zD6wa9iIi0TgrUmwPDoNyIIMJZrhF1EREJqVtuuYWRI0cC8Pnnn3PxxReHuEctiAJ1ERGpoNT3ZsJumBftnblH2LCrALtDy7SJiEjTe+utt9zfv/POO6HrSAvkmqPuMBSoi4i0dhpRbwZWZ+Uywm4h2oDPd+bx4o7PSdWSLSIiEgIHDhxg165dGIZBTk5OqLvTohgVc9Q1oi4iIhpRD3Ors3KZvnIzpVgBiKQcgLzCEqav3MzqrNxQdk9ERFqZP/3pTzz99NM89dRTLFiwoE77Ll26lB49ehATE8Pw4cPZuHFjje2PHj3Kb37zG1JTU4mOjqZfv36sWrWqId0Pbw4z9d2pQF1EpNVToB7G7A4nC97dihMoq0h+cAXqrsT3Be9uVRp8sJXbwKnXWEQEICEhgTPPPJO0tDQ+/vjjgPd75ZVXmDlzJpmZmWzevJn09HQyMjI4ePCg3/alpaWcf/757Nmzh9dff53t27fzzDPP0LVr18Y6lbBjcY2oWxWoi4i0dnUK1J977jlsNhtTpkxh/vz5QeqSuGzMPkxuYQkAZU4zUI+qCNTBDNZzC0vYmH04FN1rHQr3wSP94ZmxsPMDBewi0urdeeedvPPOOxiGwQcffBDwfosXL2batGlMnTqVtLQ0li1bRlxcHCtWrPDbfsWKFRw+fJi33nqLkSNH0qNHD0aPHk16enpjnUrYcc1Rd1qiQtwTEREJtToF6llZWXz44YfcdNNNFBcXB6tPUuHgsRL3964R9QjsNbaTRlacD8UHIedrWHmlAnYRafU6d+5MamoqN910E6effnpA+5SWlrJp0yYmTJjg3maxWJgwYQIbNmzwu88777zDiBEj+M1vfkNycjL9+/fngQcewG6veh0EsNlsFBUV+Xw1N65AHaW+i4i0enUK1IuKinjqqacYO3YsJ06cCFafpELntjHu792p70Z5je0kWBzmP7nfKGAXkVZt9OjRjB8/nssuuyzgm/b5+fnY7XaSk5N9ticnJ5OXl+d3n927d/P6669jt9tZtWoVc+fO5eGHH+ZPf/qT3/aLFi0iMTHR/dWtW7e6nVgYsLhG1K0aURcRae3qVPX9scceIyoqil27din1vQkM65lEamIMeYUllFUqJgdgACmJMQzrmRSiHrZCzoqRHFfA3mUwjM+E3mND2y8RkSbgdDo5dOgQN998MxkZGUF9LofDQefOnXn66aexWq0MHTqU/fv389BDD5GZmVml/ezZs5k5c6b7cVFRUbML1j2BukbURURauzqNqP/xj39k//79zJkzhzvvvDNYfZIKVotB5uQ0wDOi7pqjblS0yZychtVi+NtdgskVsOd8Bf+6J7R9ERFpIoZhsHnzZjZs2MDWrVvZunVrQPt17NgRq9XKgQMHfLYfOHCAlJQUv/ukpqbSr18/rFare9vPfvYz8vLyKC0trdI+OjqahIQEn6/mxqLUdxERqVDn1Pe3336b2bNn06VLl4D3q8tyLGVlZdx333307t2bmJgY0tPTWb16dYOO2ZxN7J/KkzcMcS/VElkxRz0lMYYnbxiiddRDxaj44NhlMFz4YGj7IiLShJKSklizZg2vvfYar7/+ekD7REVFMXToUNauXeve5nA4WLt2LSNGjPC7z8iRI9m5cycOh8O97YcffiA1NZWoqJaZGm5xKvVdRERMdUp9HzNmDLt372bgwIH07ds3oH1cy7EsW7aM4cOHs2TJEjIyMti+fTudO3eu0n7OnDmsXLmSZ555htNPP51///vfXH755axfv57BgwfX65jN3cT+qRz9LAlyoX0MvHT92QzrmaSR9FBKHQjj5kDv8WDo9yAirceYMWPc3xt1+Ps3c+ZMbr75Zs4880yGDRvGkiVLKC4uZurUqQDcdNNNdO3alUWLFgEwffp0Hn/8cW6//XZ++9vfsmPHDh544AF+97vfNer5hBP3iLpS30VEWr06jagPGzaMo0ePctdddzF2bGBzcuu6HMsLL7zAvffey6RJk+jVqxfTp09n0qRJPPzww/U+ZktgjTTvrkcZdkb07qAgvclV+q8y7SPoM0FBuoi0Otu2bWPbtm1s2rSJJUuWBLzfNddcw1//+lfmzZvHoEGD2LJlC6tXr3YXmNu7dy+5ubnu9t26dePf//43//3vfxk4cCC/+93vuP3225k1a1Zjn1JoldvchUlVTE5ERFzqNKK+YMECFi5ciNPpZO7cuTz33HM1tnctxzJ79mz3ttqWY7HZbMTE+FYxj42N5dNPP633MVsCa4R50XaU2ULck1YmvhO06QwJXaFgN9gKze0K0EWklfr1r3/t/t5Zx5UvZsyYwYwZM/z+bN26dVW2jRgxgs8//7xOz9GsFO6Dp8dCYlcYN4cIh3mNN7SOuohIq1enQD06OtpdQTU2NrbW9jUtx7Jt2za/+2RkZLB48WLOO+88evfuzdq1a3nzzTfd66bW55g2mw2bzRPgNse1VS0R0QA47WU4HE4sGlFvGold4Y4ssEbBX/uB7pOISCt39dVXYxgGFouFrl27hro7zVtxPhQfNP9deSWxruwtS50+nomISAtUpyvB5MmTueqqqzAMg2HDhgWlQ48++ijTpk3j9NNPxzAMevfuzdSpUxuU1r5o0SIWLFjQiL1sehFRZqAeSTknyuy0idZFvMlU3CQRERF47bXXQt2FFsgsmGdU/HvxD/fCTqvqoIiItGJ1mqN+ySWX8Prrr/Paa6+RnZ1da/v6LMfSqVMn3nrrLYqLi/nxxx/Ztm0bbdq0oVevXvU+5uzZsyksLHR//fTTT4Gcblhxpb5HYueErbyW1iIiIsHhvYb5woULQ9iTlscVkied2A0rr4RnxsKuj0LaJxERCY2AA/VVq1b5fO3du7fWfeqzHItLTEwMXbt2pby8nDfeeINLL7203sds1murVhSZcRWWiaScT3fmY3fUbV6giIhIYzhy5Ij7+4KCghD2pOWyVIysk/MV/Oue0HZGRERCIuD86UOHDvk8vvrqqwPar67LsXzxxRfs37+fQYMGsX//fubPn4/D4eDuu+8O+JgtRkWRmaNRnfm6MJbRQKRRzsxXv+ahf28nc3Ka1lEXEZEmdeqpp3LzzTdjsVhIS0sLdXdaJAcWM1jvMhjGZ9a+g4iItDgBB+o333xzvZ7gmmuu4dChQ8ybN4+8vDwGDRpUZTkWi8UzsF9SUsKcOXPYvXs3bdq0YdKkSbzwwgu0a9cu4GO2GBVFZhKOH2K0YY6g9zRyACd5hSVMX7mZJ28YomBdRESazMyZMzl58iROp5O4uLhQd6dFOtK2Hx0uXag56iIirZjhrOvaKi1AUVERiYmJFBYWhnUavH3/V1ifGVNl+9eOXjxcfjX/cQwkJTGWT+8Zp3XVm8Jf+8HxitoI8wtD2xcRaXGay7Vp5syZLF68GIBZs2bx5z//OcQ98q9ZvJ45W+Dp0ZgzER3uzS9N+Jwpo34Wql6JiEiQ1OXaVKdictK0vtvvfxm5M4w9PB/1IG9FzaXXsf+yMftwE/dMRERaqxMnTri/Ly4uDmFPWoD4TtCmM3RJh6ufd292FZAVEZHWS2t8hbHDJ0r9bo8wzLvu6ZbdzI94nq3HbmzKbomISCs2cuRIrrzySgDWr1/PY489FuIeNWOJXeGOLLBGwQnPTXdLRGQIOyUiIuFAI+phLCnO/x31cqf5a/va0Yv55TfRuW1MU3ZLRERaKZvNBoDVamX37t28//77Ie5RCxARbc5Dd5hLrzqcBhFWa4g7JSIioaZAPYyd0dX/vIXvnD24qfQeLiu9n91tz2JYz6Qm7llrpToAItK6nXbaaQC89NJLnH322QwYMCDEPWpBKgL1ciyqOyMiIkp9D2fWikqvDqeBpaLq+25HMpeW3o9RETRmTk7TBV1ERJrEm2++yQsvvMD777/PgQMHsNlsREdHh7pbLYNrRB0LEbqui4i0egrUw1lFkZmiyM48V3Qmt9ufrQjPDVISY7SOuoiINKkhQ4YwZMgQbDYbr7/+Otdffz2vv/56qLvVMrhH1K26AS8iIgrUw1pFkZl21ihm5H0HTz1LG+MkyQnR/PXqdM7u1SHUPRQRkVYoOjqa66+/nuuvvz7UXWk5HHYA7FiIsCpQFxFp7TRHPdxVFJn5z94SABI4yYEiG9f//QtGPfghq7NyQ9xBERERaTCnGaibI+r6eCYi0trpStAMrM7K5Xf/3A1AtFFGFGUA5BWWMH3lZgXrTcXQCIeIiARJReq7HavmqIuIiAL1cGd3OFnw7laOE+veFs9JAJwVjxe8uxW7w+lnbxEREWkWVPVdRES8KFAPc//dmUtu4UkcWDjuNNdLb2ucdP/cCeQWlrAx+3CIeigiIiIN5pqj7tSIuoiIKFAPb4X7GPTGKN6Omst5lq85TkWgzskqTQ8eK2nq3omIiEhj0Yi6iIh4UdX3cFacT4ytgAHGYZ6PepASZyQAbY1iT957hc5tY0LQQREREWkUPnPUNY4iItLa6UrQDFgMMyqPrigityji75xn+RpwYgCpiTEM65kUug6KiIhIw2gddRER8aJAvRlxFR3vbhzk+agHeTtqLudYviVzcpou6k3NqeJ9IiLSeOzlrhF1C9/lFKpIrIhIK6dAvRlyjbCnW3ZzX9TzIe5NK1VR9EdERKShVmflcvermwBzRP2u179h1IMfavlVEZFWTIF6M+S6yf61oxeZpTdpLfUm45W1UJGiKCIi0hCrs3KZvnIzRSfMorD2io9meYUlur6LiLRiCtSbEVeAfpxYbiq9h0tL7+dTxwBAa6k3OQXqIiLSQHaHkwXvbsUJWHEA5og6eGrG6vouItI6KVBvRlzT0AudsXziGIhrhFdrqYeAU6nvIiLSMBuzD5NbaI6kR+BZR91F13cRkdZLgXo4i+8Ese2rbO5mOcyHUb/nPMsWvNdp01rqQWZ4p74rUBcRkYbxvm5bXYE6VYvD6vouItL6KFAPZ4ld4brX/P6olyWP56P+wodRv2ek5RsA9uSfaMreNZ1yW3hUWffug1LfRUSkgTq3jXF/H1GR+m7HWmM7ERFpHRSohztrZI0/7mXJY3nkw4y0fMvL/93b8uaxFe6DR/rDM2Nh5wehDdi90901oi4iIg00rGcSqYkxGIDVMK8r5V6BugGkJsYwrGdSaDooIiIho0C9BYgxypgf8XzLnMdWnA/FByHna1h5ZWgDdu9RdI2oi4hIA1ktBpmT0wDvEXXzo5krAT5zchpWS9V0eBERadkUqDdjdqd54f7a0Yv55TcBLXkem/kBhtwQBuzeo+gK1EVEpBFM7J/KkzcMoX2M+ZHMNaKekhjDkzcMYWL/1FB2T0REQiQi1B2QunM6zbpm252n8Oey63wqwLf4eWxOV8D+jRmwdxkM4zOh99jgP7d3oO7qh4iISANN7J/KmKM94QNzRP3ZqWdxbt9OGkkXEWnFNKIe7rwqv7tCw7KKu+2zy27hE0c6riC9XVxk65nH5povnvMV/Ouepn1O0Ii6iIg0KsPpmaN+dq8OCtJFRFq5JgnUly5dSo8ePYiJiWH48OFs3LixxvZLlizhtNNOIzY2lm7dunHnnXdSUuJJ6Z4/fz6GYfh8nX766cE+jdBI7ArTPsIZ35nv6cVNpXfzvfNUADoaRT5NW9Ul3ah463YZDBc+2DTPqTnqIiISJA57GWBWfTda1QVdRET8CXrq+yuvvMLMmTNZtmwZw4cPZ8mSJWRkZLB9+3Y6d+5cpf2LL77IrFmzWLFiBeeccw4//PADP//5zzEMg8WLF7vbnXHGGXzwwQeeE4lowVn8ST35asLLdHvrcn4f8TrOirnplQP1IyfK2Jh9mBG9O5hLmlmjaLFX+479IGMh9B7fdOfoUNV3EREJErt5A7jcacHaUq/dIiISsKCPqC9evJhp06YxdepU0tLSWLZsGXFxcaxYscJv+/Xr1zNy5Eiuu+46evTowQUXXMCUKVOqjMJHRESQkpLi/urYsWOwTyWkigoP08koZICxm0HW3QAMNbYTRSngKaj2YdZeOPqTuaTZ06Nhx5rwWIO8wSq9VSf/DfpMqHuQXt812Z1Opb6LiEjQOCsCdTtWLArURURavaAG6qWlpWzatIkJEyZ4ntBiYcKECWzYsMHvPueccw6bNm1yB+a7d+9m1apVTJo0yafdjh076NKlC7169eL6669n7969wTuRMJBsFALgPWXtfyI+4bvoX/Bh1O85z/I1p5LLrV9dinPlleaSZrlfwz+ugseGegL2+gaqoRLfCdp0hi7pMNErxb3sRN2P1ZA12SsXj1MxORERaUTOihvA5VhabDKciIgELqj54vn5+djtdpKTk322Jycns23bNr/7XHfddeTn5zNq1CicTifl5eXceuut3Hvvve42w4cP59lnn+W0004jNzeXBQsWcO6555KVlUXbtm2rHNNms2Gz2dyPi4qKqrQJd/3a+U+1jjQc9DLyeD7qQcqdBhE4ceYX+jY6vMsM2BO7g+0otO8B4+bWb0S6qSV2hTuyzDT+H9d7tpedrPuxXGuyF+d7KsaPmxNY+nzlVHeNqIuISGOquK44sGKE+7VZRESCLuyqvq9bt44HHniAJ554gs2bN/Pmm2/y3nvvcf/997vbXHjhhVx99dUMHDiQjIwMVq1axdGjR3n11Vf9HnPRokUkJia6v7p169ZUp9NoApmvFmGYI8TVtiz8EUoK/Y+0h7OIaDOQLvcKzuszou5WaYm3QEbYKwfmCtRFRKQRuVPfDWuIeyIiIuEgqIF6x44dsVqtHDhwwGf7gQMHSElJ8bvP3LlzufHGG7nlllsYMGAAl19+OQ888ACLFi3C4fCfbtyuXTv69evHzp07/f589uzZFBYWur9++umnhp1YS+Eaaf/bEPjh/fAP2Ms8lf8pLW748Vxzzr0D9l0f1dzWRcXkRESkMVVcVxwK1EVEhCAH6lFRUQwdOpS1a9e6tzkcDtauXcuIESP87nPixAksFt9uWa3mRctZTSB5/Phxdu3aRWpqqt+fR0dHk5CQ4PMlXo7shhevhodOg62rqgbsDZnX3phz4su9AvWaRtTr+pyBrMmuEXUREQki1xx1OwrURUSkCVLfZ86cyTPPPMNzzz3H999/z/Tp0ykuLmbq1KkA3HTTTcyePdvdfvLkyTz55JO8/PLLZGdns2bNGubOncvkyZPdAfsf/vAHPv74Y/bs2cP69eu5/PLLsVqtTJkyJdin07KdOACvToEHToGt/wcOBxTshkfOqJoe7gqG/f1bVmJ+35Dibf54z0uvbkS9Xs9ZMVmgpjXZK2dzaERdREQaU0Wg7jTCblaiiIiEQNAXH7/mmms4dOgQ8+bNIy8vj0GDBrF69Wp3gbm9e/f6jKDPmTMHwzCYM2cO+/fvp1OnTkyePJmFCxe62+zbt48pU6ZQUFBAp06dGDVqFJ9//jmdOnUK9umETkz7pnuusuPw6vXm9xEx5kh28SEzPTx1EJx1C6xdYFZjL9wHCV2gKAcST4Gje82Aun13GHZrRfG2Q77F27qP8sw7r4tARtRrKhhXnZh2cNkT0G8iWKr5gFR5BL1yKrxIKJTbzEKLlf8vVbc9GM8VquME83lD1Udp1Vxz1B0aURcREZogUAeYMWMGM2bM8PuzdevW+TyOiIggMzOTzMzMao/38ssvN2b3moc2IboJ4R0cA+RugXcqfpfFh8x/Swp9/wUo2AX/uqviQcWods7XZvBsiTAD+Yl/gT4BVFx38R5Rr7Xqe6WCcanpMKji5gMWz8/BDPpfvbHmPlWZo67Ud6BpA8Vw5O88mypILtwHT481V0bwXr2guu0NUZ9j1qXPge4fyPPZS+v+vN7PFYzXTyQQFZlaKiYnIiIQhlXfpRrxnSDWHFUP85JvNagIjh3lZiD/jyvNyvOBpqiX16OYnLtg3Nfwr7vBsEKHXnDxEk8bu823T48PhR2V0vyPVipAuH+z/z77mwLQUlU3zaCxpjw0Zn2DYPB3npW3NcZ7oLrX05U94roB9sxY2P4vOH7Id/vToxu+uoO/56r8u/X+fXn3efu/zKkj5Tbz5l5tx/HeP9C+u6boLBsJf+1b+2v19GjYtsrsV+XXtzDH/+taetL8fbq+wvm9Kc2Ta3k2BeoiIkITjahLI0jsCtM+ghUXcNwRTdsTLaRy/eFd5ofh5IFwfqaZFg9VU+PLbVDqle5uO2Z+UHa1cY+mldX8fE47HNkLxw9U38YVsHfoDefeDWvmQGS8b5tPF8P3b/uOwLtG4tp08p0CMPEv0KMi3d/faF9lzWU0urppBnEdqm4ffQ/0HAORMYGdV7BGNV3BpL/3VyCZAd6jtq6g0/s806/z3eYve6Sm5/LXt8qvc+ogGDML2rhWzqi4AZbzNbx0rXls7+2u5Rjb94IL/gSnXeh/ikdA77tKmSqu33nH0+CZcebva/Q9EJtU0eeDZp8iosGIgMQuNR/H9Xt2n/NBs+9Jvc36EX0mVO1f4T7zuUuOeLJ8cr6q+p6s/Jq8PAWs0ZA+xXeKjjtIcniO9dK1FdsM88swoH0PuLCOWUEiNfFaR11ERMRwVldKvQUrKioiMTGRwsLC5lcBvtzGpu9+oNebE2lvHMfhBEuL+oxoMT/0JvWAcfPh9IvgeK4ZtOH0fBC3RkHnn8HoWdCxH/zvRIjvaI58lx5v2i536G0GYvEd4OkxmB/mK/23MqyQcArYjkJSr6rBpytIKtrvG6BWd+OiJg0N9AMNWnO2mCOT3ufotJtBW/52rx29Xo82KTD5Meh3fvVBa7kNDm71fS0rB3L1UbgPlp0HtkJodyqcvxBOmwjHcmpPIR99D3Toa77PXLUZ2qT4nqfr/KvToTec/VtYt9Cs5zD6HuibYQbNBbvh7+PBVmQG9ucvhF5jzH4c+r7itajEGln7jSl/LJHm/5vzfu95LV3nmpAK4+Z6AmLX7yf3a9/fteekAafX79zPez+wTgEO8ybE2D+adSNWnF+1WfteMOkvvgH7T/+F5RNqPnyHPlDgf/nOBkvq3WgBe7O+NoWh5vZ6Fj5/PYm7/4+HLL/krnmLQ90dEREJgrpcmxSoN4OLd2V2h5NL7nuB/3XOId+ZSFfjEHGU8pOzE/9rz+D+yOdaUABvQJ8LYOe/Q92R2rXtCsf2B97eNdLsCgATusAZV8IH83AHLq7RvfY94IKF0C+j+oJ3YAZ8Ky4wj+UKuKobxfcOkkuKzADuRL45OukdsNlL4fhBz4ipK5itLXirSUx7uOABWDvPDFpdx3TdqIhqYy4b6FbxejSkIGHlGwtgnvPgm2DTck+/U9PNc49O9B8sNqaIGDhrGnz1ApQcrfpzwwLxneF4XuM/d9tUmLTYvFmxf5NvsNu+F4y+G9bMNX8/6dd51ZwINsM875pueiT2MAP2dqea/3f8vXZNrREC9uZ+bQo3ze31LHz2WhL3/IsHrdO4Z+5fQ90dEREJAgXqtWhuF29/Hv3gB5Z+sJVSIoiiHHBSSiQpHOad6DnkOjvwRvlIMiNfwGqYYVOLiNtbO2s0jLrTrKgfm+gbtBfugydHmSnALgndoLTIDPTHzYUe55rbiw95AvIzroIP5prbYzvAyQLP/ondzSyANp0hf4dnuyvNuzGDt5SBMPBaeP/e2ttaIipSjx+suTCYt0BGXn2fBJ+igy2VEQHWiKqFI6V+OvSBSX+F3mPrvGtLuDbVZunSpTz00EPk5eWRnp7OY489xrBhw/y2ffbZZ91LubpER0dTUhLYe7VZvJ5ef68KV1xF4t41LIqYzuw5fw51z0REJAjqcm3SHPVmasa4vjz9n92U2uyUEunenkcHRtn+RikRgMGntgG8HL2Qo8429LPUYbRXwpPdBh//2fzCYqYwj77LDNiL832DdICiiloGrnnKrtHKNimeOcC5X3vaewfpAIU/mv96V/QHcz50zleNeWaQ9435FQhHuZnKXHl+c3VTB4r2V5x/XbSCIB3AWQ7lWsWg0RTshH/dAzM2hronYeeVV15h5syZLFu2jOHDh7NkyRIyMjLYvn07nTt39rtPQkIC27d7ppgYLakeQOVaHBVTWTRHXUREQFXfmy2rxeDaM7v5/ZkZuJsfZnZzCqNsf+Om0nsoie5opvVe+BffHSJiICoeUgaY84ejE4Pce2kcDvj4AbgvCT580ByZqZXTTCmuS4p+dc8dLlyFw54eDd++UVGxe4u57YEusDDVXF0gHNKjpeXr0MfM9JAqFi9ezLRp05g6dSppaWksW7aMuLg4VqxYUe0+hmGQkpLi/kpOTm7CHgdZpdUI4g9+CYDT0EczERFRoN6sTUhLqb0RZuCeR0c2X/4J/OpjOP1iM5W5y2CY8jLcmwt3Z8Ov/wNDb4Jff2ymQFsizDmgUW0CeBaNAISOEz55wJyb3prlfl0xvx/cc+SddsybCq1uho80tbZd4Po3YMaX9Up7b+lKS0vZtGkTEyZ4pp9YLBYmTJjAhg0bqt3v+PHjdO/enW7dunHppZfy3XffNUV3m5h549NaZhZCnVr+SsOWthQRkRZBqe/N2LCeSaQmxpBbGNh8Paer+FZiV7gjy3ceryXa0zCpJ/z+e89SUUf2mEFgXAco3A9lJyChq5kO3b67mX5tscKL/9P4Jyki0hxEtYG+damB0Lrk5+djt9urjIgnJyezbds2v/ucdtpprFixgoEDB1JYWMhf//pXzjnnHL777jtOOeWUKu1tNhs2myezqKioqHFPIshcSf2pzoOeaT3jM3XjR0SklVKg3oxZLQaZk9O4deXmgNqv2ZrHyD4dzQcR0TU3jqgUuLsCe3upJ4D3riZeuN+sTp3YFYZPN4uMVZ7XLCLSongtHzg+M9SdaXFGjBjBiBEj3I/POeccfvazn/HUU09x//33V2m/aNEiFixY0JRdDAqLKwMo5yvVOxARacWU+t7MTeyfyp0T+gbU9tn1P7Lqm9z6PZFrND4iGiJjPN+7RuQTu8KdWTDtI0i/xkyxj+9krot8wxtw83v1e14RkbBT8XevyyDz79u0jzTqWYuOHTtitVo5cOCAz/YDBw6QkhLYNK7IyEgGDx7Mzp07/f589uzZFBYWur9++umnBvc7FBzu99dg1TsQEWnFFKi3ADPG9aV9XGTtDYHbXtzM6qx6Buu18Q7ck3rCnd/Br9aZa3FHV5rnntQbLn/KnCvf6XSITjDXDDes5nrk9WWNqv++ItK44jqZ/7ctEeZ67MEW0x4yAlzWql13r/obXpXErdEwdg7cmwfTvzAzhTqe5tvOO0DvM6He66a3JlFRUQwdOpS1a9e6tzkcDtauXeszal4Tu93Ot99+S2pqqt+fR0dHk5CQ4PPVnLhmpOdaUnQDSERElPreElgtBlcM7sryz/YE1H7mq19zfloKVkuQP1x6p8/HdzKD8rap5nrerg+3Z1zum1IPcCIfnhlrfsAv2Ik7vbSy+GTzA/VH95lBwOh7zGXHnhnj265NCkxYYK4VntAVBvwP/Hu2V4OK41sioE2yuZSXP+17QcZCc65+MAu3WSLBURa840v9xXY2b2/GtjPXlY+IBqfDfP/WhSUC4jrC8bxK22v53bfvCUey69rrptc21VxBou8Ez/9t1//rmPaQv73SDob5ZRie+hdJPWHQ9eY0mtoMuBYufgSiYn2XG/RmjTbXi+/Qx/M3yFV/I6FieayuZ0F0W3O5Q4Dk081MoeJDZt9d7XqPV3BeDzNnzuTmm2/mzDPPZNiwYSxZsoTi4mL3Wuk33XQTXbt2ZdGiRQDcd999nH322fTp04ejR4/y0EMP8eOPP3LLLbeE8jSCwAI4sFtjibCf5KnYadzXR/UORERaOwXqLcSEtJSAA/UTpXYeW7uDO87vF9xOefNXwA48wbx3UJ94itnW+8PxwGth9T3mz72DAMOAQdf4zpWP62B+0G93Kkz8i6dd/4qbAu4P8q75pYM8a26fyIdlo+Ck13rk7XvBpL94bi4U7ofY9r5tKouIgUHXwZfVLzvkDk7adYdJD0HPc80l1mxF8NS5VY9vRJhrXgdL265QeswsFljTDYv66tAHzpoG/55lBqR1DW4bk2E132cnCqD0eGD7pA6CCfOh+znm+8h2zByR/WE1vDzFzw7mh29S083zXnuf7/ruJ/Jh2XlgqyjKeP5CSOlvLjPnKtR43j2wZo4nQIzrAE+Pwf3eTR0Ew6bBBwvM92T+dqq9sQUQ1xnKis2vgF4nP+85142vNXMhIdU8tw8WmOc2Zhb0HOOZHgOe/9ve/6+fOs88x8RTzeUie57rOb53/YuiHPj4z2ZbVwDfNgWO5Zmvz6jfm6tYWL1WnXDdFIzrAEW5ZsA/+h7om2HeBPH+G+Rdf6O6wDsi2tP3mtpJra655hoOHTrEvHnzyMvLY9CgQaxevdpdYG7v3r1YLJ5EvyNHjjBt2jTy8vJo3749Q4cOZf369aSlpYXqFBqX671a8f/75P/Noe3R7zEsSnYUEREwnM7Wt/5HUVERiYmJFBYWNrvUuOrYHU6G3r+GoycDG4mNj7LwzfyJwR9Vb6hym+fDcUmRGeB5BwHV7eMqeOevXeF+c9S9utGxw9nmKFvl0X9vh7PNgMm1Nnd8ZzO48A4K8r4xgy5XwJYyEMbPg1OG+X7g99dPVx+8R/psRfD3cWa/hkyFtQugpIabBVjN16pjPxhwJbw/13yun10M377uaebqVx+v0c9D31cEhAGKS4YTB/z/rENv84ZJn/Ge32NJoXkuCV3N1ys2yTdLITUdzr7NDAajE6Bgl9n3M6fCN69Dm05wdG/gQbZL+17mTZEeo8zj7fsSllc3cuUVDI+fW/0oauF+87WKTTRH2b0LjHm/v7zfyy7+3quVt3nvV917t9zme2Mr/bqKkeiKvqQMgHHzoO/5NZ9z8hnmc7hWc0gZ4LlxUPnGl3e//J1bTWr7P1pdW1cA713Isrp9AmkXZlritSmUmsXr6fV/59iS4bQ9uo15Cfdz38zfhbpnIiISBHW5NilQD9eLdz08+sEPPPLBjoDb3zmhH7cHWIiuxaktsAgk8Ci3QVmJ2S4ypmpQUNsNgfr00XvbT//1H3BZIs2R2PN+7zuCWFJkjgAfyzUDy8Qa+lW4H5aN9B3V7zIYzroF3p/nuUHRvoc5IhpfaaTXEmEGe94Bek3nV1MA6j16bbF4th3Z4wkiq7wGUeAoNf8ddSeMvMPct3JgmLPF92YKUG2gXZPKgXIw06Nrem+6flaUU/17z/Vat001b4a8P9f3vVD5fVyXoFoapKVem0Klub2exx45i7aFPzAvcSH33Tkj1N0REZEgUKBei+Z28Q6U3eFk4PzVFJc6am9cYdkNQ5jY339hHmkEdR1prIvC/WaK/Ikj5vHbdYcLFsJpEz1zbBvSr8qj+t7Bs+vPhit4qxxodx9V98CuPq/V4Wx4ZpyZbdDuVBg338wYcJabN1G85xv7493v4dN908zrE2gH8/ddV4EE9PUZDZegaanXplBpbq/n8cVDaVO0k3ntFnHfHbeFujsiIhIEdbk2aY56C2K1GDx0VTq3vfhVwPvMf+e7piks11rVtl59QyR2hZnfVw2aG6tf1c3f9bdvdTUI6qI+r1VST/j9Nj8jvtbAjle532dc1vTnECw19cX7Z+HUZ5HWzGE3/zU0R11ERLQ8W4szaWAXpp3bI+D2eUU27n79a+yOVpdY0TK41rWvbd5+Q45fl+A/FKOyrtegIcF1TfUCRESahJkN57RYa2knIiKtgQL1FuiPF53B2NM6Bdz+jc37GTj/38FbX11ERERqZDjNQN3QiLqIiKBAvcX61Xm969S+uNTOrSs3K1gXEREJhYpA3WloRF1ERBSot1jDeiaRGFv3EgQL3t2qNHgREZEmZjjNOeoaURcREVCg3mJZLQa/GNmzzvvlFpawMftwEHokIiIi1aooDKo56iIiAgrUW7QZ4/oSF1X3C35e4ckg9EZERESq45mjroKWIiKiQL1Fs1oMfn1erzrvd/9732uuuoiISBNypb6jOeoiIoIC9RZvxri+tIuLrNM+h4tLma7CclXYHU427Crg7S372bCrQHP5RUSk8VSkvitQFxERgLpXG5NmxWox+PMVA5i+cjN1CSudmIXlzk9LwWpRGt7qrFwWvLuV3MIS97bUxBgyJ6cxsX9qCHsmIiItgUHFiLpFYygiItJEI+pLly6lR48exMTEMHz4cDZu3Fhj+yVLlnDaaacRGxtLt27duPPOOykpKfFpU9djtmYT+6fy5A1DSIqv28h6bmEJn+8qAFr3aPLqrFymr9zsE6QD5BWWKPNAREQahVExoq6q7yIiAk0wov7KK68wc+ZMli1bxvDhw1myZAkZGRls376dzp07V2n/4osvMmvWLFasWME555zDDz/8wM9//nMMw2Dx4sX1OqaYwfq405MZfP/7FNvsAe/3i+f+y8/P6c47X+e2ytFku8PJgne3+s1GcAIGyjwQEZGG8yzPptR3ERFpghH1xYsXM23aNKZOnUpaWhrLli0jLi6OFStW+G2/fv16Ro4cyXXXXUePHj244IILmDJlis+IeV2PKaaoCAu/OrduxeVs5Q6e+iS71Y4mb8w+XOXcvTnRknYiItIIKqq+o+XZRESEIAfqpaWlbNq0iQkTJnie0GJhwoQJbNiwwe8+55xzDps2bXIH5rt372bVqlVMmjSp3se02WwUFRX5fLVWM8b1JT664R8CXCPMC97d2qLT4A8eqz5Ir087ERERfwxcgbqys0REJMiBen5+Pna7neTkZJ/tycnJ5OXl+d3nuuuu47777mPUqFFERkbSu3dvxowZw7333lvvYy5atIjExET3V7du3Rrh7Jonq8XgoSsHNsqxWsNocue2MY3aTkRExB/POuoaURcRkTBcnm3dunU88MADPPHEE2zevJk333yT9957j/vvv7/ex5w9ezaFhYXur59++qkRe9z8TBrYhckDUxrteC15NHlYzyRSE2OobnzDwJyvP6xnUlN2S0REWhgDLc8mIiIeQS0m17FjR6xWKwcOHPDZfuDAAVJS/AeKc+fO5cYbb+SWW24BYMCAARQXF/OrX/2KP/7xj/U6ZnR0NNHR0Y1wRi3HkmuH8MmO9yk8Wd7gY+Ufs2F3OJtVMTW7w8nG7MMcPFZC57ZmoO2v/1aLQebkNKav3IwBPkXlXK0zJ6c1q3MXEZHwY3FqeTYREfEI6tUgKiqKoUOHsnbtWvc2h8PB2rVrGTFihN99Tpw4gaXSRcpqNe8uO53Oeh1TqrJaDB5spBT4+9/7nlEPfthsCsutzspl1IMfMuWZz7n95S1MeeZzzlq4hlXf5Pht71reLiXRN709JTGGJ28Y0uIr34uISJA5PbeBK38GEhGR1inoV4OZM2fyzDPP8Nxzz/H9998zffp0iouLmTp1KgA33XQTs2fPdrefPHkyTz75JC+//DLZ2dmsWbOGuXPnMnnyZHfAXtsxJTAT+6ey7IYhxEU1PM2uuVSBr25N9MPFZdz24lcsWrXV734T+6fy6T3j3I/7Jbfh03vGKUgXEZGGc3iWTXUaQV85V0REmoGgXw2uueYaDh06xLx588jLy2PQoEGsXr3aXQxu7969PneP58yZg2EYzJkzh/3799OpUycmT57MwoULAz6mBG5i/1TOT0th6v9u5JMd+fU+jmss4N5/fsvJMgcpCf7TyQNNOQ+GmtZEd3nqk2zST2nPpIFVA3DvfibGRirdXUREGodraTbAomuLiIgAhtPpbLlra1WjqKiIxMRECgsLSUhICHV3wkJpuYPT5vyrxiC2rlITY8icnOYedV6dlcuCd7f6jGZXblOThgb5G3YVMOWZz2tt1yE+io1/nOD32D1mvQfAsB5JvHqrplqISOPRtalxNavXs+wkLDTr7Pxp4PvMuWJ4iDskIiLBUJdrk/KrBICoCAu/Oq8nT32S3WjHzC0s4daVm3niusFYLAbTV26uciPAlTJf21zvhgb5EHh1+oLiUjZmH2ZE7w7VtjE04CEiIo3Fa0Rdy7OJiAiE4fJsEjqzJ6Xx6/N6Nvpxf/PiV8x641u/o/WubQve3Yrd4X88v7p55XWdF1+Xtc79BfXeyScK1EVEpNF4zVHHokBdREQUqEslsyel8f19E2kb03jJFk7g6MmyGn+eW1jCxuzDVX5W07xyZ8VXTUG+t2E9k0iKjwyoz/6Celu51xxCReoiItJYfEbU9dFMREQUqIsfsVFWHrpqIE0divobxd6YfbjKSHpl1QX5lVktBn+6tH+t7VITzfnvldnKGi9QtzucbNhVwNtb9rNhV0FANxpERKSF8g7UrRpRFxERzVGXarjWDp//znfkFdma5Dn9jWIHOq98zda8GueUu0wa2IVf7zta7Vx8A8icnOa3kFxJuSc1sSGBdWPMtxcRkRZEc9RFRKQSjahLtSb2T+WzWeO5fXzfoD9XdaPYgc4rf3tLTsDB8+xJaTw+ZbDfPtRU1M57RL3U7vDbpjaNNd9eRERaEC3PJiIilShQlxpZLQZ3nt8vKEXmvM29yP8odqDzyl2V2gM17medfR7//vx+fHrPuBpHtL1H1EvL6x6o1zbfHgKfby8iIi1IRTG5cqelTsuOiohIy6VAXQIye1IaT1w3hPio4KTkrd12gNJyR5V521aLweWDugZ0jEDT5AFOlNp9HndLiqv1w1FJWcMC9drm29dUVE9ERFqwihF1BwaGipWKiAiaoy51MGlgKhn9U3hs7Q6WrN3RqMd+Y/N+3ty832e02TVve0JaCss/21PrMWpKk7c7nGzMPszBYyV0bhtDaqJv28qBuz/eVd/rk/oe6I2EutxwEBGRFsBpXoMcWNCAuoiIgAJ1qSOrxeCO8/vRL7kNv3npK5yNmKVd+VC5hSXcunIzvxvXm5SEGPKK/AewBpBSzRx38F+8rWObKJ82J0rLa+1fQ0fUA51vX5f13kVEpAVwj6hbsGpEXUREUOq71NOkgV1YOmVIkzzX3z7cxcFqgnQwA/xJ/VPYmH24yvzu6oq35R8v9XlcbKt9RP2kV5tjJeV1nks+rGcSqYkx1S57Z1B9UT0REWnBKuao27GomJyIiAAK1KUBJg1MZdkNQ6qkkQdDbePXyz/bw5RnPueshWtY9U0OUHPxtspOlNU8or46K5e73/zG/biopIxRD35YpyrtVotB5uQ0vz9zfSyrbmk4ERFpwSrS05wYWDSiLiIiKPVdGmhi/1TOT0txz//ek3+CJR/8EFBwHAyHi8u47cWvGL95H+f07lhj8TZvJypGyyvPZR/WM4k1W/OYvnJzlXNyLalW05JulbnWp7/njW8pPFnm3p6iddRFRFqvitR3u+aoi4hIBQXq0mBWi8GI3h3cj09LacPsN7/lyImyGvYKrrXbDrF226GA22/PO8ajH+zgpY17febCpyREU1LuqHZJNQNzSbXz01ICHgmf2D+VvKIS5r+zFYC/Xp3O5YO7aiRdRKS1cheT04i6iIiYlPoujW5i/1S+uHcCbaKbz32gjXsO88gHP1QpWJdXZONoDTcc6rukmq3Mk8zft3MbBekiIq2ZVzE5zVEXERFQoC5BEhVh4a9XDwx1N5pMXZdUO+lVQb44gIrzIiLSgjm8R9RD3BcREQkLCtQlaCb2N4vNpSS0/OXG6rqkmk+gHkDFeRERacF85qgrUhcREc1RlyCrXGyuc9sYhnZvzxMf7eTxj3ZQj+XIw9KRYt/l3vwVpfNOby8p9QTngazhLiIiLZh7jrpS30VExKRAXYKucrE5gDvO78dvx/flsbU7WPrRTsrquCZ5uLnv/74jo79ZUG51Vi4L3t3qU3E+JSGaKcNOpUfHeDq3jfFJdz9uU6AuItKqVSzP5nAq9V1EREwK1CVkrBbDJ2D/+6e7Od5M08Dzimzc/frXjD89md+86GcptyIbj3yww/04JtIz62Rj9mF6dWxTZdRdRETCRLkNrFEQrLR0h2dE3arUdxERQYG6hAHvgN2VLt4xPhqH08nKL37k398dCHUXA/LG5v28sXl/QG1LvKq+v70lh7e35JCqtdRFRMJP4T54eiwkdoVxc6D3+MYP2N1V37U8m4iImBSoS9jwlyJ/br9OflPJW6K8whKmr9zMkzcMUbAuIhIuivOh+KD578orocvgRg/Y7Q47VswR9d2HjmN3OJVhJSLSyilQl7BXuSDdnvwTvLRxb5U1z5s7J2AAC97dyvlp5nz36orS1VasDmovaBdoGxERAajIhMr9plED9tVZubz79pcsxRxRX/bJbt7+OkcZViIirZwCdWkWKo+2zxjXh43Zh8krPMnh4lLaxUXx2c5DvPlVTgh72XBOILewhOWf7Ca1fSyZ73zHYa+K8u3jIujRIY7v8477pM9XTptf9U0uc97O8tm3cht/mQpKvxcRqUVFhXafgH18JvQeW+dDrc7KZfrKzYyw2CDKXJ4NlGElIiJgOJ3O5l1uux6KiopITEyksLCQhISEUHdHGlFrSZOvzhPXDebrfUd56pPsatvcOaEvfTu39Vv0zjUmpA+HIk1P16bG1WivZ84WeHp0zW06ngYzNtbpsHaHk1EPfkhuYQnnWr7hhag/s9XRnUmliwDz73FKYgyf3jNOmU4iIi1EXa5Nlhp/KtLMTOyfyqf3jOOlaWfz8FUDGd2vI3FRVr9tk+IjmXZuz2p/3hzd9uJXNQbpAI98sIMZL1UN0sEc0XcC9/7zW/751X427CrAHsDSeXaHkw27Cnh7S+D7iEjrs3TpUnr06EFMTAzDhw9n48bAgtuXX34ZwzC47LLLgtvBujAqrh1dBsOFD9Z5943Zh903lS0Vf5HteAJyV4bVxuzDDe6qiIg0P02S+r506VIeeugh8vLySE9P57HHHmPYsGF+244ZM4aPP/64yvZJkybx3nvvAfDzn/+c5557zufnGRkZrF69uvE7L82OJ02+A1ee2c09D9uVJp/UJpqUBM987FkX/ozH1u5g2ce7KCl31Hr8lqC2OPpwcRl3vrIFMG9o/OnS/kwa2MXvnPY1W/NCmkKvefYizcMrr7zCzJkzWbZsGcOHD2fJkiVkZGSwfft2OnfuXO1+e/bs4Q9/+APnnntuE/Y2AMlnwITMes9RP3jM8zfTgqvqe9XxE+92IiLSegQ9UK/rhfnNN9+ktNQzr7agoID09HSuvvpqn3YTJ07kf//3f92Po6Ojg3cS0qz5qyZf+eeu5eE+31XAht357DpUzL+y8pqwl+HrcHEZt734FRO+2sd3Ocd8AvJ2cZEcPVFWZZ/cwhJuXbmZZX5S6BszsNY8e5HmY/HixUybNo2pU6cCsGzZMt577z1WrFjBrFmz/O5jt9u5/vrrWbBgAf/5z384evRoE/a4MgvugnIA178ObZPrfbTObWO8jlx9oO7dTkREWo+gB+p1vTAnJSX5PH755ZeJi4urEqhHR0eTkpISvI5Lq2O1GIzs25GRfTsCZhA4641vOHqyPMQ9Cw8ffH+oyjZ/Qbq337/2NSfLHO4MhsYcfXcVYaqcHKAiTCLhp7S0lE2bNjF79mz3NovFwoQJE9iwYUO1+91333107tyZX/7yl/znP/9piq5WFd8J2nSGhK4w4H/g3xXnYC+teb9aDOuZRGpiDHmFJVjxrKPu4pqjPqxnUjVHEBGRliyogXp9L8zeli9fzrXXXkt8fLzP9nXr1tG5c2fat2/PuHHj+NOf/kSHDv5HTW02Gzabzf24qKioHmcjrY1rWbjPdxXw2a5D5BwtoWv7WCItFl7+708tbnm4YCi22d0p9JFWKLNXbeMafb9zQl9mjOsb0Oi63eFkwbtbq51nX3mZOxEJrfz8fOx2O8nJviPQycnJbNu2ze8+n376KcuXL2fLli0BPUfQrvWJXeGOLLBGwY+febY3MFC3WgwyJ6cxfeVmrznq5oi6669W5uQ0/Q0TEWmlghqo1+fC7G3jxo1kZWWxfPlyn+0TJ07kiiuuoGfPnuzatYt7772XCy+8kA0bNmC1Vi0MtmjRIhYsWNCwk5FWqfIou8tvx/d1p2+v+e4A//dtboh62Hz4C9K9PfLBDl78Yi/XDutWUYzOYHjFSNIX2QWAOYXh7F4dfIow+eMqwvT5roIqvzsRCX/Hjh3jxhtv5JlnnqFjx8D+Dwf1Wh9RMb2u3HMjgPKG36yd2D+VJ28Ywn/e2gzl4KwI0VM0hUdEpNUL63XUly9fzoABA6oUnrv22mvd3w8YMICBAwfSu3dv1q1bx/jx46scZ/bs2cycOdP9uKioiG7dugWv49Liec97v3RQVxaXO5j95je8vSWH8kqV2uIiLZwoax1F6hrqwDEbj67d6X78+Ee+P3/8o53ERFro1TGeQPzqhS+59qxuTEhLYWj39mz68Ui1RQVFJHg6duyI1WrlwIEDPtsPHDjgdxrbrl272LNnD5MnT3ZvczjMv6MRERFs376d3r17++zTJNd6n0DdVn27OpjYP5ULnGnwBtidFv527SAuGthFf5dERFq5oAbqdb0weysuLubll1/mvvvuq/V5evXqRceOHdm5c6ffQD06OlrF5iSooiIsPPw/g/jLVenugnTeI8D+5mZL/ZSUOdiaeyygtsWldpZ/tofln+3BMMDpJ1dexedEgi8qKoqhQ4eydu1a9xJrDoeDtWvXMmPGjCrtTz/9dL799lufbXPmzOHYsWM8+uijfgPwJrnW2xs/UAcwnJ456iN6d1SQLiIiwQ3U63ph9vbaa69hs9m44YYban2effv2UVBQQGqqPmhLaFWXKu+a7+69TFy7uCjW78pn9Xd5FNtqyQuXBvMXpINnjvzEM5K5fnh3LBaD/OO2gCrSh3JpOC1LJ83NzJkzufnmmznzzDMZNmwYS5Ysobi42F1s9qabbqJr164sWrSImJgY+vfv77N/u3btAKpsb1LlXvPS7Y0XqJeVlxOFWfU9NqrqFD4REWl9gp76XpcLs7fly5dz2WWXVSkQd/z4cRYsWMCVV15JSkoKu3bt4u6776ZPnz5kZGQE+3RE6s3fMnFXDj2Fv3gFXNmHivn7p9kct6nSfFNb/d0BVn/nm/2TGBvJz8/pzrCeHdzBuyuFfs3WPN7aksPhYs8H99rWnG+sQFrL0klzdM0113Do0CHmzZtHXl4egwYNYvXq1e46Nnv37sViqbo8WVjxnpfeiCPqZWWeQD0mIsxfAxERaRJBD9Trc2Hevn07n376Ke+//36V41mtVr755huee+45jh49SpcuXbjgggu4//77ld4uzVLlAN57PffKBdUcTmgfF0XHttF0bhONw+lk5Rc/8uG2g5TZqxkylnorPFlWMWd+Z61twXfN+c17C32C+MYKpLUsnTRnM2bMqDajbt26dTXu++yzzzZ+h+rKu9J7IwbqpeVlxAMYFiKsCtRFRAQMp7O6hNCWq6ioiMTERAoLC0lISAh1d0QazO5wupeR23/kJACGYbiXk3t2/R6Onqx5zXNpGsu8AmnXqHugBe7sDiejHvyw2loHrnWXP71nnNLgmyFdmxpXUF7P9Y/D+380v79yOQy4qlEOe/DjZ+j80R9Yx1DGzP+wUY4pIiLhpy7XprCu+i4igalubryLa5TeXyBvNQxWfLZH6fZN5LaVm7l4YCoRVgtrtx2k0M8NlOpG3wNdlu7Zz7K5cUQPNv14RHPYRRqTV+r7V7tzKYkraJT/W2Vl5t8Bw9BouoiImBSoi7QCtQXyt0/ox+e7CvjPzoN8u6+IuGgrbaMjef+7AxwvVQDfmBzAO9/k1tjGVeDuisGpJCfGknu0hK7tY9l1sDig57j/ve9ZuOp7vFcK9J4/DypGJ1IfO3IK6Fvx/esbd/OPDZ83yrSWcntFQVGLCsmJiIhJgbqIVBvIe6fU7zt8goLiMmKjLHRuG0O72CjW787n658Kq8yX7tMxjnbx0XRJjOZwcRnrdxfgaHWTbBruza9qDuhrUvn1ds2f//W+oww+tb2K0YnU0aJVW2mX9RN9Kz45RWOOguc2Qn2I8jLzhqhFgbqIiFRQoC4i1aptJB6gtNzBCxv28OPhE3RPiuPGET2IqlS12O5wsn5HPm98tY8TpXbaREfw0baDHNG8+Sb31CfZQHaV7a5idEuvG0z7+GiNtIt4WfVNDk99ks28CM/frCg83zuBBe9u5fy0lHr9fymzV2QuKVAXEZEKCtRFpEGiIiz88txeNbaxWgzOPa0T557Wyb3NlXr9/ne5vLZpH8e91pKPjjAAA1u5I1jdlkpcA/AzXvqq1pR571UJRvTuwNm9OriDk/oUyFMKvoQzu8PJnLezAN/gPArfaUG5hSVM/tsntIuLoqTcTkyElQ7xURQUl1JSbifaasEwjCrfx0RYGV94kNOBk2VOPtuZ7/N/SkREWicF6iISEq5l6Ub07sCci8+oEqwBPtvyj9uY/ea31Ra9S0mI5sweSXy47SAnSu1+20jtqkuZH/3lXjq1iWFVVp7P6/v4RztpFxfJn68YgMMBc97O8lmWzsVfar3Wg5fmYGP2YQ4XmwG6d3AebVR9n2/NO16v5/iZtRgi4XiZk1/9/Qv3/yn9PxARab0UqItIyFVeS96l8rZJA1Ldo7nea8p7j9h6j/juOHicz3bm+4zWJ8ZEYHeiKvd19PEPBdX+7OiJMm5dubnG/V0F8n45sgcT0lI4UlzKb16sfT147xH3jvHRYED+cZvP9xqJl2D6YGue+/soo/oR9YawVPxPcGK+h13/p5Y1YN67iIg0bwrURaTZCGTOfOU2/lKrAZ/07HZxURwutvHlj0f4cNtByuyqfBcsyz/bw/LP9mBAlSAdr23z3/mOMruTzHe+8ztCX5lG4iUYVmflsvyzPe7H0V6p797fN5QVc5qP3elb36Mh895FRKR5U6AuIi1aoKP1ANMwA/vHP9zJik93U1iiUfdgqe1WSF6Rjd++9FXAx3ON2D9x3WAy+qe6VyvYf+QkhmHQtX0s5/TuWO+5v5pL3/rYHU7mv/OdzzbvUfSoRgzUXSPqDnzfU7mFJWzMPuz375WIiLRsCtRFRLxYLQa3T+jLjHF9fAKzod3bs+nHIz4p2Gu/P8CrX+5TGn0Yue3Fr4iybqHUT1bE0o92uef+np+WUmvg7QrO12zN460tOT4j+xrBb/k2Zh/mWNERorBSShTxnCSak+6fxxsniMIGGERSRhkRUBFoez+u7nuXUiKxVIyoO/AdUQc4eKykyjYREWn5FKiLiPjhbyS+8uORfTryx4vS+HxXAc9/voePfzhESZmnUr3F8C3OZjHA6ax9NFkaxl+Q7uKa+xsbaeGk1+8quW001w0/lVOT4jh4rIQPth5gy77CaqdBuEbwH792EBcP6tro5yChV/rjF3wTfQsGUOBsSwfjmM9498WWjVwcvREHuMNrB+b/b6vXY0s135vz0Q32OjvzlaN3xfaqWRqd28Y04lmJiEhzoUBdRKQBvOfEV06P9h6F954f/9jaHfz9090+Re7ax0XQLjaS7IKT1T2VNCLvIB3gwDEbj3ywo87HmfHyFv71XR5/mzJEqfAtTBd7HtaKX2kn41iVnxsVP/Ne+bzyKujV/cz83gk46WXk0ctiFqxLMQ5XbDcPnpro+bshIiKti+F0Olvd4E5RURGJiYkUFhaSkJAQ6u6ISCtU3ZznVd/kVrvEmYSvmAgLi/8n3b3efH3o2tS4Gvp62r9+Bes/fxWEntVstyOF+eU384ljIMtuGKrpFSIiLUhdrk0aURcRCYHqitxNGphKRn/f+dNHiku5961vOXrCt3hVu9gIrj6zG29s3q/APsRKyh3c9uJX/HrfUWZPSgt1d6QRWI3QZEj0suTxfNSDHG/TgzaxSwAF6iIirZECdRGRMOMviM/on+JeHx7Mn7sqmM+68Gc+a42X2x38c8t+TpTaaRMdwfvfHeB4qQreNYWnPskm/ZT2TBqo4Eoaps3xPfCve2DGxlB3RUREQkCBuohIM1DTGvL+AvvRp3d2f293ON1BvsMJibGRfPXTEf6zI59ir3nylUVZjRoLs4l/c9/OIqO/1r5u7uxOZ5U5502qQx+48MFQ9kBEREJIgbqISAtXXZDvPU8+KTaKbQeO8dORE3RPiuPGET2wWgw2Zh8m58gJtuw7WlHB3kliTBQYkFdYwnvf5mIrd1R5zsoV71uTguJSrX3dAuw+WEzfUDxxUm+48C/QZ7ynYp2IiLQ6CtRFRFqpyiPx557WqUob8+cduPLMbn6P8dDV6Xy+q4DPdh0i52gJXdvHck7vjpzdqwP/zsrj7je+aZXrzGvt6+avsKSs9kaNSQG6iIh4UaAuIiL1VlNKvqswnncgX1JuZ+PuIxw+4Sl+l5IQzZRhp7Llp6N8tP1QleNEWOCS9FRS28Wx+1Ax/9mRH/bBv9a+bv6iOvXF7sRnHXVwLarmtdyagdfq567vaksnMSp2NKB9DwXoIiJShQJ1EREJGn+BfHVL0wGUljt4bn02/91zhPgoK1cMOYVz+nT0me/tPed+16Fi/vNDvt9ieTGRFkb26sBaP8F/MGnt65bhjGFjuWDtSvYdK8NGFPGcpAwrrmA8ijKS2rTho7vGYnWUgjXKE2iX2zyPq/veJSJaAbqIiFShQF1ERJpUdUvTAURFWJh2Xm+mnVfz/t7Bvytw95d+71qbvj4p+AZgtYCfKfg17pM5OU2F5FoAq8XgrkvPZPrKzRhAMXHunxlAGVH89bLBWKNjgVjfnSNjav9eRESkBobT6Wx15X7qstC8iIg0f/6C+bN7mjcLNuzOZ/+RkwAYhuET6AM+y+JFWAxe/u9P5BVVnYOemhhD5uQ0Jvav39JsujY1rsZ6PVdn5bLg3a3kFnp+5w39XYuISOtUl2uTAnV9GBIRkTpwpe7nFZ7kcHEpSW2iSUnwTeGvD12bGldjvp41TdcQEREJVF2uTUp9FxERqYOaUvelZdLvXEREmpol1B0QEREREREREQ8F6iIiIiIiIiJhpEkC9aVLl9KjRw9iYmIYPnw4GzdurLbtmDFjMAyjytdFF13kbuN0Opk3bx6pqanExsYyYcIEduzY0RSnIiIiIiIiIhJUQQ/UX3nlFWbOnElmZiabN28mPT2djIwMDh486Lf9m2++SW5urvsrKysLq9XK1Vdf7W7zl7/8hb/97W8sW7aML774gvj4eDIyMigpqVqFV0RERERERKQ5CXqgvnjxYqZNm8bUqVNJS0tj2bJlxMXFsWLFCr/tk5KSSElJcX+tWbOGuLg4d6DudDpZsmQJc+bM4dJLL2XgwIE8//zz5OTk8NZbbwX7dERERERERESCKqiBemlpKZs2bWLChAmeJ7RYmDBhAhs2bAjoGMuXL+faa68lPj4egOzsbPLy8nyOmZiYyPDhw6s9ps1mo6ioyOdLREREREREJBwFdXm2/Px87HY7ycnJPtuTk5PZtm1brftv3LiRrKwsli9f7t6Wl5fnPkblY7p+VtmiRYtYsGBBle0K2EVEJFy4rklOpzPEPWkZXK+jrvUiIhIu6nKtD+t11JcvX86AAQMYNmxYg44ze/ZsZs6c6X68f/9+0tLS6NatW0O7KCIi0qiOHTtGYmJiqLvR7B07dgzg/9u7/5io6z8O4M874Q4cHoeecKCiNAmHBhYEXfbjDyhTy3C1MUeLUVNR2GS5mlkIWRtubS1z5T+W/BcphpYpEw6haIhKkKBF2khYg8NkyA8FgXt9/3B++p4Q8kG4+yDPx3YbfN7vu70/T2578oa7+7DriYhIc8bS9ZO6UbdYLJgxYwYcDofLcYfDAavVOup9e3t7UVBQgF27drkcv3M/h8OB4OBgl8dcvnz5iI9lNBphNBqV7/38/NDS0oJZs2ZBp9OpOaVhurq6sGDBArS0tMBkMt3XY00XzEw9ZqYeM1OPmak3kZmJCLq7uxESEjJBq5veQkJC2PUexMzUY2bqMTP1mJl6nur6Sd2oGwwGxMTEwG63IykpCQDgdDpht9uRmZk56n0PHTqE/v5+vPbaay7Hw8LCYLVaYbfblY15V1cXqqursXnz5jGtS6/XY/78+arPZzQmk4lPdpWYmXrMTD1mph4zU2+iMuN/0icOu14bmJl6zEw9ZqYeM1PP3V0/6S99f+utt5CamorY2FjExcXh008/RW9vL9LS0gAAr7/+OubNm4e8vDyX+3355ZdISkrCnDlzXI7rdDpkZWXho48+Qnh4OMLCwpCdnY2QkBDljwFEREREREREU9Wkb9STk5Nx9epV7Ny5E21tbVi+fDmKi4uVD4Nrbm6GXu/64fONjY2orKzEyZMnR3zMd955B729vdi4cSM6Ozvx1FNPobi4GD4+PpN9OkRERERERESTyi0fJpeZmfmfL3UvLy8fdiwiImLUT8LT6XTYtWvXsPeve4LRaEROTo7Le+BpdMxMPWamHjNTj5mpx8ymB/6c1WNm6jEz9ZiZesxMPU9lphNeB4aIiIiIiIhIM/T3nkJERERERERE7sKNOhEREREREZGGcKNOREREREREpCHcqBMRERERERFpCDfq9+Hzzz/HokWL4OPjg/j4eJw5c8bTS/KYH3/8ES+99BJCQkKg0+lw5MgRl3ERwc6dOxEcHAxfX18kJibi0qVLLnM6OjqQkpICk8kEs9mMN998Ez09PW48C/fJy8vD448/jlmzZiEwMBBJSUlobGx0mdPX14eMjAzMmTMHfn5+eOWVV+BwOFzmNDc3Y82aNZg5cyYCAwPx9ttvY3Bw0J2n4lb79u1DVFQUTCYTTCYTbDYbTpw4oYwzs9Ht3r0bOp0OWVlZyjFmNlxubi50Op3LbcmSJco4M5te2PX/Yterx75Xj11/f9j1YzMlul5oXAoKCsRgMMhXX30lFy5ckA0bNojZbBaHw+HppXnE8ePH5b333pNvv/1WAEhRUZHL+O7du8Xf31+OHDkiv/76q6xdu1bCwsLk5s2bypwXXnhBoqOj5fTp0/LTTz/J4sWLZf369W4+E/dYuXKlHDhwQBoaGqSurk5Wr14toaGh0tPTo8xJT0+XBQsWiN1ul3PnzskTTzwhTz75pDI+ODgoy5Ytk8TERKmtrZXjx4+LxWKRd9991xOn5Bbfffed/PDDD/LHH39IY2Oj7NixQ7y9vaWhoUFEmNlozpw5I4sWLZKoqCjZunWrcpyZDZeTkyNLly6V1tZW5Xb16lVlnJlNH+x6V+x69dj36rHrx49dP3ZToeu5UR+nuLg4ycjIUL4fGhqSkJAQycvL8+CqtOHu8nY6nWK1WuXjjz9WjnV2dorRaJSvv/5aREQuXrwoAOTs2bPKnBMnTohOp5O///7bbWv3lPb2dgEgFRUVInI7H29vbzl06JAy57fffhMAUlVVJSK3f2HS6/XS1tamzNm3b5+YTCbp7+937wl4UEBAgOzfv5+ZjaK7u1vCw8OlpKREnn32WaW8mdnIcnJyJDo6esQxZja9sOv/G7t+fNj348Ouvzd2vTpToev50vdxuHXrFmpqapCYmKgc0+v1SExMRFVVlQdXpk1NTU1oa2tzycvf3x/x8fFKXlVVVTCbzYiNjVXmJCYmQq/Xo7q62u1rdrfr168DAGbPng0AqKmpwcDAgEtmS5YsQWhoqEtmjzzyCIKCgpQ5K1euRFdXFy5cuODG1XvG0NAQCgoK0NvbC5vNxsxGkZGRgTVr1rhkA/B5NppLly4hJCQEDz30EFJSUtDc3AyAmU0n7Hp12PVjw75Xh10/dux69bTe9V4T8ijTzD///IOhoSGXHwwABAUF4ffff/fQqrSrra0NAEbM685YW1sbAgMDXca9vLwwe/ZsZc6Dyul0IisrCytWrMCyZcsA3M7DYDDAbDa7zL07s5EyvTP2oKqvr4fNZkNfXx/8/PxQVFSEyMhI1NXVMbMRFBQU4JdffsHZs2eHjfF5NrL4+Hjk5+cjIiICra2t+OCDD/D000+joaGBmU0j7Hp12PX3xr4fO3a9Oux69aZC13OjTuRhGRkZaGhoQGVlpaeXMiVERESgrq4O169fR2FhIVJTU1FRUeHpZWlSS0sLtm7dipKSEvj4+Hh6OVPGqlWrlK+joqIQHx+PhQsX4uDBg/D19fXgyohoKmPfjx27fuzY9eMzFbqeL30fB4vFghkzZgz75D+HwwGr1eqhVWnXnUxGy8tqtaK9vd1lfHBwEB0dHQ90ppmZmTh27BhOnTqF+fPnK8etVitu3bqFzs5Ol/l3ZzZSpnfGHlQGgwGLFy9GTEwM8vLyEB0djT179jCzEdTU1KC9vR2PPfYYvLy84OXlhYqKCnz22Wfw8vJCUFAQMxsDs9mMhx9+GJcvX+bzbBph16vDrh8d+14ddv3Ysesnhha7nhv1cTAYDIiJiYHdbleOOZ1O2O122Gw2D65Mm8LCwmC1Wl3y6urqQnV1tZKXzWZDZ2cnampqlDllZWVwOp2Ij493+5onm4ggMzMTRUVFKCsrQ1hYmMt4TEwMvL29XTJrbGxEc3OzS2b19fUuv/SUlJTAZDIhMjLSPSeiAU6nE/39/cxsBAkJCaivr0ddXZ1yi42NRUpKivI1M7u3np4e/PnnnwgODubzbBph16vDrh8Z+35isOv/G7t+Ymiy6yfkI+mmoYKCAjEajZKfny8XL16UjRs3itlsdvnkv+mku7tbamtrpba2VgDIJ598IrW1tXLlyhURuX3JFrPZLEePHpXz58/Lyy+/POIlWx599FGprq6WyspKCQ8Pf2Av2bJ582bx9/eX8vJyl8tC3LhxQ5mTnp4uoaGhUlZWJufOnRObzSY2m00Zv3NZiOeff17q6uqkuLhY5s6d+0BfSmP79u1SUVEhTU1Ncv78edm+fbvodDo5efKkiDCzsfj/T4IVYWYj2bZtm5SXl0tTU5P8/PPPkpiYKBaLRdrb20WEmU0n7HpX7Hr12PfqsevvH7v+3qZC13Ojfh/27t0roaGhYjAYJC4uTk6fPu3pJXnMqVOnBMCwW2pqqojcvmxLdna2BAUFidFolISEBGlsbHR5jGvXrsn69evFz89PTCaTpKWlSXd3twfOZvKNlBUAOXDggDLn5s2bsmXLFgkICJCZM2fKunXrpLW11eVx/vrrL1m1apX4+vqKxWKRbdu2ycDAgJvPxn3eeOMNWbhwoRgMBpk7d64kJCQoxS3CzMbi7vJmZsMlJydLcHCwGAwGmTdvniQnJ8vly5eVcWY2vbDr/8WuV499rx67/v6x6+9tKnS9TkRkYv43T0RERERERET3i+9RJyIiIiIiItIQbtSJiIiIiIiINIQbdSIiIiIiIiIN4UadiIiIiIiISEO4USciIiIiIiLSEG7UiYiIiIiIiDSEG3UiIiIiIiIiDeFGnYhGlJ+fj9WrVyM9PR0ffvih6vvn5uaioaFhElZGREREE4V9T6RNOhERTy+CiLQnPz8fFosFL774IgAgMjISmzZtQn19Pfbs2YPS0lJ8//336OvrQ25uLry9vfH+++8jMDAQ69atQ2lpKTo6OtDd3Y1nnnkGaWlpHj4jIiIiuhv7nkibuFEnohHl5+fj4MGDCA0NxdKlS3H06FGUlpaiqKgIfX19KCwsxOHDh3HlyhXs3bsXer0eGzZsQHh4OIDbf2F/7rnnsGLFCiQnJ+Obb77x8BkRERHR3dj3RNrk5ekFEJF2bdmyRfkL++HDhwEAAwMDLnN0Oh1EBCICvd713TT+/v7KHCIiItIm9j2R9nCjTkT/6YsvvsCxY8cQEBCAa9euYceOHWhqasL+/fvh4+ODTZs24caNG8jOzoa3tzdyc3MRHByMtWvXenrpRERENEbseyLt4UvfiWhMXn31VRQWFnp6GURERDSJ2PdE2sCNOhEREREREZGG8PJsRERERERERBrCjToRERERERGRhnCjTkRERERERKQh3KgTERERERERaQg36kREREREREQawo06ERERERERkYZwo05ERERERESkIdyoExEREREREWkIN+pEREREREREGvI/NW+afx4aql4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "valid_dataset = TensorDataset(x_valid, y_valid)\n",
    "\n",
    "batch_size = 128\n",
    "train_dl = DataLoader(train_dataset, batch_size= batch_size, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size = batch_size, shuffle=False, drop_last=True)\n",
    "test_dl  = DataLoader(test_dataset, batch_size= batch_size, shuffle=False)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# (258, 195, 300)\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim = 300,\n",
    "                 hidden_size = 64,\n",
    "                 bidirectional = False,\n",
    "                 num_layers = 2,\n",
    "                 dropout = 0.2\n",
    "        ):\n",
    "        super(Model, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size= embed_dim,\n",
    "                            hidden_size = hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            bias= False,\n",
    "                            bidirectional=bidirectional,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout\n",
    "        )\n",
    "        self.D = 1 if self.bidirectional == False else 2\n",
    "        self.fc2 = nn.Linear(self.D * hidden_size , 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        out, (h1, c1) = self.lstm(x) \n",
    "        out = out[:, -1, :]\n",
    "        out = F.softmax(self.fc2(out), dim = -1)\n",
    "        return out\n",
    "\n",
    "torch.manual_seed(42) # for the distribution of the gradient\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "model = Model()\n",
    "model.to(device=device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 3e-4)\n",
    "print(sum(p.numel() for p in model.parameters()),'parameters')\n",
    "\n",
    "import time\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "num_iter = 500\n",
    "for i in range(num_iter):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    t1 = time.time()\n",
    "    model.train()\n",
    "    for xb_train, yb_train in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        xb_train = xb_train.to(device)\n",
    "        yb_train = yb_train.to(device)\n",
    "        with torch.autocast(device_type = 'cuda', dtype = torch.bfloat16):\n",
    "            logits= model(xb_train)\n",
    "            loss = F.cross_entropy(logits, yb_train)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        train_loss += loss.item() * batch_size\n",
    "        train_acc += (torch.argmax(logits, dim = 1) == yb_train).float().sum().item()\n",
    "        # update the gradient\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_dl.dataset)\n",
    "    train_acc /= len(train_dl.dataset)\n",
    "     \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for xb_valid, yb_valid in valid_dl:\n",
    "            xb_valid = xb_valid.to(device)\n",
    "            yb_valid = yb_valid.to(device)\n",
    "            logits = model(xb_valid)\n",
    "            loss = F.cross_entropy(logits, yb_valid)\n",
    "            valid_loss += loss.item() * batch_size\n",
    "            valid_acc += (torch.argmax(logits, dim = 1) == yb_valid).float().sum().item()\n",
    "    \n",
    "    valid_loss /= len(valid_dl.dataset)\n",
    "    valid_acc /= len(valid_dl.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    valid_accuracies.append(valid_acc)\n",
    "    t2 = time.time()\n",
    "    dt = (t2 - t1)\n",
    "    print(f'epoch {i} || train_loss {train_loss:.3f}, valid_loss {valid_loss:.3f}, train_accu {train_acc:.3f} , valid_accu {valid_acc:.3f}, dt= {dt:.2f}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_arr = np.arange(num_iter) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, train_losses, '-o', label='Train loss')\n",
    "ax.plot(x_arr, valid_losses, '->', label='Validation loss')\n",
    "ax.legend(fontsize=5)\n",
    "ax.set_xlabel('Epoch', size=5)\n",
    "ax.set_ylabel('Loss', size=5)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, train_accuracies, '-o', label='Train acc.')\n",
    "ax.plot(x_arr, valid_accuracies, '->', label='Validation acc.')\n",
    "ax.legend(fontsize=5)\n",
    "ax.set_xlabel('Epoch', size=5)\n",
    "ax.set_ylabel('Accuracy', size=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.712590799031477\n",
      "Precision: 0.7174182732884747\n",
      "Recall: 0.712590799031477\n",
      "F1-Score: 0.7138044132184673\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69      1213\n",
      "           1       0.67      0.66      0.67      1509\n",
      "           2       0.82      0.76      0.79      1408\n",
      "\n",
      "    accuracy                           0.71      4130\n",
      "   macro avg       0.72      0.71      0.71      4130\n",
      "weighted avg       0.72      0.71      0.71      4130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "test_acc = 0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for xb_test, yb_test in test_dl:\n",
    "        xb_test = xb_test.to(device)\n",
    "        yb_test = yb_test.to(device)\n",
    "        logits = model(xb_test)\n",
    "        pred = torch.argmax(logits, dim = 1)\n",
    "        test_acc += (pred == yb_test).float().sum().item()\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(yb_test.cpu().numpy())\n",
    "\n",
    "test_acc /= len(test_dl.dataset)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')  # 'weighted' pour pondérer selon les classes\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print('test accuracy', test_acc)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# train_dataset = TensorDataset(x_train, y_train)\n",
    "# test_dataset = TensorDataset(x_test, y_test)\n",
    "# valid_dataset = TensorDataset(x_valid, y_valid)\n",
    "\n",
    "# batch_size = 128\n",
    "# train_dl = DataLoader(train_dataset, batch_size= batch_size, shuffle=True, drop_last=True)\n",
    "# valid_dl = DataLoader(valid_dataset, batch_size = batch_size, shuffle=True, drop_last=True)\n",
    "# test_dl  = DataLoader(test_dataset, batch_size= batch_size, shuffle=True, drop_last= True)\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# # (258, 195, 300)\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self,\n",
    "#                  embed_dim = 300,\n",
    "#                  hidden_size = 128,\n",
    "#                  bidirectional = False,\n",
    "#                  num_layers = 1,\n",
    "#                  dropout = 0.2\n",
    "#         ):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.bidirectional = bidirectional\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_size= embed_dim,\n",
    "#                             hidden_size = hidden_size,\n",
    "#                             num_layers=num_layers,\n",
    "#                             bias= False,\n",
    "#                             bidirectional=bidirectional,\n",
    "#                             batch_first=True,\n",
    "#                             # dropout=dropout\n",
    "#         )\n",
    "#         self.D = 1 if self.bidirectional == False else 2\n",
    "#         self.fc2 = nn.Linear(self.D * hidden_size , 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         B, T, C = x.shape\n",
    "#         out, (h1, c1) = self.lstm(x)\n",
    "#         out = F.softmax(self.fc2(out), dim = -1)\n",
    "#         return out\n",
    "\n",
    "# torch.manual_seed(42) # for the distribution of the gradient\n",
    "\n",
    "# torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# model = Model()\n",
    "# model.to(device=device)\n",
    "# # model = torch.compile(model)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr = 3e-4)\n",
    "# print(sum(p.numel() for p in model.parameters()),'parameters')\n",
    "\n",
    "# import time\n",
    "# num_iter = 200\n",
    "# for i in range(num_iter):\n",
    "#     train_loss = 0\n",
    "#     train_acc = 0\n",
    "#     t1 = time.time()\n",
    "#     model.train()\n",
    "#     for xb_train, yb_train in train_dl:\n",
    "#         optimizer.zero_grad()\n",
    "#         # forward pass\n",
    "#         xb_train = xb_train.to(device)\n",
    "#         yb_train = yb_train.to(device)\n",
    "#         with torch.autocast(device_type = 'cuda', dtype = torch.float16):\n",
    "#             logits= model(xb_train)[:, -1, :]\n",
    "#             loss = F.cross_entropy(logits, yb_train)\n",
    "#         # backward pass\n",
    "#         loss.backward()\n",
    "#         train_loss += loss.item() * batch_size\n",
    "#         train_acc += (torch.argmax(logits, dim = 1) == yb_train).float().sum().item()\n",
    "#         # update the gradient\n",
    "#         optimizer.step()\n",
    "\n",
    "#     train_loss /= len(train_dl.dataset)\n",
    "#     train_acc /= len(train_dl.dataset)\n",
    "     \n",
    "#     model.eval()\n",
    "#     valid_loss = 0\n",
    "#     valid_acc = 0\n",
    "#     with torch.no_grad():\n",
    "#         for xb_valid, yb_valid in valid_dl:\n",
    "#             xb_valid = xb_valid.to(device)\n",
    "#             yb_valid = yb_valid.to(device)\n",
    "#             logits = model(xb_valid)[:, -1, :]\n",
    "#             loss = F.cross_entropy(logits, yb_valid)\n",
    "#             valid_loss += loss.item() * batch_size\n",
    "#             valid_acc += (torch.argmax(logits, dim = 1) == yb_valid).float().sum().item()\n",
    "    \n",
    "#     valid_loss /= len(valid_dl.dataset)\n",
    "#     valid_acc /= len(valid_dl.dataset)\n",
    "#     t2 = time.time()\n",
    "#     dt = (t2 - t1)\n",
    "#     print(f'epoch {i} || train_loss {train_loss:.3f}, valid_loss {valid_loss:.3f}, train_accu {train_acc:.3f} , valid_accu {valid_acc:.3f}, dt= {dt:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
