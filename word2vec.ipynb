{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9536</td>\n",
       "      <td>Cooking microwave pizzas, yummy</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6135</td>\n",
       "      <td>Any plans of allowing sub tasks to show up in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17697</td>\n",
       "      <td>I love the humor, I just reworded it. Like sa...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14182</td>\n",
       "      <td>naw idk what ur talkin about</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17840</td>\n",
       "      <td>That sucks to hear. I hate days like that</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41639</th>\n",
       "      <td>10277</td>\n",
       "      <td>Fuck no internet damn time warner!</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41640</th>\n",
       "      <td>8610</td>\n",
       "      <td>Looking forward to android 1.5 being pushed t...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41641</th>\n",
       "      <td>8114</td>\n",
       "      <td>Not good. Wasted time.</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41642</th>\n",
       "      <td>3034</td>\n",
       "      <td>U were great, as always. But, can`t we do an ...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41643</th>\n",
       "      <td>11601</td>\n",
       "      <td>- Love your desserts. Used to live in OR but ...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41644 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  label  \\\n",
       "0       9536                    Cooking microwave pizzas, yummy      2   \n",
       "1       6135  Any plans of allowing sub tasks to show up in ...      1   \n",
       "2      17697   I love the humor, I just reworded it. Like sa...      2   \n",
       "3      14182                       naw idk what ur talkin about      1   \n",
       "4      17840          That sucks to hear. I hate days like that      0   \n",
       "...      ...                                                ...    ...   \n",
       "41639  10277                 Fuck no internet damn time warner!      0   \n",
       "41640   8610   Looking forward to android 1.5 being pushed t...      1   \n",
       "41641   8114                             Not good. Wasted time.      0   \n",
       "41642   3034   U were great, as always. But, can`t we do an ...      2   \n",
       "41643  11601   - Love your desserts. Used to live in OR but ...      2   \n",
       "\n",
       "      sentiment  \n",
       "0      positive  \n",
       "1       neutral  \n",
       "2      positive  \n",
       "3       neutral  \n",
       "4      negative  \n",
       "...         ...  \n",
       "41639  negative  \n",
       "41640   neutral  \n",
       "41641  negative  \n",
       "41642  positive  \n",
       "41643  positive  \n",
       "\n",
       "[41644 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = 'data/train.csv'\n",
    "test_data = 'data/test.csv'\n",
    "valid_data = 'data/test.csv'\n",
    "\n",
    "file = \"multiclass_dataset.csv\"\n",
    "\n",
    "def save_load_df(file:str):\n",
    "    if os.path.exists(file):\n",
    "        df = pd.read_csv(file, index_col= 0)\n",
    "    else:\n",
    "        df = pd.concat(map(pd.read_csv, [train_data, test_data, valid_data]), axis= 0, ignore_index=True)\n",
    "        df.to_csv(file, columns= ['id', 'text', 'label', 'sentiment'])\n",
    "        df = pd.read_csv(file, index_col= 0)\n",
    "    return df\n",
    "\n",
    "df = save_load_df(file=file)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP1, TP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess():\n",
    "    def __init__(self):\n",
    "        self.text_pattern = re.compile(\n",
    "        r'(<.+?>)'         # Balises HTML\n",
    "        r'|([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'  # Emails\n",
    "        r'|(https?://[^\\s\\n\\r]+)' # URLs commençant par http ou https\n",
    "        r'|(www\\.[^\\s]+)'      # URLs commençant par www\n",
    "        r'|([\\U00010000-\\U0010ffff])'  # Émojis et autres caractères au-delà de l'ASCII étendu\n",
    "        r'|([^\\x00-\\xFF])'     # Tout ce qui n'est pas en ASCII étendu (0-255)\n",
    "        )\n",
    "        self.emoji_pattern = re.compile(\n",
    "            \"[\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "            \"\\U0001F300-\\U0001F5FF\"  # Miscellaneous Symbols and Pictographs\n",
    "            \"\\U0001F680-\\U0001F6FF\"  # Transport and Map Symbols\n",
    "            \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "            \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "            \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "            \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "            \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "            \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "            \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "            \"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "            \"]+\",\n",
    "            flags=re.UNICODE,\n",
    "        )\n",
    "        self.punctuation = set(string.punctuation)\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = self.text_pattern.sub('', str(text))\n",
    "        text = self.emoji_pattern.sub('', str(text))\n",
    "        text = text.lower()\n",
    "        return text\n",
    "    \n",
    "    def get_tokens(self, text):\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        tokens = []\n",
    "        for sentence in sentences:\n",
    "            words = nltk.word_tokenize(sentence)\n",
    "            for word in words:\n",
    "                if word not in self.stop_words:\n",
    "                    word = ''.join([c for c in word if c not in self.punctuation])\n",
    "                    if word == '':\n",
    "                        continue\n",
    "                    tokens.append(word)\n",
    "        return tokens\n",
    "\n",
    "    def lemmetize_with_pos(self, tokens):\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        lemmes = [] \n",
    "        pos_tag = []\n",
    "        for token, pos in pos_tags:\n",
    "            if pos.startswith('J'):\n",
    "                lemma = self.lemmatizer.lemmatize(token, pos = 'a')\n",
    "            elif pos.startswith('V'):\n",
    "                lemma =  self.lemmatizer.lemmatize(token, pos = 'v')\n",
    "            elif pos.startswith('RB'):\n",
    "                lemma = self.lemmatizer.lemmatize(token, pos = 'r')\n",
    "            elif pos.startswith('N'):\n",
    "                lemma = self.lemmatizer.lemmatize(token, pos = 'n')\n",
    "            else:\n",
    "                lemma = self.lemmatizer.lemmatize(token)\n",
    "            lemmes.append(lemma)\n",
    "            pos_tag.append(pos)\n",
    "        return lemmes, pos_tag\n",
    "    \n",
    "    def get_lemmes(self, text):\n",
    "        text = self.clean_text(text)\n",
    "        tokens = self.get_tokens(text)\n",
    "        lemmes, _ = self.lemmetize_with_pos(tokens)\n",
    "        return lemmes\n",
    "    \n",
    "    def visualize_data(self, text):\n",
    "        text = self.clean_text(text)\n",
    "        tokens = self.get_tokens(text)\n",
    "        lemmes, pos_tag = self.lemmetize_with_pos(tokens)\n",
    "        data = [[token, lemme, pos] for token, lemme, pos in zip(tokens, lemmes, pos_tag)]\n",
    "        return data\n",
    "    \n",
    "texts = list(df['text'])\n",
    "labels = list(df['label'])\n",
    "process_text = PreProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cook, microwave, pizza, yummy]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[plan, allow, sub, task, show, widget]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[love, humor, reword, like, say, group, therap...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[naw, idk, ur, talkin]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[suck, hear, hate, day, like]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41639</th>\n",
       "      <td>[fuck, internet, damn, time, warner]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41640</th>\n",
       "      <td>[look, forward, android, 15, push, g1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41641</th>\n",
       "      <td>[good, waste, time]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41642</th>\n",
       "      <td>[u, great, always, east, germany, noko, least,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41643</th>\n",
       "      <td>[love, dessert, use, live, live, tx, visit]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41644 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0                        [cook, microwave, pizza, yummy]      2\n",
       "1                 [plan, allow, sub, task, show, widget]      1\n",
       "2      [love, humor, reword, like, say, group, therap...      2\n",
       "3                                 [naw, idk, ur, talkin]      1\n",
       "4                          [suck, hear, hate, day, like]      0\n",
       "...                                                  ...    ...\n",
       "41639               [fuck, internet, damn, time, warner]      0\n",
       "41640             [look, forward, android, 15, push, g1]      1\n",
       "41641                                [good, waste, time]      0\n",
       "41642  [u, great, always, east, germany, noko, least,...      2\n",
       "41643        [love, dessert, use, live, live, tx, visit]      2\n",
       "\n",
       "[41644 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.DataFrame(data = [(process_text.get_lemmes(text), label) for text, label in zip(texts, labels)], columns=['sentence', 'label'])\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[true, nonpremium, version, soon, loose, way, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[rereview, could, best, habit, tracker, goal, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[one, major, shortcoming, app, habit, tracker,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[one, major, shortcoming, app, habit, tracker,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[bought, pro, version, week, ago, great, conce...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41502</th>\n",
       "      <td>[laggy]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41503</th>\n",
       "      <td>[ibood]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41504</th>\n",
       "      <td>[miss]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41505</th>\n",
       "      <td>[home]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41506</th>\n",
       "      <td>[zokay]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41507 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0      [true, nonpremium, version, soon, loose, way, ...      1\n",
       "1      [rereview, could, best, habit, tracker, goal, ...      1\n",
       "2      [one, major, shortcoming, app, habit, tracker,...      2\n",
       "3      [one, major, shortcoming, app, habit, tracker,...      2\n",
       "4      [bought, pro, version, week, ago, great, conce...      2\n",
       "...                                                  ...    ...\n",
       "41502                                            [laggy]      1\n",
       "41503                                            [ibood]      1\n",
       "41504                                             [miss]      0\n",
       "41505                                             [home]      1\n",
       "41506                                            [zokay]      1\n",
       "\n",
       "[41507 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the empty rows , and sort the DF by length of the text \n",
    "corpus = corpus[corpus['sentence'].str.len() != 0]\n",
    "corpus = corpus.sort_values(by = 'sentence', key = lambda sent: sent.str.len(), ascending=False)\n",
    "corpus = corpus.reset_index(drop = True)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.12792969, 0.047851562, 0.106933594, 0.0017...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.123535156, 0.031982422, 0.15039062, 0.1523...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.045654297, -0.14550781, 0.15625, 0.1660156...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.045654297, -0.14550781, 0.15625, 0.1660156...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.16699219, -0.05419922, -0.087402344, 0.019...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41352</th>\n",
       "      <td>[[0.040527344, 0.0625, -0.017456055, 0.0786132...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41353</th>\n",
       "      <td>[[-0.05102539, 0.045898438, -0.2734375, -0.259...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41354</th>\n",
       "      <td>[[-0.07763672, -0.15722656, -0.15136719, 0.292...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41355</th>\n",
       "      <td>[[-0.1796875, 0.057128906, 0.14160156, -0.0771...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41356</th>\n",
       "      <td>[[-0.01184082, 0.079589844, 0.016845703, -0.08...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41357 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     vec  label\n",
       "0      [[0.12792969, 0.047851562, 0.106933594, 0.0017...      1\n",
       "1      [[0.123535156, 0.031982422, 0.15039062, 0.1523...      1\n",
       "2      [[0.045654297, -0.14550781, 0.15625, 0.1660156...      2\n",
       "3      [[0.045654297, -0.14550781, 0.15625, 0.1660156...      2\n",
       "4      [[0.16699219, -0.05419922, -0.087402344, 0.019...      2\n",
       "...                                                  ...    ...\n",
       "41352  [[0.040527344, 0.0625, -0.017456055, 0.0786132...      0\n",
       "41353  [[-0.05102539, 0.045898438, -0.2734375, -0.259...      1\n",
       "41354  [[-0.07763672, -0.15722656, -0.15136719, 0.292...      1\n",
       "41355  [[-0.1796875, 0.057128906, 0.14160156, -0.0771...      2\n",
       "41356  [[-0.01184082, 0.079589844, 0.016845703, -0.08...      1\n",
       "\n",
       "[41357 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "sentences = list(corpus['sentence'])\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary= True)\n",
    "\n",
    "def sentence_to_vec(sentence):\n",
    "    sentence_to_vec = [word2vec_model[word] for word in sentence if word in word2vec_model]\n",
    "    return sentence_to_vec\n",
    "\n",
    "df1 = pd.DataFrame(data = [(sentence_to_vec(sentence), label) for sentence, label in zip(sentences, list(corpus['label']))], \n",
    "                   columns=['vec', 'label'])\n",
    "\n",
    "df1 = df1[df1['vec'].str.len() != 0]\n",
    "df1 = df1.sort_values(by = 'vec', key = lambda vec: vec.str.len(), ascending=False)\n",
    "df1 = df1.reset_index(drop= True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.31835938, 0.059570312, -0.22949219, 0.087...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.048583984, 0.14355469, 0.22851562, 0.26953...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.048583984, 0.14355469, 0.22851562, 0.26953...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.040527344, 0.0625, -0.017456055, 0.0786132...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.10546875, -0.13574219, -0.12402344, 0.042...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41299</th>\n",
       "      <td>[[0.040527344, 0.0625, -0.017456055, 0.0786132...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41300</th>\n",
       "      <td>[[-0.05102539, 0.045898438, -0.2734375, -0.259...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41301</th>\n",
       "      <td>[[-0.07763672, -0.15722656, -0.15136719, 0.292...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41302</th>\n",
       "      <td>[[-0.1796875, 0.057128906, 0.14160156, -0.0771...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41303</th>\n",
       "      <td>[[-0.01184082, 0.079589844, 0.016845703, -0.08...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     vec  label\n",
       "0      [[-0.31835938, 0.059570312, -0.22949219, 0.087...      1\n",
       "1      [[0.048583984, 0.14355469, 0.22851562, 0.26953...      1\n",
       "2      [[0.048583984, 0.14355469, 0.22851562, 0.26953...      1\n",
       "3      [[0.040527344, 0.0625, -0.017456055, 0.0786132...      0\n",
       "4      [[-0.10546875, -0.13574219, -0.12402344, 0.042...      0\n",
       "...                                                  ...    ...\n",
       "41299  [[0.040527344, 0.0625, -0.017456055, 0.0786132...      0\n",
       "41300  [[-0.05102539, 0.045898438, -0.2734375, -0.259...      1\n",
       "41301  [[-0.07763672, -0.15722656, -0.15136719, 0.292...      1\n",
       "41302  [[-0.1796875, 0.057128906, 0.14160156, -0.0771...      2\n",
       "41303  [[-0.01184082, 0.079589844, 0.016845703, -0.08...      1\n",
       "\n",
       "[41304 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [len(vec) for vec in list(df1['vec']) if len(vec) <= 64]\n",
    "df1 = df1[df1['vec'].str.len() <= 64]\n",
    "df1 = df1.reset_index(drop= True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41304, 64, 300])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequence([torch.from_numpy(np.array(vec)) for vec in list(df1['vec'])], batch_first=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41304])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.from_numpy(np.array(list(df1['label'])))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    15302\n",
       "2    13862\n",
       "0    12140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(41644 - 41304) # dropped rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size=0.5, train_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "valid_dataset = TensorDataset(x_valid, y_valid)\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_dataset, batch_size= batch_size, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size = batch_size, shuffle=True, drop_last=True)\n",
    "test_dl  = DataLoader(test_dataset, batch_size= batch_size, shuffle=True, drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embed_dim = 300, hidden_size = 128, n_layers= 1):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers = n_layers, batch_first=True)\n",
    "        # self.fc1 = nn.Linear(n_layers * hidden_size, hidden_size)\n",
    "        # self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 3)\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (h1, c1) = self.lstm(x)\n",
    "        # x = self.fc1(x)\n",
    "        # x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        logits = self.softmax(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220547 M\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337) # for the distribution of the gradient\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Model()\n",
    "model.to(device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "print(sum(p.numel() for p in model.parameters()), \"M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 300]) torch.Size([32])\n",
      "torch.Size([32, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "for xb_train, yb_train in train_dl:\n",
    "    print(xb_train.shape, yb_train.shape)\n",
    "    out = model(xb_train)\n",
    "    print(out.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220547 M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lstm): LSTM(300, 128, batch_first=True)\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for _ in range(10):\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     train_acc = 0\n",
    "#     for xb_train, yb_train in train_dl:\n",
    "#         optimizer.zero_grad(set_to_none=False)\n",
    "#         # forward pass\n",
    "#         xb_train = xb_train.to(device)\n",
    "#         yb_train = yb_train.to(device)\n",
    "#         logits= model(xb_train)[:, 0, :]\n",
    "#         loss = F.cross_entropy(logits, yb_train)\n",
    "#         # print(loss.item())\n",
    "#         # import sys; sys.exit(0)\n",
    "#         # backward pass\n",
    "#         loss.backward()\n",
    "#         train_loss += loss.item() * batch_size\n",
    "#         train_acc += (torch.argmax(logits, dim = 1) == yb_train).float().sum().item()\n",
    "#         # update the gradient\n",
    "#         optimizer.step()\n",
    "\n",
    "#     train_loss /= len(train_dl.dataset)\n",
    "#     train_acc /= len(train_dl.dataset)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         valid_loss = 0\n",
    "#         valid_acc = 0\n",
    "#         for xb_valid, yb_valid in valid_dl:\n",
    "#             xb_train = xb_train.to(device)\n",
    "#             yb_train = yb_train.to(device)\n",
    "#             logits = model(xb_valid)[:, 0, :]\n",
    "#             loss = F.cross_entropy(logits, yb_valid)\n",
    "#             valid_loss += loss.item() * batch_size\n",
    "#             valid_acc += (torch.argmax(logits, dim = 1) == yb_train).float().sum().item()\n",
    "    \n",
    "#     valid_loss /= len(valid_dl.dataset)\n",
    "#     valid_acc /= len(valid_dl.dataset)\n",
    "#     # print(f'train_loss {train_loss:4f}, valid loss {valid_loss:4f} ')\n",
    "#     print(f'accuracy {train_acc:4f} || , valid acc {valid_acc:4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
